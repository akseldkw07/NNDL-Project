{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_5aFAaALeLW"
      },
      "source": [
        "# SECTION 1: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85tMtuD924rr",
        "outputId": "761eafdb-8b00-4e58-845f-8db2cf22b374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Sun Dec 14 17:27:36 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   31C    P0             52W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makseldkw\u001b[0m (\u001b[33makseldkw07\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi  # just to sanity-check the GPU\n",
        "\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "\n",
        "USE_WANDB = True\n",
        "WANDB_ENTITY = \"nndl-project-F25\"\n",
        "WANDB_PROJECT = \"Multihead-Classification-Competition\"\n",
        "\n",
        "if USE_WANDB:\n",
        "  wandb.login()\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import os, zipfile, random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# wandb run-naming schema\n",
        "def make_run_name(base: str) -> str:\n",
        "    \"\"\"Create a unique run name with timestamp.\"\"\"\n",
        "    return f\"{base}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "# optional: for approximate reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxiTY5skLo7b"
      },
      "source": [
        "# SECTION 2: Config & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04GRyoqmIVed"
      },
      "outputs": [],
      "source": [
        "DATA_ROOT = \"/content/drive/MyDrive/NNDL-Project/Project Data\"\n",
        "\n",
        "# Local scratch space on the VM / Colab\n",
        "LOCAL_DATA_ROOT = \"/content/local_data\"\n",
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "\n",
        "train_zip_path = os.path.join(DATA_ROOT, \"train_images.zip\")\n",
        "test_zip_path = os.path.join(DATA_ROOT, \"test_images.zip\")\n",
        "\n",
        "# Unzip to LOCAL_DATA_ROOT instead of Drive\n",
        "train_out_dir = os.path.join(LOCAL_DATA_ROOT, \"train_images\")\n",
        "test_out_dir = os.path.join(LOCAL_DATA_ROOT, \"test_images\")\n",
        "\n",
        "if not os.path.exists(train_out_dir):\n",
        "    os.makedirs(train_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(train_zip_path, \"r\") as z:\n",
        "        z.extractall(train_out_dir)\n",
        "\n",
        "if not os.path.exists(test_out_dir):\n",
        "    os.makedirs(test_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(test_zip_path, \"r\") as z:\n",
        "        z.extractall(test_out_dir)\n",
        "\n",
        "TRAIN_IMG_DIR = os.path.join(train_out_dir, \"train_images\")\n",
        "TEST_IMG_DIR = os.path.join(test_out_dir, \"test_images\")\n",
        "\n",
        "TRAIN_CSV = os.path.join(DATA_ROOT, \"train_data.csv\")\n",
        "SUPER_CSV = os.path.join(DATA_ROOT, \"superclass_mapping.csv\")\n",
        "SUB_CSV = os.path.join(DATA_ROOT, \"subclass_mapping.csv\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2  # can set to 0 if we hit dataloader issues\n",
        "\n",
        "VAL_SPLIT = 0.1  # 10% validation\n",
        "IMG_SIZE = 64  # our image dimensions\n",
        "\n",
        "PROJECT_NAME = \"coms4776-transfer-learning\"  # TBD update\n",
        "APPROACH = \"two_models\"  # \"two_heads\" or \"two_models\"\n",
        "DATA_AUGMENT = True\n",
        "\n",
        "# Indices for \"novel\" classes (per provided data)\n",
        "NOVEL_SUPER_IDX = 3  # superclass index for novel\n",
        "NOVEL_SUB_IDX = 87  # subclass index for novel\n",
        "\n",
        "# Number of times run full-batch\n",
        "EPOCHS = 15\n",
        "\n",
        "# Learning rates\n",
        "LR = 1e-4  # overall learning rate\n",
        "LR_HEAD = 1e-2  # head learning rate, used when freezing backbone\n",
        "WEIGHT_DECAY = 1e-4  # seems standard\n",
        "BACKBONE = \"resnet50\"  # \"resnet18\" or \"resnet50\"\n",
        "\n",
        "# Novel-super CIFAR integration (more images)\n",
        "# Options: \"none\", \"small\" (~1000 samples), \"large\" (~5000 samples)\n",
        "CIFAR_NOVEL_MODE = \"large\"  # \"large\" or \"small\" or \"none\"\n",
        "\n",
        "# Path to store metadata about CIFAR novel images\n",
        "CIFAR_NOVEL_CSV_PATH = os.path.join(LOCAL_DATA_ROOT, \"cifar_novel_data.csv\")\n",
        "\n",
        "# Fine-tuning mode for ResNet backbone\n",
        "# \"full\"   = train all layers (what you're currently doing)\n",
        "# \"frozen\" = freeze backbone, train only the heads on top\n",
        "FINE_TUNE_MODE = \"full\"  # or \"frozen\"\n",
        "\n",
        "# Initial novelty thresholds (starting points, will tune further)\n",
        "TAU_SUPER = (\n",
        "    0.99  # NOTE: per calibration with validation data. if max superclass prob < TAU_SUPER -> predict novel superclass\n",
        ")\n",
        "TAU_SUB = 0.85  # NOTE: per calibration with validation data. if max subclass prob < TAU_SUB  -> predict novel subclass\n",
        "\n",
        "########### MAKE SURE USE_PSEDUO_NOVEL IS FALSE BEFORE LEADERBOARD SUBMISSION ##################################################\n",
        "USE_PSEUDO_NOVEL = False  # to validate on held-out subclasses from training. Used to fine-tune TAU_SUB\n",
        "PSEUDO_NOVEL_FRACTION = 0.15\n",
        "PSEUDO_NOVEL_SEED = 123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stQpD0L1ggNX",
        "outputId": "59772190-9548-4120-aa2f-112803244f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building CIFAR novel-super dataset (this happens once)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169M/169M [00:13<00:00, 12.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total candidate CIFAR images (allowed classes, excl. reptiles): 45000\n",
            "Selected indices: 5000\n",
            "Saved CIFAR novel-super metadata to: /content/local_data/cifar_novel_data.csv\n",
            "Images copied into TRAIN_IMG_DIR: /content/local_data/train_images/train_images\n"
          ]
        }
      ],
      "source": [
        "# Build CIFAR-100 novel-super dataset (excluding reptiles)\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "# Download CIFAR100 once (raw PIL images)\n",
        "CIFAR_ROOT = os.path.join(LOCAL_DATA_ROOT, \"cifar100_raw\")\n",
        "os.makedirs(CIFAR_ROOT, exist_ok=True)\n",
        "\n",
        "# Only do the heavy image-copying if CSV doesn't exist\n",
        "if CIFAR_NOVEL_MODE != \"none\" and not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "    print(\"Building CIFAR novel-super dataset (this happens once)...\")\n",
        "\n",
        "    cifar_train = CIFAR100(root=CIFAR_ROOT, train=True, download=True, transform=None)\n",
        "\n",
        "    # CIFAR-100 fine label names (with underscores)\n",
        "    cifar_fine_names = cifar_train.classes  # e.g. \"apple\", \"beaver\", \"aquarium_fish\", ...\n",
        "\n",
        "    # Fine classes we want, based on your list, excluding reptiles\n",
        "    # (these names match CIFAR-100 fine label names)\n",
        "    allowed_fine_names = set(\n",
        "        [\n",
        "            # aquatic mammals\n",
        "            \"beaver\",\n",
        "            \"dolphin\",\n",
        "            \"otter\",\n",
        "            \"seal\",\n",
        "            \"whale\",\n",
        "            # fish\n",
        "            \"aquarium_fish\",\n",
        "            \"flatfish\",\n",
        "            \"ray\",\n",
        "            \"shark\",\n",
        "            \"trout\",\n",
        "            # flowers\n",
        "            \"orchid\",\n",
        "            \"poppy\",\n",
        "            \"rose\",\n",
        "            \"sunflower\",\n",
        "            \"tulip\",\n",
        "            # food containers\n",
        "            \"bottle\",\n",
        "            \"bowl\",\n",
        "            \"can\",\n",
        "            \"cup\",\n",
        "            \"plate\",\n",
        "            # fruit and vegetables\n",
        "            \"apple\",\n",
        "            \"mushroom\",\n",
        "            \"orange\",\n",
        "            \"pear\",\n",
        "            \"sweet_pepper\",\n",
        "            # household electrical devices\n",
        "            \"clock\",\n",
        "            \"keyboard\",\n",
        "            \"lamp\",\n",
        "            \"telephone\",\n",
        "            \"television\",\n",
        "            # household furniture\n",
        "            \"bed\",\n",
        "            \"chair\",\n",
        "            \"couch\",\n",
        "            \"table\",\n",
        "            \"wardrobe\",\n",
        "            # insects\n",
        "            \"bee\",\n",
        "            \"beetle\",\n",
        "            \"butterfly\",\n",
        "            \"caterpillar\",\n",
        "            \"cockroach\",\n",
        "            # large carnivores\n",
        "            \"bear\",\n",
        "            \"leopard\",\n",
        "            \"lion\",\n",
        "            \"tiger\",\n",
        "            \"wolf\",\n",
        "            # large man-made outdoor things\n",
        "            \"bridge\",\n",
        "            \"castle\",\n",
        "            \"house\",\n",
        "            \"road\",\n",
        "            \"skyscraper\",\n",
        "            # large natural outdoor scenes\n",
        "            \"cloud\",\n",
        "            \"forest\",\n",
        "            \"mountain\",\n",
        "            \"plain\",\n",
        "            \"sea\",\n",
        "            # large omnivores and herbivores\n",
        "            \"camel\",\n",
        "            \"cattle\",\n",
        "            \"chimpanzee\",\n",
        "            \"elephant\",\n",
        "            \"kangaroo\",\n",
        "            # medium-sized mammals\n",
        "            \"fox\",\n",
        "            \"porcupine\",\n",
        "            \"possum\",\n",
        "            \"raccoon\",\n",
        "            \"skunk\",\n",
        "            # non-insect invertebrates\n",
        "            \"crab\",\n",
        "            \"lobster\",\n",
        "            \"snail\",\n",
        "            \"spider\",\n",
        "            \"worm\",\n",
        "            # people\n",
        "            \"baby\",\n",
        "            \"boy\",\n",
        "            \"girl\",\n",
        "            \"man\",\n",
        "            \"woman\",\n",
        "            # small mammals\n",
        "            \"hamster\",\n",
        "            \"mouse\",\n",
        "            \"rabbit\",\n",
        "            \"shrew\",\n",
        "            \"squirrel\",\n",
        "            # trees\n",
        "            \"maple\",\n",
        "            \"oak\",\n",
        "            \"palm\",\n",
        "            \"pine\",\n",
        "            \"willow\",\n",
        "            # vehicles 1\n",
        "            \"bicycle\",\n",
        "            \"bus\",\n",
        "            \"motorcycle\",\n",
        "            \"pickup_truck\",\n",
        "            \"train\",\n",
        "            # vehicles 2\n",
        "            \"lawn_mower\",\n",
        "            \"rocket\",\n",
        "            \"streetcar\",\n",
        "            \"tank\",\n",
        "            \"tractor\",\n",
        "            # NOTE: reptiles group (\"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\") is *excluded* on purpose\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Map class_name -> list of indices for that fine class\n",
        "    name_to_indices = {name: [] for name in allowed_fine_names}\n",
        "    for idx in range(len(cifar_train)):\n",
        "        _, fine_label = cifar_train[idx]  # fine_label is int index into cifar_fine_names\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "        if fine_name in allowed_fine_names:\n",
        "            name_to_indices[fine_name].append(idx)\n",
        "\n",
        "    # Flatten candidate indices across all allowed classes\n",
        "    candidate_indices = []\n",
        "    for name, idx_list in name_to_indices.items():\n",
        "        candidate_indices.extend(idx_list)\n",
        "\n",
        "    print(\"Total candidate CIFAR images (allowed classes, excl. reptiles):\", len(candidate_indices))\n",
        "\n",
        "    # Target total novel-super samples (max 5000, as you requested)\n",
        "    TARGET_TOTAL = 5000\n",
        "    random.seed(42)\n",
        "    random.shuffle(candidate_indices)\n",
        "    selected_indices = candidate_indices[:TARGET_TOTAL]\n",
        "\n",
        "    print(\"Selected indices:\", len(selected_indices))\n",
        "\n",
        "    # Copy images into TRAIN_IMG_DIR and build CSV rows\n",
        "    cifar_aug_records = []\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        img, fine_label = cifar_train[idx]\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "\n",
        "        # Unique filename to avoid collisions\n",
        "        fname = f\"cifar_novel_{idx}_{fine_name}.png\"\n",
        "        dst_path = os.path.join(TRAIN_IMG_DIR, fname)\n",
        "\n",
        "        # img is PIL.Image when transform=None\n",
        "        img.save(dst_path)\n",
        "\n",
        "        record = {\n",
        "            \"image\": fname,\n",
        "            \"superclass_index\": NOVEL_SUPER_IDX,  # novel superclass\n",
        "            \"subclass_index\": NOVEL_SUB_IDX,  # novel subclass\n",
        "            \"description\": f\"CIFAR100:{fine_name} (novel superclass)\",\n",
        "        }\n",
        "        cifar_aug_records.append(record)\n",
        "\n",
        "    cifar_aug_df = pd.DataFrame(cifar_aug_records)\n",
        "    cifar_aug_df.to_csv(CIFAR_NOVEL_CSV_PATH, index=False)\n",
        "    print(\"Saved CIFAR novel-super metadata to:\", CIFAR_NOVEL_CSV_PATH)\n",
        "    print(\"Images copied into TRAIN_IMG_DIR:\", TRAIN_IMG_DIR)\n",
        "\n",
        "elif CIFAR_NOVEL_MODE != \"none\":\n",
        "    print(\"CIFAR novel-super CSV already exists at:\", CIFAR_NOVEL_CSV_PATH)\n",
        "else:\n",
        "    print(\"CIFAR_NOVEL_MODE='none'; skipping CIFAR novel-super creation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NzoPU6L0kE"
      },
      "source": [
        "# SECTION 3: Data Loading & DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1DTM3ycL7_-",
        "outputId": "f06c8bdc-2660-4e27-d752-ac3668ad05dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num superclasses: 4\n",
            "Num subclasses: 88\n",
            "CIFAR_NOVEL_MODE='large' → using 5000 CIFAR novel-super samples.\n",
            "Combined train_df size (original + CIFAR): 11288\n",
            "  Novel-super count (superclass_index == NOVEL_SUPER_IDX): 5000\n",
            "Example sub_to_super mapping (first 10): {0: 1, 1: 2, 2: 1, 3: 2, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 1}\n"
          ]
        }
      ],
      "source": [
        "# SECTION 3: Data Loading & Dataloaders\n",
        "\n",
        "# Base training data from class\n",
        "base_train_df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "super_map_df = pd.read_csv(SUPER_CSV)  # columns: index, class\n",
        "sub_map_df = pd.read_csv(SUB_CSV)  # columns: index, class\n",
        "\n",
        "num_super = len(super_map_df)\n",
        "num_sub = len(sub_map_df)\n",
        "\n",
        "print(\"Num superclasses:\", num_super)\n",
        "print(\"Num subclasses:\", num_sub)\n",
        "\n",
        "# --- Integrate CIFAR novel-super examples, if enabled ---\n",
        "\n",
        "if CIFAR_NOVEL_MODE == \"none\":\n",
        "    train_df = base_train_df.copy()\n",
        "    print(\"CIFAR_NOVEL_MODE='none' → using only original training data.\")\n",
        "else:\n",
        "    if not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"CIFAR_NOVEL_MODE={CIFAR_NOVEL_MODE} but {CIFAR_NOVEL_CSV_PATH} not found. \"\n",
        "            \"Run the CIFAR novel-super build section first.\"\n",
        "        )\n",
        "\n",
        "    cifar_aug_df = pd.read_csv(CIFAR_NOVEL_CSV_PATH)\n",
        "\n",
        "    if CIFAR_NOVEL_MODE == \"small\":\n",
        "        # Use ~1000 CIFAR novel-super images\n",
        "        n_small = min(1000, len(cifar_aug_df))\n",
        "        cifar_aug_df = cifar_aug_df.sample(n=n_small, random_state=42).reset_index(drop=True)\n",
        "        print(f\"CIFAR_NOVEL_MODE='small' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    elif CIFAR_NOVEL_MODE == \"large\":\n",
        "        # Use all available (up to 5000 created earlier)\n",
        "        print(f\"CIFAR_NOVEL_MODE='large' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown CIFAR_NOVEL_MODE: {CIFAR_NOVEL_MODE}\")\n",
        "\n",
        "    # Combine original training data with CIFAR novel-super rows\n",
        "    train_df = pd.concat([base_train_df, cifar_aug_df], ignore_index=True)\n",
        "    print(\"Combined train_df size (original + CIFAR):\", len(train_df))\n",
        "    print(\n",
        "        \"  Novel-super count (superclass_index == NOVEL_SUPER_IDX):\",\n",
        "        (train_df[\"superclass_index\"] == NOVEL_SUPER_IDX).sum(),\n",
        "    )\n",
        "\n",
        "# --- Build subclass -> superclass mapping from *combined* train_df ---\n",
        "# This still satisfies “each subclass has a single superclass”:\n",
        "#  - Original subclasses 0..86\n",
        "#  - Novel subclass 87 always maps to NOVEL_SUPER_IDX\n",
        "sub_to_super = train_df.groupby(\"subclass_index\")[\"superclass_index\"].agg(lambda x: x.value_counts().index[0]).to_dict()\n",
        "\n",
        "print(\"Example sub_to_super mapping (first 10):\", dict(list(sub_to_super.items())[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vdqaByetMJR9"
      },
      "outputs": [],
      "source": [
        "# Dataset functions\n",
        "class BirdDogReptileDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_name = row[\"image\"]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        super_idx = int(row[\"superclass_index\"])\n",
        "        sub_idx = int(row[\"subclass_index\"])\n",
        "        return image, super_idx, sub_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydp5kOpbMWTc"
      },
      "outputs": [],
      "source": [
        "# Test dataset (for leaderboard predictions)\n",
        "\n",
        "\n",
        "class BirdDogReptileTestDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        # assumes images are named 0.jpg, 1.jpg, ..., N-1.jpg\n",
        "        self.filenames = sorted(os.listdir(img_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.filenames[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcWn_qDgMcIa"
      },
      "outputs": [],
      "source": [
        "# Transforms\n",
        "\n",
        "if DATA_AUGMENT:\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "else:\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "val_test_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_xpuCQFMf6X",
        "outputId": "39863463-ba29-4ec9-ca42-ed1769dce8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Simple split, novel-super aware]\n",
            "  Seen-super samples: 6288\n",
            "  Novel-super samples: 5000\n",
            "  Final split sizes:\n",
            "    train: 10160\n",
            "    val:   1128\n",
            "    train novel-super: 4500\n",
            "    val novel-super:   500\n",
            "[Simple split] Train size: 10160, Val size: 1128\n",
            "Test size: 11180\n"
          ]
        }
      ],
      "source": [
        "# Train/val split + loaders with optional pseudo-novel validation,\n",
        "# ensuring novel-super examples (super == NOVEL_SUPER_IDX) appear in both train and val.\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "pseudo_novel_loader = None  # default; will be set if USE_PSEUDO_NOVEL\n",
        "heldout_subclasses = None  # to inspect later if needed\n",
        "\n",
        "\n",
        "def split_seen_vs_novel_super(df, val_split, novel_super_idx, rng_seed=42):\n",
        "    \"\"\"\n",
        "    Split dataframe into train/val, ensuring that both seen-super (0/1/2)\n",
        "    and novel-super (== novel_super_idx) appear in both splits if present.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "\n",
        "    df_novel_super = df[df[\"superclass_index\"] == novel_super_idx]\n",
        "    df_seen_super = df[df[\"superclass_index\"] != novel_super_idx]\n",
        "\n",
        "    print(\"  Seen-super samples:\", len(df_seen_super))\n",
        "    print(\"  Novel-super samples:\", len(df_novel_super))\n",
        "\n",
        "    # Split seen-super part\n",
        "    if len(df_seen_super) > 0:\n",
        "        val_seen_size = int(len(df_seen_super) * val_split)\n",
        "        val_seen_indices = rng.choice(len(df_seen_super), size=val_seen_size, replace=False)\n",
        "        val_seen_df = df_seen_super.iloc[val_seen_indices]\n",
        "        train_seen_df = df_seen_super.drop(val_seen_df.index)\n",
        "    else:\n",
        "        val_seen_df = df_seen_super.iloc[0:0]\n",
        "        train_seen_df = df_seen_super.iloc[0:0]\n",
        "\n",
        "    # Split novel-super part (if any)\n",
        "    if len(df_novel_super) > 0:\n",
        "        val_novel_size = max(1, int(len(df_novel_super) * val_split))\n",
        "        val_novel_indices = rng.choice(len(df_novel_super), size=val_novel_size, replace=False)\n",
        "        val_novel_df = df_novel_super.iloc[val_novel_indices]\n",
        "        train_novel_df = df_novel_super.drop(val_novel_df.index)\n",
        "    else:\n",
        "        val_novel_df = df_novel_super.iloc[0:0]\n",
        "        train_novel_df = df_novel_super.iloc[0:0]\n",
        "\n",
        "    # Combine splits and shuffle\n",
        "    train_split_df = pd.concat([train_seen_df, train_novel_df], ignore_index=True)\n",
        "    val_split_df = pd.concat([val_seen_df, val_novel_df], ignore_index=True)\n",
        "\n",
        "    train_split_df = train_split_df.sample(frac=1.0, random_state=rng_seed).reset_index(drop=True)\n",
        "    val_split_df = val_split_df.sample(frac=1.0, random_state=rng_seed + 1).reset_index(drop=True)\n",
        "\n",
        "    print(\"  Final split sizes:\")\n",
        "    print(\"    train:\", len(train_split_df))\n",
        "    print(\"    val:  \", len(val_split_df))\n",
        "    print(\"    train novel-super:\", (train_split_df[\"superclass_index\"] == novel_super_idx).sum())\n",
        "    print(\"    val novel-super:  \", (val_split_df[\"superclass_index\"] == novel_super_idx).sum())\n",
        "\n",
        "    return train_split_df, val_split_df\n",
        "\n",
        "\n",
        "if not USE_PSEUDO_NOVEL:\n",
        "    # -------------------------\n",
        "    # Simple split, but novel-super-aware\n",
        "    # -------------------------\n",
        "    print(\"[Simple split, novel-super aware]\")\n",
        "\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(\n",
        "        train_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=42,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(f\"[Simple split] Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
        "\n",
        "else:\n",
        "    # -------------------------\n",
        "    # Pseudo-novel setup: hold out some subclasses entirely for pseudo-novel validation\n",
        "    # while still keeping novel-super in both train and val.\n",
        "    # -------------------------\n",
        "\n",
        "    print(\"[Pseudo-novel subclass split + novel-super-aware train/val]\")\n",
        "\n",
        "    # 1) choose subset of subclasses to treat as pseudo-novel\n",
        "    all_subclasses = sorted(train_df[\"subclass_index\"].unique())\n",
        "    # Do NOT hold out the novel subclass itself (87)\n",
        "    all_subclasses_no_novel = [c for c in all_subclasses if c != NOVEL_SUB_IDX]\n",
        "\n",
        "    rng = np.random.default_rng(PSEUDO_NOVEL_SEED)\n",
        "\n",
        "    num_holdout = max(1, int(len(all_subclasses_no_novel) * PSEUDO_NOVEL_FRACTION))\n",
        "    heldout_subclasses = set(rng.choice(all_subclasses_no_novel, size=num_holdout, replace=False).tolist())\n",
        "    seen_subclasses = [c for c in all_subclasses if c not in heldout_subclasses]\n",
        "\n",
        "    print(f\"[Pseudo-novel] Total subclasses (excl. novel): {len(all_subclasses_no_novel)}\")\n",
        "    print(f\"[Pseudo-novel] Held-out subclasses (pseudo-novel): {sorted(heldout_subclasses)}\")\n",
        "    print(f\"[Pseudo-novel] Seen subclasses (incl. novel-sub): {len(seen_subclasses)}\")\n",
        "\n",
        "    # 2) split dataframe into seen vs pseudo-novel (by subclass)\n",
        "    seen_mask = ~train_df[\"subclass_index\"].isin(heldout_subclasses)\n",
        "    seen_df = train_df[seen_mask].reset_index(drop=True)\n",
        "    pseudo_novel_df = train_df[~seen_mask].reset_index(drop=True)\n",
        "\n",
        "    print(f\"[Pseudo-novel] Seen samples: {len(seen_df)}, Pseudo-novel samples: {len(pseudo_novel_df)}\")\n",
        "\n",
        "    # 3) Train/val split on seen data, but ensure novel-super in both\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(\n",
        "        seen_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=PSEUDO_NOVEL_SEED,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_seen_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_seen_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # 4) pseudo-novel validation loader (all held-out subclasses, val-style transform)\n",
        "    pseudo_novel_dataset = BirdDogReptileDataset(\n",
        "        pseudo_novel_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "    pseudo_novel_loader = DataLoader(\n",
        "        pseudo_novel_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"[Pseudo-novel] Train size: {len(train_dataset)}, \"\n",
        "        f\"Seen-val size: {len(val_seen_dataset)}, \"\n",
        "        f\"Pseudo-novel val size: {len(pseudo_novel_dataset)}\"\n",
        "    )\n",
        "\n",
        "# Test loader is the same regardless\n",
        "test_dataset = BirdDogReptileTestDataset(TEST_IMG_DIR, transform=val_test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=NUM_WORKERS)\n",
        "# change batch size back to 1 if see any errors\n",
        "\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6WgPWLVND6D"
      },
      "source": [
        "# SECTION 4: Backbone & Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQS_4YIINJyo"
      },
      "outputs": [],
      "source": [
        "# Backbone builder\n",
        "\n",
        "# Using ImageNet pretrained ResNet backbone, and chopping off FC head to Transfer Learn\n",
        "\n",
        "\n",
        "def build_resnet_backbone():\n",
        "    # Using torchvision ResNet-18 with ImageNet weights\n",
        "    if BACKBONE == \"resnet18\":\n",
        "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    elif BACKBONE == \"resnet50\":\n",
        "        base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown BACKBONE: {BACKBONE}\")\n",
        "    # Remove the final classification layer\n",
        "    in_features = base.fc.in_features\n",
        "    base.fc = nn.Identity()\n",
        "    return base, in_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyTxkOsZNZaR"
      },
      "outputs": [],
      "source": [
        "# Methods for Shared backbone + two heads + KL divergence\n",
        "\n",
        "\n",
        "class SharedBackboneTwoHeads(nn.Module):\n",
        "    def __init__(self, num_super, num_sub):\n",
        "        super().__init__()\n",
        "        self.backbone, feat_dim = build_resnet_backbone()\n",
        "        self.super_head = nn.Linear(feat_dim, num_super)\n",
        "        self.sub_head = nn.Linear(feat_dim, num_sub)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        super_logits = self.super_head(feats)\n",
        "        sub_logits = self.sub_head(feats)\n",
        "        return super_logits, sub_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NrchhvbNhi2"
      },
      "outputs": [],
      "source": [
        "# KL helper that maps subclass probs to superclass probs using sub_to_super mapping\n",
        "\n",
        "\n",
        "def sub_probs_to_super_probs(sub_probs, sub_to_super, num_super):\n",
        "    \"\"\"\n",
        "    sub_probs: (B, num_sub), softmax over subclasses\n",
        "    returns: (B, num_super), summed probs per super-class\n",
        "    \"\"\"\n",
        "    B, num_sub = sub_probs.shape\n",
        "    super_probs = torch.zeros(B, num_super, device=sub_probs.device)\n",
        "\n",
        "    for sub_idx, super_idx in sub_to_super.items():\n",
        "        super_probs[:, super_idx] += sub_probs[:, sub_idx]\n",
        "\n",
        "    # For safety: re-normalize in case of any numeric drift\n",
        "    super_probs = super_probs / (super_probs.sum(dim=1, keepdim=True) + 1e-8)\n",
        "    return super_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4yfIaOINvbk"
      },
      "outputs": [],
      "source": [
        "# Single-head model for 2-separate models approach\n",
        "# Each model is just a backbone + one linear head\n",
        "\n",
        "# to instantiate, one has num_classes = num_super, other has num_classes = num_sub\n",
        "\n",
        "\n",
        "class SingleHeadModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone, feat_dim = build_resnet_backbone()\n",
        "        self.head = nn.Linear(feat_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        logits = self.head(feats)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuf8bEcxONLs"
      },
      "source": [
        "# SECTION 5: Training & evaluation utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Unso2GHLOnLe"
      },
      "outputs": [],
      "source": [
        "# functions for training\n",
        "\n",
        "# we pass a flag mode to indicate which model using either:\n",
        "# \"two_heads_kl\", \"single_head_super\" or \"single_head\"sub\"\n",
        "\n",
        "\n",
        "def accuracy_from_logits(logits, targets):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    correct = (preds == targets).sum().item()\n",
        "    total = targets.size(0)\n",
        "    return correct, total\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "    model, optimizer, loader, criterion, mode, sub_to_super=None, num_super=None, alpha_kl=0.1, temperature=1.0\n",
        "):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    super_correct = sub_correct = 0\n",
        "    super_total = sub_total = 0\n",
        "\n",
        "    for images, super_labels, sub_labels in loader:\n",
        "        images = images.to(device)\n",
        "        super_labels = super_labels.to(device)\n",
        "        sub_labels = sub_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if mode == \"two_heads_kl\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "            # CE losses\n",
        "            loss_super = criterion(super_logits, super_labels)\n",
        "            loss_sub = criterion(sub_logits, sub_labels)\n",
        "\n",
        "            # KL term between super head and aggregated subclass head\n",
        "            with torch.no_grad():\n",
        "                # target: super_probs\n",
        "                super_probs = F.softmax(super_logits / temperature, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits / temperature, dim=1)\n",
        "            agg_super_probs = sub_probs_to_super_probs(sub_probs, sub_to_super, num_super)\n",
        "\n",
        "            # KL(super || agg_super) = sum p * (log p - log q)\n",
        "            # using KLDivLoss with log_softmax input and probs target:\n",
        "            kl_loss = F.kl_div(input=torch.log(agg_super_probs + 1e-8), target=super_probs, reduction=\"batchmean\")\n",
        "\n",
        "            loss = loss_super + loss_sub + alpha_kl * kl_loss\n",
        "\n",
        "            sc, st = accuracy_from_logits(super_logits, super_labels)\n",
        "            suc, sut = accuracy_from_logits(sub_logits, sub_labels)\n",
        "            super_correct += sc\n",
        "            super_total += st\n",
        "            sub_correct += suc\n",
        "            sub_total += sut\n",
        "\n",
        "        elif mode in (\"single_head_super\", \"single_head_sub\"):\n",
        "            logits = model(images)\n",
        "            if mode == \"single_head_super\":\n",
        "                loss = criterion(logits, super_labels)\n",
        "                sc, st = accuracy_from_logits(logits, super_labels)\n",
        "                super_correct += sc\n",
        "                super_total += st\n",
        "            else:\n",
        "                loss = criterion(logits, sub_labels)\n",
        "                suc, sut = accuracy_from_logits(logits, sub_labels)\n",
        "                sub_correct += suc\n",
        "                sub_total += sut\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode {mode}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    metrics = {\"loss\": avg_loss}\n",
        "    if super_total > 0:\n",
        "        metrics[\"acc_super\"] = super_correct / super_total\n",
        "    if sub_total > 0:\n",
        "        metrics[\"acc_sub\"] = sub_correct / sub_total\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader, criterion, mode, sub_to_super=None, num_super=None, alpha_kl=0.1, temperature=1.0):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    super_correct = sub_correct = 0\n",
        "    super_total = sub_total = 0\n",
        "\n",
        "    for images, super_labels, sub_labels in loader:\n",
        "        images = images.to(device)\n",
        "        super_labels = super_labels.to(device)\n",
        "        sub_labels = sub_labels.to(device)\n",
        "\n",
        "        if mode == \"two_heads_kl\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "            loss_super = criterion(super_logits, super_labels)\n",
        "            loss_sub = criterion(sub_logits, sub_labels)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                super_probs = F.softmax(super_logits / temperature, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits / temperature, dim=1)\n",
        "            agg_super_probs = sub_probs_to_super_probs(sub_probs, sub_to_super, num_super)\n",
        "\n",
        "            kl_loss = F.kl_div(input=torch.log(agg_super_probs + 1e-8), target=super_probs, reduction=\"batchmean\")\n",
        "\n",
        "            loss = loss_super + loss_sub + alpha_kl * kl_loss\n",
        "\n",
        "            sc, st = accuracy_from_logits(super_logits, super_labels)\n",
        "            suc, sut = accuracy_from_logits(sub_logits, sub_labels)\n",
        "            super_correct += sc\n",
        "            super_total += st\n",
        "            sub_correct += suc\n",
        "            sub_total += sut\n",
        "\n",
        "        elif mode in (\"single_head_super\", \"single_head_sub\"):\n",
        "            logits = model(images)\n",
        "            if mode == \"single_head_super\":\n",
        "                loss = criterion(logits, super_labels)\n",
        "                sc, st = accuracy_from_logits(logits, super_labels)\n",
        "                super_correct += sc\n",
        "                super_total += st\n",
        "            else:\n",
        "                loss = criterion(logits, sub_labels)\n",
        "                suc, sut = accuracy_from_logits(logits, sub_labels)\n",
        "                sub_correct += suc\n",
        "                sub_total += sut\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    metrics = {\"val_loss\": avg_loss}\n",
        "    if super_total > 0:\n",
        "        metrics[\"val_acc_super\"] = super_correct / super_total\n",
        "    if sub_total > 0:\n",
        "        metrics[\"val_acc_sub\"] = sub_correct / sub_total\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "varT5fWNMiJI"
      },
      "outputs": [],
      "source": [
        "# Analysis and Visualize: for Novel Subclass fine tuning\n",
        "# Determines optimal threshold value from training data (except held out) vs. held out (pseudo-novel) subclass data\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_max_probs_sub(model, loader, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Collect max softmax probabilities from the subclass head.\n",
        "\n",
        "    mode:\n",
        "      - \"two_heads\": model(images) -> (super_logits, sub_logits)\n",
        "      - \"sub_single_head\": model(images) -> sub_logits\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    probs = []\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            _, sub_logits = model(images)\n",
        "        elif mode == \"sub_single_head\":\n",
        "            sub_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        # Softmax over subclasses, then take max per sample\n",
        "        p = F.softmax(sub_logits, dim=1).max(dim=1).values\n",
        "        probs.extend(p.cpu().numpy().tolist())\n",
        "\n",
        "    return np.array(probs)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def analyze_tau_sub(model, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Compare max subclass probabilities on:\n",
        "      - seen validation (val_loader)\n",
        "      - pseudo-novel validation (pseudo_novel_loader)\n",
        "    and suggest TAU_SUB candidates.\n",
        "    \"\"\"\n",
        "\n",
        "    if pseudo_novel_loader is None:\n",
        "        print(\n",
        "            \"pseudo_novel_loader is None. \" \"Set USE_PSEUDO_NOVEL = True before building loaders to use this analysis.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # Collect max probs\n",
        "    seen_probs = collect_max_probs_sub(model, val_loader, mode=mode)\n",
        "    pseudo_probs = collect_max_probs_sub(model, pseudo_novel_loader, mode=mode)\n",
        "\n",
        "    # Summary stats\n",
        "    def summarize(name, arr):\n",
        "        print(f\"\\n{name} subclass max-prob stats:\")\n",
        "        print(f\"  count = {len(arr)}\")\n",
        "        print(f\"  mean  = {arr.mean():.3f}\")\n",
        "        print(f\"  std   = {arr.std():.3f}\")\n",
        "        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
        "        pvals = {p: float(np.percentile(arr, p)) for p in percentiles}\n",
        "        print(\"  percentiles:\")\n",
        "        for p in percentiles:\n",
        "            print(f\"    p{p:>2}: {pvals[p]:.3f}\")\n",
        "        return pvals\n",
        "\n",
        "    seen_p = summarize(\"Seen\", seen_probs)\n",
        "    pseudo_p = summarize(\"Pseudo-novel\", pseudo_probs)\n",
        "\n",
        "    # Simple candidate thresholds\n",
        "    # 1) 10th percentile of seen (reject only the lowest-confidence seen examples)\n",
        "    tau_candidate_1 = seen_p[10]\n",
        "\n",
        "    # 2) Midpoint between mean(seen) and mean(pseudo)\n",
        "    tau_candidate_2 = 0.5 * (seen_probs.mean() + pseudo_probs.mean())\n",
        "\n",
        "    print(\"\\nSuggested TAU_SUB candidates:\")\n",
        "    print(f\"  tau_sub ≈ 10th percentile of seen: {tau_candidate_1:.3f}\")\n",
        "    print(f\"  tau_sub ≈ mean(seen + pseudo)/2:  {tau_candidate_2:.3f}\")\n",
        "    print(\"\\nYou can start with one of these for TAU_SUB and adjust based on leaderboard/behavior.\")\n",
        "\n",
        "    # Histogram visualization\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(seen_probs, bins=30, alpha=0.5, label=\"Seen subclasses\")\n",
        "    plt.hist(pseudo_probs, bins=30, alpha=0.5, label=\"Pseudo-novel subclasses\")\n",
        "    plt.axvline(tau_candidate_1, linestyle=\"--\", label=f\"p10 seen ~ {tau_candidate_1:.2f}\")\n",
        "    plt.axvline(tau_candidate_2, linestyle=\":\", label=f\"mean midpoint ~ {tau_candidate_2:.2f}\")\n",
        "    plt.xlabel(\"Max softmax probability (subclass head)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Subclass max-prob: seen vs pseudo-novel\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Optional: log histograms and candidates to W&B\n",
        "    if USE_WANDB:\n",
        "        try:\n",
        "            import wandb\n",
        "\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"sub_seen_maxprob_hist\": wandb.Histogram(seen_probs),\n",
        "                    \"sub_pseudo_maxprob_hist\": wandb.Histogram(pseudo_probs),\n",
        "                    \"tau_sub_candidate_p10_seen\": tau_candidate_1,\n",
        "                    \"tau_sub_candidate_mean_midpoint\": tau_candidate_2,\n",
        "                }\n",
        "            )\n",
        "            print(\"Logged histograms and tau_sub candidates to Weights & Biases.\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not log to W&B:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E6cjjSDOODs"
      },
      "outputs": [],
      "source": [
        "# Analysis and Visualize: for Novel Superclass fine tuning\n",
        "# Determines the optimal threshold from provided training data vs. Novel Super data (more images)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_max_probs_super(model, loader, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Collect max softmax probabilities from the superclass head.\n",
        "\n",
        "    mode:\n",
        "      - \"two_heads\": model(images) -> (super_logits, sub_logits)\n",
        "      - \"super_single_head\": model(images) -> super_logits\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    probs = []\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            super_logits, _ = model(images)\n",
        "        elif mode == \"super_single_head\":\n",
        "            super_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        p = F.softmax(super_logits, dim=1).max(dim=1).values\n",
        "        probs.extend(p.cpu().numpy().tolist())\n",
        "\n",
        "    return np.array(probs)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def analyze_tau_super(model, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Analyze max superclass probabilities on validation set, split into:\n",
        "      - seen superclasses (super != NOVEL_SUPER_IDX)\n",
        "      - novel superclasses (super == NOVEL_SUPER_IDX)\n",
        "\n",
        "    This assumes:\n",
        "      - val_loader batches look like (images, super_labels, sub_labels, ...)\n",
        "      - NOVEL_SUPER_IDX is defined (e.g. 3)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    seen_probs = []\n",
        "    novel_probs = []\n",
        "\n",
        "    for batch in val_loader:\n",
        "        images = batch[0].to(device)\n",
        "        super_labels = batch[1].to(device)  # assumes (images, super, sub, ...)\n",
        "\n",
        "        # Forward\n",
        "        if mode == \"two_heads\":\n",
        "            super_logits, _ = model(images)\n",
        "        elif mode == \"super_single_head\":\n",
        "            super_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        probs = F.softmax(super_logits, dim=1)  # (B, num_super)\n",
        "        max_probs, _ = probs.max(dim=1)  # (B,)\n",
        "\n",
        "        novel_mask = super_labels == NOVEL_SUPER_IDX\n",
        "        seen_mask = ~novel_mask\n",
        "\n",
        "        if seen_mask.any():\n",
        "            seen_probs.extend(max_probs[seen_mask].detach().cpu().numpy().tolist())\n",
        "        if novel_mask.any():\n",
        "            novel_probs.extend(max_probs[novel_mask].detach().cpu().numpy().tolist())\n",
        "\n",
        "    seen_probs = np.array(seen_probs)\n",
        "    novel_probs = np.array(novel_probs)\n",
        "\n",
        "    def summarize(name, arr):\n",
        "        print(f\"\\n{name} superclass max-prob stats:\")\n",
        "        print(f\"  count = {len(arr)}\")\n",
        "        print(f\"  mean  = {arr.mean():.3f}\")\n",
        "        print(f\"  std   = {arr.std():.3f}\")\n",
        "        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
        "        pvals = {p: float(np.percentile(arr, p)) for p in percentiles}\n",
        "        print(\"  percentiles:\")\n",
        "        for p in percentiles:\n",
        "            print(f\"    p{p:>2}: {pvals[p]:.3f}\")\n",
        "        return pvals\n",
        "\n",
        "    if len(seen_probs) == 0:\n",
        "        print(\"No seen-super examples found in val_loader (super != NOVEL_SUPER_IDX).\")\n",
        "        return\n",
        "    seen_p = summarize(\"Seen superclasses (0/1/2)\", seen_probs)\n",
        "\n",
        "    if len(novel_probs) == 0:\n",
        "        print(\"\\nNo novel-super examples (super == NOVEL_SUPER_IDX) in val_loader yet.\")\n",
        "        novel_p = None\n",
        "    else:\n",
        "        novel_p = summarize(\"Novel superclasses (== NOVEL_SUPER_IDX)\", novel_probs)\n",
        "\n",
        "    # ---- Candidate thresholds ----\n",
        "    # Start from seen distribution:\n",
        "    tau_p10_seen = seen_p[10]\n",
        "    tau_p5_seen = seen_p[5]\n",
        "    tau_mean_minus_std = max(0.0, min(1.0, seen_probs.mean() - seen_probs.std()))\n",
        "\n",
        "    # If we have novel-super stats, try to place tau between seen & novel means/percentiles\n",
        "    if novel_p is not None:\n",
        "        # Midpoint between seen mean and novel mean\n",
        "        tau_mean_mid = 0.5 * (seen_probs.mean() + novel_probs.mean())\n",
        "        print(\"\\nSuggested TAU_SUPER candidates (using seen + novel):\")\n",
        "        print(f\"  tau_super ≈ 10th percentile of seen:       {tau_p10_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ 5th percentile of seen:        {tau_p5_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ mean(seen) - std(seen):        {tau_mean_minus_std:.3f}\")\n",
        "        print(f\"  tau_super ≈ mean(seen & novel) midpoint:   {tau_mean_mid:.3f}\")\n",
        "        tau_candidates = [tau_p10_seen, tau_p5_seen, tau_mean_minus_std, tau_mean_mid]\n",
        "    else:\n",
        "        print(\"\\nSuggested TAU_SUPER candidates (seen only):\")\n",
        "        print(f\"  tau_super ≈ 10th percentile of seen:       {tau_p10_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ 5th percentile of seen:        {tau_p5_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ mean(seen) - std(seen):        {tau_mean_minus_std:.3f}\")\n",
        "        tau_candidates = [tau_p10_seen, tau_p5_seen, tau_mean_minus_std]\n",
        "\n",
        "    # ---- Histogram plot ----\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(seen_probs, bins=30, alpha=0.6, label=\"Seen superclasses (0/1/2)\")\n",
        "    if len(novel_probs) > 0:\n",
        "        plt.hist(novel_probs, bins=30, alpha=0.6, label=\"Novel superclasses (3)\")\n",
        "\n",
        "    # Draw candidate lines (use a couple of them for visual reference)\n",
        "    for tau in tau_candidates[:3]:\n",
        "        plt.axvline(tau, linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "    plt.xlabel(\"Max softmax probability (superclass head)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Superclass max-prob: seen vs novel-super on validation\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Optional: log to W&B ----\n",
        "    if USE_WANDB:\n",
        "        try:\n",
        "            import wandb\n",
        "\n",
        "            log_dict = {\n",
        "                \"super_seen_maxprob_hist\": wandb.Histogram(seen_probs),\n",
        "            }\n",
        "            if len(novel_probs) > 0:\n",
        "                log_dict[\"super_novel_maxprob_hist\"] = wandb.Histogram(novel_probs)\n",
        "            # Also log first few tau candidates\n",
        "            log_dict[\"tau_super_candidate_1\"] = float(tau_candidates[0])\n",
        "            if len(tau_candidates) > 1:\n",
        "                log_dict[\"tau_super_candidate_2\"] = float(tau_candidates[1])\n",
        "            if len(tau_candidates) > 2:\n",
        "                log_dict[\"tau_super_candidate_3\"] = float(tau_candidates[2])\n",
        "            wandb.log(log_dict)\n",
        "            print(\"Logged superclass histograms and tau_super candidates to Weights & Biases.\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not log to W&B:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO9BTeC7rIwe"
      },
      "outputs": [],
      "source": [
        "# Additional eval helper functions\n",
        "\n",
        "# This calculates the following:\n",
        "# 1. How often we correctly keep seen classes (low false \"novel\" rate)\n",
        "# 2. How often we correctly identify CIFAR \"novel super\" samples (new data)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_on_val_with_novelty(\n",
        "    model, mode=\"two_heads\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, loader=None, name=\"val\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate a model on a loader with novel thresholds applied.\n",
        "\n",
        "    For subclasses, we ONLY care about:\n",
        "      - overall subclass acc\n",
        "      - seen-subclass acc / false-novel rate\n",
        "\n",
        "    We DO NOT report \"novel-subclass accuracy\" here because there are no\n",
        "    ground-truth novel-sub labels in the original validation data.\n",
        "    \"\"\"\n",
        "    if loader is None:\n",
        "        loader = val_loader\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    super_correct = 0\n",
        "    sub_correct = 0\n",
        "\n",
        "    seen_super_correct = seen_super_total = 0\n",
        "    novel_super_correct = novel_super_total = 0\n",
        "\n",
        "    seen_sub_correct = seen_sub_total = 0\n",
        "    novel_sub_correct = novel_sub_total = 0  # still counted but not reported\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "        super_true = batch[1].to(device)\n",
        "        sub_true = batch[2].to(device)\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "        elif mode == \"super_single_head\":\n",
        "            super_logits = model(images)\n",
        "            sub_logits = None\n",
        "        elif mode == \"sub_single_head\":\n",
        "            super_logits = None\n",
        "            sub_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        # --- Superclass ---\n",
        "        if super_logits is not None:\n",
        "            super_probs = F.softmax(super_logits, dim=1)\n",
        "            max_super_probs, super_idx = super_probs.max(dim=1)\n",
        "\n",
        "            super_pred = super_idx.clone()\n",
        "            novel_mask_super = max_super_probs < tau_super\n",
        "            super_pred[novel_mask_super] = NOVEL_SUPER_IDX\n",
        "\n",
        "            match_super = super_pred == super_true\n",
        "            super_correct += match_super.sum().item()\n",
        "\n",
        "            seen_mask_super = super_true != NOVEL_SUPER_IDX\n",
        "            novel_mask_super_label = super_true == NOVEL_SUPER_IDX\n",
        "\n",
        "            if seen_mask_super.any():\n",
        "                seen_super_correct += match_super[seen_mask_super].sum().item()\n",
        "                seen_super_total += seen_mask_super.sum().item()\n",
        "            if novel_mask_super_label.any():\n",
        "                novel_super_correct += match_super[novel_mask_super_label].sum().item()\n",
        "                novel_super_total += novel_mask_super_label.sum().item()\n",
        "\n",
        "        # --- Subclass ---\n",
        "        if sub_logits is not None:\n",
        "            sub_probs = F.softmax(sub_logits, dim=1)\n",
        "            max_sub_probs, sub_idx = sub_probs.max(dim=1)\n",
        "\n",
        "            sub_pred = sub_idx.clone()\n",
        "            novel_mask_sub = max_sub_probs < tau_sub\n",
        "            sub_pred[novel_mask_sub] = NOVEL_SUB_IDX\n",
        "\n",
        "            match_sub = sub_pred == sub_true\n",
        "            sub_correct += match_sub.sum().item()\n",
        "\n",
        "            seen_mask_sub = sub_true != NOVEL_SUB_IDX\n",
        "            novel_mask_sub_label = sub_true == NOVEL_SUB_IDX\n",
        "\n",
        "            if seen_mask_sub.any():\n",
        "                seen_sub_correct += match_sub[seen_mask_sub].sum().item()\n",
        "                seen_sub_total += seen_mask_sub.sum().item()\n",
        "            if novel_mask_sub_label.any():\n",
        "                # counted but not reported; there shouldn't be any in original val\n",
        "                novel_sub_correct += match_sub[novel_mask_sub_label].sum().item()\n",
        "                novel_sub_total += novel_mask_sub_label.sum().item()\n",
        "\n",
        "    # ----- Compute metrics dict -----\n",
        "    metrics = {}\n",
        "\n",
        "    if total > 0:\n",
        "        if super_correct > 0 or seen_super_total + novel_super_total > 0:\n",
        "            metrics[\"overall_super_acc\"] = super_correct / total\n",
        "        if sub_correct > 0 or seen_sub_total + novel_sub_total > 0:\n",
        "            metrics[\"overall_sub_acc\"] = sub_correct / total\n",
        "\n",
        "    if seen_super_total > 0:\n",
        "        metrics[\"seen_super_acc\"] = seen_super_correct / seen_super_total\n",
        "        metrics[\"seen_super_false_novel\"] = 1.0 - metrics[\"seen_super_acc\"]\n",
        "    if novel_super_total > 0:\n",
        "        metrics[\"novel_super_acc\"] = novel_super_correct / novel_super_total\n",
        "\n",
        "    if seen_sub_total > 0:\n",
        "        metrics[\"seen_sub_acc\"] = seen_sub_correct / seen_sub_total\n",
        "        metrics[\"seen_sub_false_novel\"] = 1.0 - metrics[\"seen_sub_acc\"]\n",
        "    # NOTE: we deliberately do NOT add novel-sub metrics to `metrics`,\n",
        "    # because they are not meaningful for this dataset.\n",
        "\n",
        "    # ----- Print summary -----\n",
        "    print(f\"\\n=== Evaluation on {name} ===\")\n",
        "    if \"overall_super_acc\" in metrics:\n",
        "        print(f\"Overall superclass acc: {metrics['overall_super_acc']:.4f}\")\n",
        "    if \"overall_sub_acc\" in metrics:\n",
        "        print(f\"Overall subclass acc:   {metrics['overall_sub_acc']:.4f}\")\n",
        "\n",
        "    if \"seen_super_acc\" in metrics:\n",
        "        print(f\"Seen superclass acc (true super != novel):   {metrics['seen_super_acc']:.4f}\")\n",
        "        print(f\"Seen superclass false-novel rate:            {metrics['seen_super_false_novel']:.4f}\")\n",
        "    if \"novel_super_acc\" in metrics:\n",
        "        print(f\"Novel superclass acc (true super == novel):  {metrics['novel_super_acc']:.4f}\")\n",
        "\n",
        "    if \"seen_sub_acc\" in metrics:\n",
        "        print(f\"Seen subclass acc (true sub != novel):       {metrics['seen_sub_acc']:.4f}\")\n",
        "        print(f\"Seen subclass false-novel rate:              {metrics['seen_sub_false_novel']:.4f}\")\n",
        "\n",
        "    # ----- Optional: log to W&B (only real metrics) -----\n",
        "    if USE_WANDB:\n",
        "        log_dict = {}\n",
        "        for k, v in metrics.items():\n",
        "            log_dict[f\"{name}_{k}\"] = v\n",
        "        if log_dict:\n",
        "            wandb.log(log_dict)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# This enables us to evaluate how often we correctly mark held-out subclasses as novel (proxy for leaderboard performance on subclasses)\n",
        "@torch.no_grad()\n",
        "def evaluate_pseudo_novel_sub_with_novelty(\n",
        "    model, mode=\"two_heads\", tau_sub=TAU_SUB, loader=None, name=\"pseudo_novel_sub\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate how well the model flags held-out subclasses as novel.\n",
        "\n",
        "    Assumes:\n",
        "      - loader yields only *held-out* subclasses (true unseen subclasses)\n",
        "      - true labels are NOT NOVEL_SUB_IDX, but we *want* the model to predict NOVEL_SUB_IDX.\n",
        "    \"\"\"\n",
        "    if loader is None:\n",
        "        loader = pseudo_novel_loader\n",
        "\n",
        "    if loader is None:\n",
        "        print(\"No pseudo_novel_loader available.\")\n",
        "        return {}\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    predicted_novel = 0\n",
        "    predicted_seen = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "        # we don't actually need the labels here for correctness, only for counting\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            _, sub_logits = model(images)\n",
        "        elif mode == \"sub_single_head\":\n",
        "            sub_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode for pseudo-novel eval: {mode}\")\n",
        "\n",
        "        sub_probs = F.softmax(sub_logits, dim=1)\n",
        "        max_sub_probs, sub_idx = sub_probs.max(dim=1)\n",
        "\n",
        "        sub_pred = sub_idx.clone()\n",
        "        novel_mask_sub = max_sub_probs < tau_sub\n",
        "        sub_pred[novel_mask_sub] = NOVEL_SUB_IDX\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        predicted_novel += (sub_pred == NOVEL_SUB_IDX).sum().item()\n",
        "        predicted_seen += (sub_pred != NOVEL_SUB_IDX).sum().item()\n",
        "\n",
        "    metrics = {}\n",
        "    if total > 0:\n",
        "        metrics[\"pseudo_novel_sub_novel_rate\"] = predicted_novel / total\n",
        "        metrics[\"pseudo_novel_sub_false_seen\"] = predicted_seen / total\n",
        "\n",
        "    print(f\"\\n=== Evaluation on {name} (held-out subclasses) ===\")\n",
        "    if total > 0:\n",
        "        print(f\"Fraction flagged as novel (good): {metrics['pseudo_novel_sub_novel_rate']:.4f}\")\n",
        "        print(f\"Fraction mapped to seen subclasses (bad): {metrics['pseudo_novel_sub_false_seen']:.4f}\")\n",
        "\n",
        "    if USE_WANDB and metrics:\n",
        "        log_dict = {f\"{name}_{k}\": v for k, v in metrics.items()}\n",
        "        wandb.log(log_dict)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U11cdLGHxFa0"
      },
      "outputs": [],
      "source": [
        "# Dashboard for our evals so we can determine how model will likely perform on leaderboard evaluation\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def novelty_dashboard(model, mode=\"two_heads\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, include_pseudo=True):\n",
        "    \"\"\"\n",
        "    Run thresholded evals and show a compact table of key metrics.\n",
        "\n",
        "    Subclass side focuses on:\n",
        "      - seen subclasses (false-novel rate)\n",
        "      - held-out pseudo-novel subclasses (how often marked as novel)\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # --- Main val_loader stats (seen + CIFAR-novel) ---\n",
        "    val_metrics = evaluate_on_val_with_novelty(\n",
        "        model,\n",
        "        mode=mode,\n",
        "        tau_super=tau_super,\n",
        "        tau_sub=tau_sub,\n",
        "        loader=val_loader,\n",
        "        name=\"val\",\n",
        "    )\n",
        "\n",
        "    # Superclass (val)\n",
        "    if \"seen_super_acc\" in val_metrics:\n",
        "        rows.append(\n",
        "            {\n",
        "                \"Split\": \"val\",\n",
        "                \"Head\": \"super\",\n",
        "                \"Metric\": \"Seen superclass accuracy\",\n",
        "                \"Meaning\": \"Correctly keep seen superclasses as seen\",\n",
        "                \"Value\": float(val_metrics[\"seen_super_acc\"]),\n",
        "            }\n",
        "        )\n",
        "        if \"seen_super_false_novel\" in val_metrics:\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"Split\": \"val\",\n",
        "                    \"Head\": \"super\",\n",
        "                    \"Metric\": \"Seen superclass false-novel rate\",\n",
        "                    \"Meaning\": \"Seen superclasses incorrectly flipped to novel\",\n",
        "                    \"Value\": float(val_metrics[\"seen_super_false_novel\"]),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    if \"novel_super_acc\" in val_metrics:\n",
        "        rows.append(\n",
        "            {\n",
        "                \"Split\": \"val\",\n",
        "                \"Head\": \"super\",\n",
        "                \"Metric\": \"Novel superclass accuracy (CIFAR)\",\n",
        "                \"Meaning\": \"CIFAR novel-super samples correctly predicted as novel\",\n",
        "                \"Value\": float(val_metrics[\"novel_super_acc\"]),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    # Subclass (val) — ONLY seen-subclass metrics\n",
        "    if \"seen_sub_acc\" in val_metrics:\n",
        "        rows.append(\n",
        "            {\n",
        "                \"Split\": \"val\",\n",
        "                \"Head\": \"sub\",\n",
        "                \"Metric\": \"Seen subclass accuracy\",\n",
        "                \"Meaning\": \"Correctly keep seen subclasses as seen\",\n",
        "                \"Value\": float(val_metrics[\"seen_sub_acc\"]),\n",
        "            }\n",
        "        )\n",
        "        if \"seen_sub_false_novel\" in val_metrics:\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"Split\": \"val\",\n",
        "                    \"Head\": \"sub\",\n",
        "                    \"Metric\": \"Seen subclass false-novel rate\",\n",
        "                    \"Meaning\": \"Seen subclasses incorrectly flipped to novel\",\n",
        "                    \"Value\": float(val_metrics[\"seen_sub_false_novel\"]),\n",
        "                }\n",
        "            )\n",
        "    # NOTE: we deliberately do NOT add a \"novel subclass accuracy\" row here.\n",
        "\n",
        "    # --- Pseudo-novel subclass stats (held-out subclasses) ---\n",
        "    pseudo_metrics = {}\n",
        "    if include_pseudo and pseudo_novel_loader is not None and mode in (\"two_heads\", \"sub_single_head\"):\n",
        "        pseudo_metrics = evaluate_pseudo_novel_sub_with_novelty(\n",
        "            model,\n",
        "            mode=mode,\n",
        "            tau_sub=tau_sub,\n",
        "            loader=pseudo_novel_loader,\n",
        "            name=\"pseudo_novel_sub\",\n",
        "        )\n",
        "\n",
        "        if \"pseudo_novel_sub_novel_rate\" in pseudo_metrics:\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"Split\": \"pseudo_novel\",\n",
        "                    \"Head\": \"sub\",\n",
        "                    \"Metric\": \"Pseudo-novel marked as novel\",\n",
        "                    \"Meaning\": \"Held-out subclasses correctly flagged as novel\",\n",
        "                    \"Value\": float(pseudo_metrics[\"pseudo_novel_sub_novel_rate\"]),\n",
        "                }\n",
        "            )\n",
        "        if \"pseudo_novel_sub_false_seen\" in pseudo_metrics:\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"Split\": \"pseudo_novel\",\n",
        "                    \"Head\": \"sub\",\n",
        "                    \"Metric\": \"Pseudo-novel mapped to seen\",\n",
        "                    \"Meaning\": \"Held-out subclasses wrongly mapped to some seen subclass\",\n",
        "                    \"Value\": float(pseudo_metrics[\"pseudo_novel_sub_false_seen\"]),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    # --- Config / settings summary (for *printing* only) ---\n",
        "    config_rows = [\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"BACKBONE\",\n",
        "            \"Meaning\": \"Feature extractor (e.g. resnet18 / resnet50)\",\n",
        "            \"Value\": BACKBONE,\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"TAU_SUPER\",\n",
        "            \"Meaning\": \"Novelty threshold for superclass head\",\n",
        "            \"Value\": str(tau_super),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"TAU_SUB\",\n",
        "            \"Meaning\": \"Novelty threshold for subclass head\",\n",
        "            \"Value\": str(tau_sub),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"CIFAR_NOVEL_MODE\",\n",
        "            \"Meaning\": \"Extra novel-super CIFAR data mode\",\n",
        "            \"Value\": str(CIFAR_NOVEL_MODE),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"FINE_TUNE_MODE\",\n",
        "            \"Meaning\": \"Backbone training mode (full vs frozen)\",\n",
        "            \"Value\": str(FINE_TUNE_MODE),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"APPROACH\",\n",
        "            \"Meaning\": \"Model architecture (two_heads vs two_models)\",\n",
        "            \"Value\": str(APPROACH),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"USE_PSEUDO_NOVEL\",\n",
        "            \"Meaning\": \"Using held-out subclasses for pseudo-novel eval\",\n",
        "            \"Value\": str(bool(USE_PSEUDO_NOVEL)),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"DATA_AUGMENT\",\n",
        "            \"Meaning\": \"Whether data augmentation is enabled for training\",\n",
        "            \"Value\": str(bool(DATA_AUGMENT)),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    rows.extend(config_rows)\n",
        "\n",
        "    if not rows:\n",
        "        print(\"No metrics to display in dashboard.\")\n",
        "        return None\n",
        "\n",
        "    dashboard_df = pd.DataFrame(rows)\n",
        "    dashboard_df = dashboard_df.sort_values(by=[\"Split\", \"Head\", \"Metric\"]).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n==== Novelty Dashboard ====\")\n",
        "    print(dashboard_df)\n",
        "\n",
        "    # --- Log to W&B: metrics only, numeric Value column ---\n",
        "    if USE_WANDB:\n",
        "        try:\n",
        "            wandb_table_df = dashboard_df.copy()\n",
        "\n",
        "            def _to_str(v):\n",
        "                if isinstance(v, float):\n",
        "                    return f\"{v:.6f}\"\n",
        "                return str(v)\n",
        "\n",
        "            wandb_table_df[\"Split\"] = wandb_table_df[\"Split\"].astype(str)\n",
        "            wandb_table_df[\"Head\"] = wandb_table_df[\"Head\"].astype(str)\n",
        "            wandb_table_df[\"Metric\"] = wandb_table_df[\"Metric\"].astype(str)\n",
        "            wandb_table_df[\"Meaning\"] = wandb_table_df[\"Meaning\"].astype(str)\n",
        "            wandb_table_df[\"Value\"] = wandb_table_df[\"Value\"].apply(_to_str)\n",
        "\n",
        "            wandb.log({\"novelty_dashboard\": wandb.Table(dataframe=wandb_table_df)})\n",
        "        except Exception as e:\n",
        "            print(\"Could not log dashboard table to W&B:\", e)\n",
        "\n",
        "    return dashboard_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVHcWqkOdomF"
      },
      "outputs": [],
      "source": [
        "# Helper to choose backbone (freeze or full) and choose optimizer parameter\n",
        "\n",
        "\n",
        "def setup_backbone_training(model, fine_tune_mode=\"full\", lr_full=1e-4, lr_head=1e-3):\n",
        "    \"\"\"\n",
        "    Given a model with attributes:\n",
        "        - model.backbone  (all feature extractor layers)\n",
        "        - head layers (e.g. super/sub heads) as other modules,\n",
        "    freeze or unfreeze the backbone and return an optimizer.\n",
        "\n",
        "    Returns:\n",
        "        optimizer, effective_lr\n",
        "    \"\"\"\n",
        "    if fine_tune_mode == \"full\":\n",
        "        # Everything trainable\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "        trainable_params = model.parameters()\n",
        "        lr = lr_full\n",
        "    elif fine_tune_mode == \"frozen\":\n",
        "        # Freeze backbone, train only heads\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = False\n",
        "        # Only parameters that still require grad will be optimized\n",
        "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "        lr = lr_head\n",
        "        print(f\"Freezing backbone; training {len(trainable_params)} parameter tensors in heads only.\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown FINE_TUNE_MODE: {fine_tune_mode}\")\n",
        "\n",
        "    optimizer = optim.Adam(trainable_params, lr=lr, weight_decay=WEIGHT_DECAY)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpvDqfhKRKQ7"
      },
      "source": [
        "# SECTION 6: Approach A: Shared backbone, two heads + KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxn7j1w1RRJk",
        "outputId": "9b4541f7-fa86-4752-ed21-8803ab6ed473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads training in this cell.\n"
          ]
        }
      ],
      "source": [
        "# Original idea\n",
        "\n",
        "LR = 1e-4  # maybe two different learning rates\n",
        "ALPHA_KL = 0.1\n",
        "TEMPERATURE = 1.0\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = setup_backbone_training(\n",
        "        model_two_heads,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_two_heads = None\n",
        "    if USE_WANDB:\n",
        "        run_two_heads = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_heads_kl_resnet\"),\n",
        "            group=\"two_heads\",  # to group/filter all two_heads runs\n",
        "            config={\n",
        "                \"approach\": \"two_heads_kl\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"alpha_kl\": ALPHA_KL,\n",
        "                \"temperature\": TEMPERATURE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_score = 0.0\n",
        "\n",
        "    print(\"Training shared-backbone two-heads model (KL-coupled):\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_two_heads,\n",
        "            optimizer,\n",
        "            train_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_two_heads,\n",
        "            val_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_acc_super = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        val_acc_sub = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        val_loss = val_metrics[\"val_loss\"]\n",
        "\n",
        "        print(\n",
        "            f\"[Two-heads] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_loss:.4f}, \"\n",
        "            f\"val_acc_super={val_acc_super:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc_sub:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            # prefix metrics so they don't collide with two-model ones\n",
        "            log_dict = {\n",
        "                \"epoch\": epoch,\n",
        "                \"two_heads_train_loss\": train_metrics[\"loss\"],\n",
        "                \"two_heads_val_loss\": val_loss,\n",
        "                \"two_heads_val_acc_super\": val_acc_super,\n",
        "                \"two_heads_val_acc_sub\": val_acc_sub,\n",
        "            }\n",
        "            wandb.log(log_dict, step=epoch)\n",
        "\n",
        "        # simple combined score: average of super/sub val accuracy\n",
        "        val_score = 0.5 * val_acc_super + 0.5 * val_acc_sub\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(\n",
        "                model_two_heads.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best two-heads model\")\n",
        "\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    analyze_tau_sub(model_two_heads, mode=\"two_heads\")\n",
        "    analyze_tau_super(model_two_heads, mode=\"two_heads\")\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_two_heads, mode=\"two_heads\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, loader=val_loader, name=\"val_two_heads\"\n",
        "    )\n",
        "    evaluate_pseudo_novel_sub_with_novelty(model_two_heads, mode=\"two_heads\", tau_sub=TAU_SUB)\n",
        "    novelty_dashboard(model_two_heads, mode=\"two_heads\", tau_super=TAU_SUPER, tau_sub=TAU_SUB)\n",
        "\n",
        "    if run_two_heads is not None:\n",
        "        run_two_heads.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads training in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNtlQWujRg4X"
      },
      "source": [
        "# SECTION 7: Approach B - Two separate models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RPa25bz6RlhN",
        "outputId": "99bce20c-e6c4-430c-ec42-41a19095224f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 236MB/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_172858-h41gamtl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/h41gamtl' target=\"_blank\">two_models_super_resnet_20251214_172858</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/h41gamtl' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/h41gamtl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training superclass model:\n",
            "[Super] Epoch 1: train_loss=0.1025, val_loss=0.0293, val_acc_super=0.9920\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 2: train_loss=0.0149, val_loss=0.0183, val_acc_super=0.9956\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 3: train_loss=0.0140, val_loss=0.0085, val_acc_super=0.9991\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 4: train_loss=0.0080, val_loss=0.0100, val_acc_super=0.9982\n",
            "[Super] Epoch 5: train_loss=0.0055, val_loss=0.0072, val_acc_super=0.9982\n",
            "[Super] Epoch 6: train_loss=0.0037, val_loss=0.0135, val_acc_super=0.9982\n",
            "[Super] Epoch 7: train_loss=0.0037, val_loss=0.0084, val_acc_super=0.9973\n",
            "[Super] Epoch 8: train_loss=0.0097, val_loss=0.0062, val_acc_super=0.9991\n",
            "[Super] Epoch 9: train_loss=0.0054, val_loss=0.0084, val_acc_super=0.9991\n",
            "[Super] Epoch 10: train_loss=0.0029, val_loss=0.0032, val_acc_super=0.9991\n",
            "[Super] Epoch 11: train_loss=0.0038, val_loss=0.0062, val_acc_super=0.9982\n",
            "[Super] Epoch 12: train_loss=0.0026, val_loss=0.0095, val_acc_super=0.9991\n",
            "[Super] Epoch 13: train_loss=0.0028, val_loss=0.0131, val_acc_super=0.9982\n",
            "[Super] Epoch 14: train_loss=0.0010, val_loss=0.0150, val_acc_super=0.9973\n",
            "[Super] Epoch 15: train_loss=0.0035, val_loss=0.0104, val_acc_super=0.9965\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>super_train_loss</td><td>█▂▂▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>super_val_acc</td><td>▁▅█▇▇▇▆███▇█▇▆▅</td></tr><tr><td>super_val_loss</td><td>█▅▂▃▂▄▂▂▂▁▂▃▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>super_train_loss</td><td>0.0035</td></tr><tr><td>super_val_acc</td><td>0.99645</td></tr><tr><td>super_val_loss</td><td>0.01041</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_super_resnet_20251214_172858</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/h41gamtl' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/h41gamtl</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_172858-h41gamtl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_173027-r234zg0j</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/r234zg0j' target=\"_blank\">two_models_sub_resnet_20251214_173027</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/r234zg0j' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/r234zg0j</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training subclass model:\n",
            "[Sub] Epoch 1: train_loss=1.3384, val_loss=0.3369, val_acc_sub=0.8998\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 2: train_loss=0.2614, val_loss=0.2578, val_acc_sub=0.9158\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 3: train_loss=0.1387, val_loss=0.1930, val_acc_sub=0.9397\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 4: train_loss=0.0993, val_loss=0.1894, val_acc_sub=0.9433\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 5: train_loss=0.0704, val_loss=0.1524, val_acc_sub=0.9504\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 6: train_loss=0.0730, val_loss=0.1722, val_acc_sub=0.9521\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 7: train_loss=0.0592, val_loss=0.1769, val_acc_sub=0.9468\n",
            "[Sub] Epoch 8: train_loss=0.0479, val_loss=0.1936, val_acc_sub=0.9406\n",
            "[Sub] Epoch 9: train_loss=0.0430, val_loss=0.1972, val_acc_sub=0.9468\n",
            "[Sub] Epoch 10: train_loss=0.0483, val_loss=0.2493, val_acc_sub=0.9335\n",
            "[Sub] Epoch 11: train_loss=0.0431, val_loss=0.1716, val_acc_sub=0.9450\n",
            "[Sub] Epoch 12: train_loss=0.0421, val_loss=0.1713, val_acc_sub=0.9477\n",
            "[Sub] Epoch 13: train_loss=0.0323, val_loss=0.1709, val_acc_sub=0.9512\n",
            "[Sub] Epoch 14: train_loss=0.0300, val_loss=0.2130, val_acc_sub=0.9450\n",
            "[Sub] Epoch 15: train_loss=0.0376, val_loss=0.1575, val_acc_sub=0.9654\n",
            "  Saved new best subclass model\n",
            "pseudo_novel_loader is None. Set USE_PSEUDO_NOVEL = True before building loaders to use this analysis.\n",
            "\n",
            "Seen superclasses (0/1/2) superclass max-prob stats:\n",
            "  count = 628\n",
            "  mean  = 0.995\n",
            "  std   = 0.028\n",
            "  percentiles:\n",
            "    p 1: 0.861\n",
            "    p 5: 0.987\n",
            "    p10: 0.996\n",
            "    p25: 0.999\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Novel superclasses (== NOVEL_SUPER_IDX) superclass max-prob stats:\n",
            "  count = 500\n",
            "  mean  = 1.000\n",
            "  std   = 0.000\n",
            "  percentiles:\n",
            "    p 1: 0.999\n",
            "    p 5: 0.999\n",
            "    p10: 0.999\n",
            "    p25: 1.000\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Suggested TAU_SUPER candidates (using seen + novel):\n",
            "  tau_super ≈ 10th percentile of seen:       0.996\n",
            "  tau_super ≈ 5th percentile of seen:        0.987\n",
            "  tau_super ≈ mean(seen) - std(seen):        0.967\n",
            "  tau_super ≈ mean(seen & novel) midpoint:   0.997\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged superclass histograms and tau_super candidates to Weights & Biases.\n",
            "\n",
            "=== Evaluation on val_super_only ===\n",
            "Overall superclass acc: 0.9654\n",
            "Seen superclass acc (true super != novel):   0.9379\n",
            "Seen superclass false-novel rate:            0.0621\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "=== Evaluation on val_sub_only ===\n",
            "Overall subclass acc:   0.9264\n",
            "Seen subclass acc (true sub != novel):       0.8678\n",
            "Seen subclass false-novel rate:              0.1322\n",
            "No pseudo_novel_loader available.\n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall superclass acc: 0.9654\n",
            "Seen superclass acc (true super != novel):   0.9379\n",
            "Seen superclass false-novel rate:            0.0621\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "     Split   Head                             Metric  \\\n",
            "0   config      -                           APPROACH   \n",
            "1   config      -                           BACKBONE   \n",
            "2   config      -                   CIFAR_NOVEL_MODE   \n",
            "3   config      -                       DATA_AUGMENT   \n",
            "4   config      -                     FINE_TUNE_MODE   \n",
            "5   config      -                            TAU_SUB   \n",
            "6   config      -                          TAU_SUPER   \n",
            "7   config      -                   USE_PSEUDO_NOVEL   \n",
            "8      val  super  Novel superclass accuracy (CIFAR)   \n",
            "9      val  super           Seen superclass accuracy   \n",
            "10     val  super   Seen superclass false-novel rate   \n",
            "\n",
            "                                              Meaning       Value  \n",
            "0        Model architecture (two_heads vs two_models)  two_models  \n",
            "1        Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                   Extra novel-super CIFAR data mode       large  \n",
            "3   Whether data augmentation is enabled for training        True  \n",
            "4             Backbone training mode (full vs frozen)        full  \n",
            "5                 Novelty threshold for subclass head        0.85  \n",
            "6               Novelty threshold for superclass head        0.99  \n",
            "7     Using held-out subclasses for pseudo-novel eval       False  \n",
            "8   CIFAR novel-super samples correctly predicted ...         1.0  \n",
            "9            Correctly keep seen superclasses as seen    0.937898  \n",
            "10     Seen superclasses incorrectly flipped to novel    0.062102  \n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall subclass acc:   0.9264\n",
            "Seen subclass acc (true sub != novel):       0.8678\n",
            "Seen subclass false-novel rate:              0.1322\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "    Split Head                          Metric  \\\n",
            "0  config    -                        APPROACH   \n",
            "1  config    -                        BACKBONE   \n",
            "2  config    -                CIFAR_NOVEL_MODE   \n",
            "3  config    -                    DATA_AUGMENT   \n",
            "4  config    -                  FINE_TUNE_MODE   \n",
            "5  config    -                         TAU_SUB   \n",
            "6  config    -                       TAU_SUPER   \n",
            "7  config    -                USE_PSEUDO_NOVEL   \n",
            "8     val  sub          Seen subclass accuracy   \n",
            "9     val  sub  Seen subclass false-novel rate   \n",
            "\n",
            "                                             Meaning       Value  \n",
            "0       Model architecture (two_heads vs two_models)  two_models  \n",
            "1       Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                  Extra novel-super CIFAR data mode       large  \n",
            "3  Whether data augmentation is enabled for training        True  \n",
            "4            Backbone training mode (full vs frozen)        full  \n",
            "5                Novelty threshold for subclass head        0.85  \n",
            "6              Novelty threshold for superclass head        0.99  \n",
            "7    Using held-out subclasses for pseudo-novel eval       False  \n",
            "8             Correctly keep seen subclasses as seen    0.867834  \n",
            "9       Seen subclasses incorrectly flipped to novel    0.132166  \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>sub_train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sub_val_acc</td><td>▁▃▅▆▆▇▆▅▆▅▆▆▆▆█</td></tr><tr><td>sub_val_loss</td><td>█▅▃▂▁▂▂▃▃▅▂▂▂▃▁</td></tr><tr><td>tau_super_candidate_1</td><td>▁</td></tr><tr><td>tau_super_candidate_2</td><td>▁</td></tr><tr><td>tau_super_candidate_3</td><td>▁</td></tr><tr><td>val_novel_super_acc</td><td>▁</td></tr><tr><td>val_overall_sub_acc</td><td>▁</td></tr><tr><td>val_overall_super_acc</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>sub_train_loss</td><td>0.03765</td></tr><tr><td>sub_val_acc</td><td>0.96543</td></tr><tr><td>sub_val_loss</td><td>0.15753</td></tr><tr><td>tau_super_candidate_1</td><td>0.99621</td></tr><tr><td>tau_super_candidate_2</td><td>0.98662</td></tr><tr><td>tau_super_candidate_3</td><td>0.96741</td></tr><tr><td>val_novel_super_acc</td><td>1</td></tr><tr><td>val_overall_sub_acc</td><td>0.92642</td></tr><tr><td>val_overall_super_acc</td><td>0.96543</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_sub_resnet_20251214_173027</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/r234zg0j' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/r234zg0j</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_173027-r234zg0j/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Second idea to compare\n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "if APPROACH == \"two_models\":\n",
        "    # Superclass model\n",
        "    model_super = SingleHeadModel(num_classes=num_super).to(device)\n",
        "    criterion_super = nn.CrossEntropyLoss()\n",
        "    optimizer_super = setup_backbone_training(\n",
        "        model_super,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_super = None\n",
        "    if USE_WANDB:\n",
        "        run_super = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_super_resnet\"),\n",
        "            group=\"two_models\",  # to filter all two_models runs together\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"super\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_super = 0.0\n",
        "\n",
        "    print(\"Training superclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_super,\n",
        "            optimizer_super,\n",
        "            train_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_super,\n",
        "            val_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        print(\n",
        "            f\"[Super] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_super={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"super_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"super_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"super_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_super:\n",
        "            best_val_super = val_acc\n",
        "            torch.save(\n",
        "                model_super.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_super_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best superclass model\")\n",
        "\n",
        "    if run_super is not None:\n",
        "        run_super.finish()\n",
        "\n",
        "    # Subclass model\n",
        "    model_sub = SingleHeadModel(num_classes=num_sub).to(device)\n",
        "    criterion_sub = nn.CrossEntropyLoss()\n",
        "    optimizer_sub = setup_backbone_training(\n",
        "        model_sub,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_sub = None\n",
        "    if USE_WANDB:\n",
        "        run_sub = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_sub_resnet\"),\n",
        "            group=\"two_models\",\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"sub\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_sub = 0.0\n",
        "\n",
        "    print(\"\\nTraining subclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_sub,\n",
        "            optimizer_sub,\n",
        "            train_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_sub,\n",
        "            val_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        print(\n",
        "            f\"[Sub] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"sub_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"sub_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"sub_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_sub:\n",
        "            best_val_sub = val_acc\n",
        "            torch.save(\n",
        "                model_sub.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_sub_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best subclass model\")\n",
        "\n",
        "    best_super_path = os.path.join(DATA_ROOT, \"best_super_model.pth\")\n",
        "    best_sub_path = os.path.join(DATA_ROOT, \"best_sub_model.pth\")\n",
        "    model_super.load_state_dict(torch.load(best_super_path, map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(best_sub_path, map_location=device))\n",
        "\n",
        "    analyze_tau_sub(model_sub, mode=\"sub_single_head\")\n",
        "    analyze_tau_super(model_super, mode=\"super_single_head\")\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_super,\n",
        "        mode=\"super_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        loader=val_loader,\n",
        "        name=\"val_super_only\",\n",
        "    )\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_sub, mode=\"sub_single_head\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, loader=val_loader, name=\"val_sub_only\"\n",
        "    )\n",
        "    evaluate_pseudo_novel_sub_with_novelty(model_sub, mode=\"sub_single_head\", tau_sub=TAU_SUB)\n",
        "    novelty_dashboard(\n",
        "        model_super, mode=\"super_single_head\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, include_pseudo=False\n",
        "    )  # no pseudo-novel meaning for super head\n",
        "    novelty_dashboard(model_sub, mode=\"sub_single_head\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, include_pseudo=True)\n",
        "\n",
        "    if run_sub is not None:\n",
        "        run_sub.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-model training in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZTFepgRxey"
      },
      "source": [
        "# SECTION 8: Test-time Inference & CSV Export for leaderboard **(two-head model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_69xbINR2w6",
        "outputId": "0d260e6f-bd77-4fb7-8b0c-7e2216519b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\n"
          ]
        }
      ],
      "source": [
        "# Inference in order to predict \"novel\" superclass / subclasses\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_test_two_heads(model, test_loader, tau_super=TAU_SUPER, tau_sub=TAU_SUB):\n",
        "    \"\"\"\n",
        "    Inference for the two-heads model with novelty thresholds.\n",
        "\n",
        "    model:       SharedBackboneTwoHeads(...)\n",
        "    test_loader: DataLoader yielding (images, img_names)\n",
        "    tau_super:   threshold for superclass novelty\n",
        "    tau_sub:     threshold for subclass novelty\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    images_list = []\n",
        "    super_preds = []\n",
        "    sub_preds = []\n",
        "\n",
        "    for images, img_names in test_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "\n",
        "        # Forward pass once\n",
        "        super_logits, sub_logits = model(images)  # (B, num_super), (B, num_sub)\n",
        "\n",
        "        # --- Superclass predictions with novelty ---\n",
        "        super_probs = F.softmax(super_logits, dim=1)  # (B, num_super)\n",
        "        max_super_probs, super_idx = super_probs.max(dim=1)  # (B,)\n",
        "        super_novel_mask = max_super_probs < tau_super\n",
        "        super_idx = super_idx.clone()\n",
        "        super_idx[super_novel_mask] = NOVEL_SUPER_IDX\n",
        "\n",
        "        # --- Subclass predictions with novelty ---\n",
        "        sub_probs = F.softmax(sub_logits, dim=1)  # (B, num_sub)\n",
        "        max_sub_probs, sub_idx = sub_probs.max(dim=1)  # (B,)\n",
        "        sub_novel_mask = max_sub_probs < tau_sub\n",
        "        sub_idx = sub_idx.clone()\n",
        "        sub_idx[sub_novel_mask] = NOVEL_SUB_IDX\n",
        "\n",
        "        # Move to CPU as plain Python ints\n",
        "        super_idx = super_idx.cpu().tolist()\n",
        "        sub_idx = sub_idx.cpu().tolist()\n",
        "\n",
        "        # img_names is a list of filenames (len = B)\n",
        "        images_list.extend(img_names)\n",
        "        super_preds.extend(super_idx)\n",
        "        sub_preds.extend(sub_idx)\n",
        "\n",
        "    df = pd.DataFrame({\"image\": images_list, \"superclass_index\": super_preds, \"subclass_index\": sub_preds})\n",
        "    return df\n",
        "\n",
        "\n",
        "# SECTION: Test-time inference & CSV export for two-heads model\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    # Recreate the model and load best checkpoint\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    test_predictions = predict_test_two_heads(\n",
        "        model_two_heads,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_heads_predictions.csv\")\n",
        "    test_predictions.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-heads predictions (with novelty) to:\", out_csv_path)\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPpeqduiLv5"
      },
      "source": [
        "# SECTION 9: Test-time Inference & CSV Export for leaderboard **(two separate models)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWEswAdKijVa",
        "outputId": "1edff7e8-38af-478d-d4b0-c302bc981e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved two-model predictions (with novelty) to: /content/drive/MyDrive/NNDL-Project/Project Data/two_models_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def predict_test_two_models(model_super, model_sub, test_loader, tau_super=TAU_SUPER, tau_sub=TAU_SUB):\n",
        "    \"\"\"\n",
        "    Inference for the two-model setup (separate super + sub models) with novelty thresholds.\n",
        "\n",
        "    model_super: SingleHeadModel for superclass (num_classes = num_super)\n",
        "    model_sub:   SingleHeadModel for subclass  (num_classes = num_sub)\n",
        "    test_loader: DataLoader yielding (images, img_names)\n",
        "    tau_super:   threshold for superclass novelty\n",
        "    tau_sub:     threshold for subclass novelty\n",
        "    \"\"\"\n",
        "\n",
        "    model_super.eval()\n",
        "    model_sub.eval()\n",
        "\n",
        "    images_list = []\n",
        "    super_preds = []\n",
        "    sub_preds = []\n",
        "\n",
        "    for images, img_names in test_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "\n",
        "        # Forward passes\n",
        "        super_logits = model_super(images)  # (B, num_super)\n",
        "        sub_logits = model_sub(images)  # (B, num_sub)\n",
        "\n",
        "        # --- Superclass predictions with novelty ---\n",
        "        super_probs = F.softmax(super_logits, dim=1)  # (B, num_super)\n",
        "        max_super_probs, super_idx = super_probs.max(dim=1)  # (B,)\n",
        "        super_novel_mask = max_super_probs < tau_super\n",
        "        super_idx = super_idx.clone()\n",
        "        super_idx[super_novel_mask] = NOVEL_SUPER_IDX\n",
        "\n",
        "        # --- Subclass predictions with novelty ---\n",
        "        sub_probs = F.softmax(sub_logits, dim=1)  # (B, num_sub)\n",
        "        max_sub_probs, sub_idx = sub_probs.max(dim=1)  # (B,)\n",
        "        sub_novel_mask = max_sub_probs < tau_sub\n",
        "        sub_idx = sub_idx.clone()\n",
        "        sub_idx[sub_novel_mask] = NOVEL_SUB_IDX\n",
        "\n",
        "        # Move indices to CPU as plain Python ints\n",
        "        super_idx = super_idx.cpu().tolist()\n",
        "        sub_idx = sub_idx.cpu().tolist()\n",
        "\n",
        "        # img_names is a list of filenames (len = B)\n",
        "        images_list.extend(img_names)\n",
        "        super_preds.extend(super_idx)\n",
        "        sub_preds.extend(sub_idx)\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        {\n",
        "            \"image\": images_list,\n",
        "            \"superclass_index\": super_preds,\n",
        "            \"subclass_index\": sub_preds,\n",
        "        }\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "if APPROACH == \"two_models\":\n",
        "    model_super = SingleHeadModel(num_classes=num_super).to(device)\n",
        "    model_sub = SingleHeadModel(num_classes=num_sub).to(device)\n",
        "\n",
        "    model_super.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_super_model.pth\"), map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_sub_model.pth\"), map_location=device))\n",
        "\n",
        "    test_predictions_two_models = predict_test_two_models(\n",
        "        model_super,\n",
        "        model_sub,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_models_predictions.csv\")\n",
        "    test_predictions_two_models.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-model predictions (with novelty) to:\", out_csv_path)\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-models inference in this cell.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kret_312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
