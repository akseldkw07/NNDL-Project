{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_5aFAaALeLW"
      },
      "source": [
        "# SECTION 1: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85tMtuD924rr",
        "outputId": "a8ff2421-ec14-4751-f710-56f625a786ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Fri Dec 12 21:05:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   30C    P0             51W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcm4521\u001b[0m (\u001b[33mnndl-project-F25\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi  # just to sanity-check the GPU\n",
        "\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "\n",
        "USE_WANDB = True\n",
        "WANDB_ENTITY = \"nndl-project-F25\"\n",
        "WANDB_PROJECT = \"Multihead-Classification-Competition\"\n",
        "\n",
        "if USE_WANDB:\n",
        "  wandb.login()\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import os, zipfile, random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# wandb run-naming schema\n",
        "def make_run_name(base: str) -> str:\n",
        "    \"\"\"Create a unique run name with timestamp.\"\"\"\n",
        "    return f\"{base}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "# optional: for approximate reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from constants import *\n",
        "from evaluation_utils import *\n",
        "from inference import *\n",
        "from models import *\n",
        "from resnet_pretrain import *\n",
        "from training_utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxiTY5skLo7b"
      },
      "source": [
        "# SECTION 2: Config & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04GRyoqmIVed"
      },
      "outputs": [],
      "source": [
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "\n",
        "train_zip_path = os.path.join(DATA_ROOT, \"train_images.zip\")\n",
        "test_zip_path = os.path.join(DATA_ROOT, \"test_images.zip\")\n",
        "\n",
        "# Unzip to LOCAL_DATA_ROOT instead of Drive\n",
        "train_out_dir = os.path.join(LOCAL_DATA_ROOT, \"train_images\")\n",
        "test_out_dir = os.path.join(LOCAL_DATA_ROOT, \"test_images\")\n",
        "if not os.path.exists(train_out_dir):\n",
        "    os.makedirs(train_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(train_zip_path, \"r\") as z:\n",
        "        z.extractall(train_out_dir)\n",
        "\n",
        "if not os.path.exists(test_out_dir):\n",
        "    os.makedirs(test_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(test_zip_path, \"r\") as z:\n",
        "        z.extractall(test_out_dir)\n",
        "\n",
        "\n",
        "TRAIN_IMG_DIR = os.path.join(train_out_dir, \"train_images\")\n",
        "TEST_IMG_DIR = os.path.join(test_out_dir, \"test_images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stQpD0L1ggNX",
        "outputId": "69007633-c6f9-43ad-8565-1f82ae555bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building CIFAR novel-super dataset (this happens once)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169M/169M [00:05<00:00, 29.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total candidate CIFAR images (allowed classes, excl. reptiles): 45000\n",
            "Selected indices: 5000\n",
            "Saved CIFAR novel-super metadata to: /content/local_data/cifar_novel_data.csv\n",
            "Images copied into TRAIN_IMG_DIR: /content/local_data/train_images/train_images\n"
          ]
        }
      ],
      "source": [
        "# Build CIFAR-100 novel-super dataset (excluding reptiles)\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "# Download CIFAR100 once (raw PIL images)\n",
        "CIFAR_ROOT = os.path.join(LOCAL_DATA_ROOT, \"cifar100_raw\")\n",
        "os.makedirs(CIFAR_ROOT, exist_ok=True)\n",
        "\n",
        "# Only do the heavy image-copying if CSV doesn't exist\n",
        "if CIFAR_NOVEL_MODE != \"none\" and not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "    print(\"Building CIFAR novel-super dataset (this happens once)...\")\n",
        "\n",
        "    cifar_train = CIFAR100(root=CIFAR_ROOT, train=True, download=True, transform=None)\n",
        "\n",
        "    # CIFAR-100 fine label names (with underscores)\n",
        "    cifar_fine_names = cifar_train.classes  # e.g. \"apple\", \"beaver\", \"aquarium_fish\", ...\n",
        "\n",
        "    # Fine classes we want, based on your list, excluding reptiles\n",
        "    # (these names match CIFAR-100 fine label names)\n",
        "    allowed_fine_names = set(\n",
        "        [\n",
        "            # aquatic mammals\n",
        "            \"beaver\",\n",
        "            \"dolphin\",\n",
        "            \"otter\",\n",
        "            \"seal\",\n",
        "            \"whale\",\n",
        "            # fish\n",
        "            \"aquarium_fish\",\n",
        "            \"flatfish\",\n",
        "            \"ray\",\n",
        "            \"shark\",\n",
        "            \"trout\",\n",
        "            # flowers\n",
        "            \"orchid\",\n",
        "            \"poppy\",\n",
        "            \"rose\",\n",
        "            \"sunflower\",\n",
        "            \"tulip\",\n",
        "            # food containers\n",
        "            \"bottle\",\n",
        "            \"bowl\",\n",
        "            \"can\",\n",
        "            \"cup\",\n",
        "            \"plate\",\n",
        "            # fruit and vegetables\n",
        "            \"apple\",\n",
        "            \"mushroom\",\n",
        "            \"orange\",\n",
        "            \"pear\",\n",
        "            \"sweet_pepper\",\n",
        "            # household electrical devices\n",
        "            \"clock\",\n",
        "            \"keyboard\",\n",
        "            \"lamp\",\n",
        "            \"telephone\",\n",
        "            \"television\",\n",
        "            # household furniture\n",
        "            \"bed\",\n",
        "            \"chair\",\n",
        "            \"couch\",\n",
        "            \"table\",\n",
        "            \"wardrobe\",\n",
        "            # insects\n",
        "            \"bee\",\n",
        "            \"beetle\",\n",
        "            \"butterfly\",\n",
        "            \"caterpillar\",\n",
        "            \"cockroach\",\n",
        "            # large carnivores\n",
        "            \"bear\",\n",
        "            \"leopard\",\n",
        "            \"lion\",\n",
        "            \"tiger\",\n",
        "            \"wolf\",\n",
        "            # large man-made outdoor things\n",
        "            \"bridge\",\n",
        "            \"castle\",\n",
        "            \"house\",\n",
        "            \"road\",\n",
        "            \"skyscraper\",\n",
        "            # large natural outdoor scenes\n",
        "            \"cloud\",\n",
        "            \"forest\",\n",
        "            \"mountain\",\n",
        "            \"plain\",\n",
        "            \"sea\",\n",
        "            # large omnivores and herbivores\n",
        "            \"camel\",\n",
        "            \"cattle\",\n",
        "            \"chimpanzee\",\n",
        "            \"elephant\",\n",
        "            \"kangaroo\",\n",
        "            # medium-sized mammals\n",
        "            \"fox\",\n",
        "            \"porcupine\",\n",
        "            \"possum\",\n",
        "            \"raccoon\",\n",
        "            \"skunk\",\n",
        "            # non-insect invertebrates\n",
        "            \"crab\",\n",
        "            \"lobster\",\n",
        "            \"snail\",\n",
        "            \"spider\",\n",
        "            \"worm\",\n",
        "            # people\n",
        "            \"baby\",\n",
        "            \"boy\",\n",
        "            \"girl\",\n",
        "            \"man\",\n",
        "            \"woman\",\n",
        "            # small mammals\n",
        "            \"hamster\",\n",
        "            \"mouse\",\n",
        "            \"rabbit\",\n",
        "            \"shrew\",\n",
        "            \"squirrel\",\n",
        "            # trees\n",
        "            \"maple\",\n",
        "            \"oak\",\n",
        "            \"palm\",\n",
        "            \"pine\",\n",
        "            \"willow\",\n",
        "            # vehicles 1\n",
        "            \"bicycle\",\n",
        "            \"bus\",\n",
        "            \"motorcycle\",\n",
        "            \"pickup_truck\",\n",
        "            \"train\",\n",
        "            # vehicles 2\n",
        "            \"lawn_mower\",\n",
        "            \"rocket\",\n",
        "            \"streetcar\",\n",
        "            \"tank\",\n",
        "            \"tractor\",\n",
        "            # NOTE: reptiles group (\"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\") is *excluded* on purpose\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Map class_name -> list of indices for that fine class\n",
        "    name_to_indices = {name: [] for name in allowed_fine_names}\n",
        "    for idx in range(len(cifar_train)):\n",
        "        _, fine_label = cifar_train[idx]  # fine_label is int index into cifar_fine_names\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "        if fine_name in allowed_fine_names:\n",
        "            name_to_indices[fine_name].append(idx)\n",
        "\n",
        "    # Flatten candidate indices across all allowed classes\n",
        "    candidate_indices = []\n",
        "    for name, idx_list in name_to_indices.items():\n",
        "        candidate_indices.extend(idx_list)\n",
        "\n",
        "    print(\"Total candidate CIFAR images (allowed classes, excl. reptiles):\", len(candidate_indices))\n",
        "\n",
        "    # Target total novel-super samples (max 5000, as you requested)\n",
        "    TARGET_TOTAL = 5000\n",
        "    random.seed(42)\n",
        "    random.shuffle(candidate_indices)\n",
        "    selected_indices = candidate_indices[:TARGET_TOTAL]\n",
        "\n",
        "    print(\"Selected indices:\", len(selected_indices))\n",
        "\n",
        "    # Copy images into TRAIN_IMG_DIR and build CSV rows\n",
        "    cifar_aug_records = []\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        img, fine_label = cifar_train[idx]\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "\n",
        "        # Unique filename to avoid collisions\n",
        "        fname = f\"cifar_novel_{idx}_{fine_name}.png\"\n",
        "        dst_path = os.path.join(TRAIN_IMG_DIR, fname)\n",
        "\n",
        "        # img is PIL.Image when transform=None\n",
        "        img.save(dst_path)\n",
        "\n",
        "        record = {\n",
        "            \"image\": fname,\n",
        "            \"superclass_index\": NOVEL_SUPER_IDX,  # novel superclass\n",
        "            \"subclass_index\": NOVEL_SUB_IDX,  # novel subclass\n",
        "            \"description\": f\"CIFAR100:{fine_name} (novel superclass)\",\n",
        "        }\n",
        "        cifar_aug_records.append(record)\n",
        "\n",
        "    cifar_aug_df = pd.DataFrame(cifar_aug_records)\n",
        "    cifar_aug_df.to_csv(CIFAR_NOVEL_CSV_PATH, index=False)\n",
        "    print(\"Saved CIFAR novel-super metadata to:\", CIFAR_NOVEL_CSV_PATH)\n",
        "    print(\"Images copied into TRAIN_IMG_DIR:\", TRAIN_IMG_DIR)\n",
        "\n",
        "elif CIFAR_NOVEL_MODE != \"none\":\n",
        "    print(\"CIFAR novel-super CSV already exists at:\", CIFAR_NOVEL_CSV_PATH)\n",
        "else:\n",
        "    print(\"CIFAR_NOVEL_MODE='none'; skipping CIFAR novel-super creation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NzoPU6L0kE"
      },
      "source": [
        "# SECTION 3: Data Loading & DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1DTM3ycL7_-",
        "outputId": "d47edd42-8294-4dee-8b0c-1ba8ddf35d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num superclasses: 4\n",
            "Num subclasses: 88\n",
            "CIFAR_NOVEL_MODE='large' → using 5000 CIFAR novel-super samples.\n",
            "Combined train_df size (original + CIFAR): 11288\n",
            "  Novel-super count (superclass_index == NOVEL_SUPER_IDX): 5000\n",
            "Example sub_to_super mapping (first 10): {0: 1, 1: 2, 2: 1, 3: 2, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 1}\n"
          ]
        }
      ],
      "source": [
        "# SECTION 3: Data Loading & Dataloaders\n",
        "\n",
        "# Base training data from class\n",
        "base_train_df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "super_map_df = pd.read_csv(SUPER_CSV)  # columns: index, class\n",
        "sub_map_df = pd.read_csv(SUB_CSV)  # columns: index, class\n",
        "\n",
        "num_super = len(super_map_df)\n",
        "num_sub = len(sub_map_df)\n",
        "\n",
        "print(\"Num superclasses:\", num_super)\n",
        "print(\"Num subclasses:\", num_sub)\n",
        "\n",
        "# --- Integrate CIFAR novel-super examples, if enabled ---\n",
        "\n",
        "if CIFAR_NOVEL_MODE == \"none\":\n",
        "    train_df = base_train_df.copy()\n",
        "    print(\"CIFAR_NOVEL_MODE='none' → using only original training data.\")\n",
        "else:\n",
        "    if not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"CIFAR_NOVEL_MODE={CIFAR_NOVEL_MODE} but {CIFAR_NOVEL_CSV_PATH} not found. \"\n",
        "            \"Run the CIFAR novel-super build section first.\"\n",
        "        )\n",
        "\n",
        "    cifar_aug_df = pd.read_csv(CIFAR_NOVEL_CSV_PATH)\n",
        "\n",
        "    if CIFAR_NOVEL_MODE == \"small\":\n",
        "        # Use ~1000 CIFAR novel-super images\n",
        "        n_small = min(1000, len(cifar_aug_df))\n",
        "        cifar_aug_df = cifar_aug_df.sample(n=n_small, random_state=42).reset_index(drop=True)\n",
        "        print(f\"CIFAR_NOVEL_MODE='small' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    elif CIFAR_NOVEL_MODE == \"large\":\n",
        "        # Use all available (up to 5000 created earlier)\n",
        "        print(f\"CIFAR_NOVEL_MODE='large' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown CIFAR_NOVEL_MODE: {CIFAR_NOVEL_MODE}\")\n",
        "\n",
        "    # Combine original training data with CIFAR novel-super rows\n",
        "    train_df = pd.concat([base_train_df, cifar_aug_df], ignore_index=True)\n",
        "    print(\"Combined train_df size (original + CIFAR):\", len(train_df))\n",
        "    print(\n",
        "        \"  Novel-super count (superclass_index == NOVEL_SUPER_IDX):\",\n",
        "        (train_df[\"superclass_index\"] == NOVEL_SUPER_IDX).sum(),\n",
        "    )\n",
        "\n",
        "# --- Build subclass -> superclass mapping from *combined* train_df ---\n",
        "# This still satisfies “each subclass has a single superclass”:\n",
        "#  - Original subclasses 0..86\n",
        "#  - Novel subclass 87 always maps to NOVEL_SUPER_IDX\n",
        "sub_to_super = train_df.groupby(\"subclass_index\")[\"superclass_index\"].agg(lambda x: x.value_counts().index[0]).to_dict()\n",
        "\n",
        "print(\"Example sub_to_super mapping (first 10):\", dict(list(sub_to_super.items())[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdqaByetMJR9"
      },
      "outputs": [],
      "source": [
        "# Dataset functions\n",
        "class BirdDogReptileDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_name = row[\"image\"]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        super_idx = int(row[\"superclass_index\"])\n",
        "        sub_idx = int(row[\"subclass_index\"])\n",
        "        return image, super_idx, sub_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydp5kOpbMWTc"
      },
      "outputs": [],
      "source": [
        "# Test dataset (for leaderboard predictions)\n",
        "\n",
        "\n",
        "class BirdDogReptileTestDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        # assumes images are named 0.jpg, 1.jpg, ..., N-1.jpg\n",
        "        self.filenames = sorted(os.listdir(img_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.filenames[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcWn_qDgMcIa"
      },
      "outputs": [],
      "source": [
        "# Transforms\n",
        "\n",
        "if DATA_AUGMENT:\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "else:\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "val_test_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_xpuCQFMf6X",
        "outputId": "28bde91a-f161-4c30-b553-c4dad0331af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Simple split, novel-super aware]\n",
            "  Seen-super samples: 6288\n",
            "  Novel-super samples: 5000\n",
            "  Final split sizes:\n",
            "    train: 10160\n",
            "    val:   1128\n",
            "    train novel-super: 4500\n",
            "    val novel-super:   500\n",
            "[Simple split] Train size: 10160, Val size: 1128\n",
            "Test size: 11180\n"
          ]
        }
      ],
      "source": [
        "# Train/val split + loaders with optional pseudo-novel validation,\n",
        "# ensuring novel-super examples (super == NOVEL_SUPER_IDX) appear in both train and val.\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "pseudo_novel_loader = None  # default; will be set if USE_PSEUDO_NOVEL\n",
        "heldout_subclasses = None  # to inspect later if needed\n",
        "\n",
        "\n",
        "if not USE_PSEUDO_NOVEL:\n",
        "    # -------------------------\n",
        "    # Simple split, but novel-super-aware\n",
        "    # -------------------------\n",
        "    print(\"[Simple split, novel-super aware]\")\n",
        "\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(  # type: ignore\n",
        "        train_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=42,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(f\"[Simple split] Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
        "\n",
        "else:\n",
        "    # -------------------------\n",
        "    # Pseudo-novel setup: hold out some subclasses entirely for pseudo-novel validation\n",
        "    # while still keeping novel-super in both train and val.\n",
        "    # -------------------------\n",
        "\n",
        "    print(\"[Pseudo-novel subclass split + novel-super-aware train/val]\")\n",
        "\n",
        "    # 1) choose subset of subclasses to treat as pseudo-novel\n",
        "    all_subclasses = sorted(train_df[\"subclass_index\"].unique())\n",
        "    # Do NOT hold out the novel subclass itself (87)\n",
        "    all_subclasses_no_novel = [c for c in all_subclasses if c != NOVEL_SUB_IDX]\n",
        "\n",
        "    rng = np.random.default_rng(PSEUDO_NOVEL_SEED)\n",
        "\n",
        "    num_holdout = max(1, int(len(all_subclasses_no_novel) * PSEUDO_NOVEL_FRACTION))\n",
        "    heldout_subclasses = set(rng.choice(all_subclasses_no_novel, size=num_holdout, replace=False).tolist())\n",
        "    seen_subclasses = [c for c in all_subclasses if c not in heldout_subclasses]\n",
        "\n",
        "    print(f\"[Pseudo-novel] Total subclasses (excl. novel): {len(all_subclasses_no_novel)}\")\n",
        "    print(f\"[Pseudo-novel] Held-out subclasses (pseudo-novel): {sorted(heldout_subclasses)}\")\n",
        "    print(f\"[Pseudo-novel] Seen subclasses (incl. novel-sub): {len(seen_subclasses)}\")\n",
        "\n",
        "    # 2) split dataframe into seen vs pseudo-novel (by subclass)\n",
        "    seen_mask = ~train_df[\"subclass_index\"].isin(heldout_subclasses)\n",
        "    seen_df = train_df[seen_mask].reset_index(drop=True)\n",
        "    pseudo_novel_df = train_df[~seen_mask].reset_index(drop=True)\n",
        "\n",
        "    print(f\"[Pseudo-novel] Seen samples: {len(seen_df)}, Pseudo-novel samples: {len(pseudo_novel_df)}\")\n",
        "\n",
        "    # 3) Train/val split on seen data, but ensure novel-super in both\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(  # type: ignore\n",
        "        seen_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=PSEUDO_NOVEL_SEED,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_seen_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_seen_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # 4) pseudo-novel validation loader (all held-out subclasses, val-style transform)\n",
        "    pseudo_novel_dataset = BirdDogReptileDataset(\n",
        "        pseudo_novel_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "    pseudo_novel_loader = DataLoader(\n",
        "        pseudo_novel_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"[Pseudo-novel] Train size: {len(train_dataset)}, \"\n",
        "        f\"Seen-val size: {len(val_seen_dataset)}, \"\n",
        "        f\"Pseudo-novel val size: {len(pseudo_novel_dataset)}\"\n",
        "    )\n",
        "\n",
        "# Test loader is the same regardless\n",
        "test_dataset = BirdDogReptileTestDataset(TEST_IMG_DIR, transform=val_test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=NUM_WORKERS)\n",
        "# change batch size back to 1 if see any errors\n",
        "\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpvDqfhKRKQ7"
      },
      "source": [
        "# SECTION 6: Approach A: Shared backbone, two heads + KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxn7j1w1RRJk",
        "outputId": "fc6b84f6-7821-4659-aded-92a4e1703b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads training in this cell.\n"
          ]
        }
      ],
      "source": [
        "# Original idea\n",
        "\n",
        "LR = 1e-4  # maybe two different learning rates\n",
        "ALPHA_KL = 0.1\n",
        "TEMPERATURE = 1.0\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = setup_backbone_training(\n",
        "        model_two_heads,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_two_heads = None\n",
        "    if USE_WANDB:\n",
        "        run_two_heads = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_heads_kl_resnet\"),\n",
        "            group=\"two_heads\",  # to group/filter all two_heads runs\n",
        "            config={\n",
        "                \"approach\": \"two_heads_kl\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"alpha_kl\": ALPHA_KL,\n",
        "                \"temperature\": TEMPERATURE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_score = 0.0\n",
        "\n",
        "    print(\"Training shared-backbone two-heads model (KL-coupled):\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_two_heads,\n",
        "            optimizer,\n",
        "            train_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_two_heads,\n",
        "            val_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_acc_super = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        val_acc_sub = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        val_loss = val_metrics[\"val_loss\"]\n",
        "\n",
        "        print(\n",
        "            f\"[Two-heads] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_loss:.4f}, \"\n",
        "            f\"val_acc_super={val_acc_super:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc_sub:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            # prefix metrics so they don't collide with two-model ones\n",
        "            log_dict = {\n",
        "                \"epoch\": epoch,\n",
        "                \"two_heads_train_loss\": train_metrics[\"loss\"],\n",
        "                \"two_heads_val_loss\": val_loss,\n",
        "                \"two_heads_val_acc_super\": val_acc_super,\n",
        "                \"two_heads_val_acc_sub\": val_acc_sub,\n",
        "            }\n",
        "            wandb.log(log_dict, step=epoch)\n",
        "\n",
        "        # simple combined score: average of super/sub val accuracy\n",
        "        val_score = 0.5 * val_acc_super + 0.5 * val_acc_sub\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(\n",
        "                model_two_heads.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best two-heads model\")\n",
        "\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    analyze_tau_sub(model_two_heads, pseudo_novel_loader, val_loader, mode=\"two_heads\")\n",
        "    analyze_tau_super(model_two_heads, val_loader, NOVEL_SUPER_IDX, mode=\"two_heads\")\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_two_heads,\n",
        "        mode=\"two_heads\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        val_loader=val_loader,\n",
        "        name=\"val_two_heads\",\n",
        "    )\n",
        "    evaluate_pseudo_novel_sub_with_novelty(model_two_heads, mode=\"two_heads\", tau_sub=TAU_SUB)\n",
        "    novelty_dashboard(\n",
        "        model_two_heads,\n",
        "        val_loader=val_loader,\n",
        "        pseudo_novel_loader=pseudo_novel_loader,\n",
        "        mode=\"two_heads\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "\n",
        "    if run_two_heads is not None:\n",
        "        run_two_heads.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads training in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNtlQWujRg4X"
      },
      "source": [
        "# SECTION 7: Approach B - Two separate models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RPa25bz6RlhN",
        "outputId": "20c3abe4-8b0e-4abe-e8de-58f7366a6302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 233MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Freezing backbone; training 2 parameter tensors in heads only.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251212_210647-uj6geqsu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/uj6geqsu' target=\"_blank\">two_models_super_resnet_20251212_210647</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/uj6geqsu' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/uj6geqsu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training superclass model:\n",
            "[Super] Epoch 1: train_loss=0.4176, val_loss=0.2374, val_acc_super=0.9246\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 2: train_loss=0.2318, val_loss=0.1964, val_acc_super=0.9335\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 3: train_loss=0.1948, val_loss=0.1907, val_acc_super=0.9353\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 4: train_loss=0.1953, val_loss=0.1703, val_acc_super=0.9450\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 5: train_loss=0.1796, val_loss=0.1501, val_acc_super=0.9486\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 6: train_loss=0.1619, val_loss=0.1422, val_acc_super=0.9504\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 7: train_loss=0.1559, val_loss=0.1543, val_acc_super=0.9459\n",
            "[Super] Epoch 8: train_loss=0.1626, val_loss=0.1431, val_acc_super=0.9530\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 9: train_loss=0.1539, val_loss=0.1423, val_acc_super=0.9468\n",
            "[Super] Epoch 10: train_loss=0.1444, val_loss=0.1407, val_acc_super=0.9495\n",
            "[Super] Epoch 11: train_loss=0.1409, val_loss=0.1734, val_acc_super=0.9415\n",
            "[Super] Epoch 12: train_loss=0.1402, val_loss=0.1456, val_acc_super=0.9539\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 13: train_loss=0.1423, val_loss=0.1267, val_acc_super=0.9574\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 14: train_loss=0.1374, val_loss=0.1502, val_acc_super=0.9495\n",
            "[Super] Epoch 15: train_loss=0.1369, val_loss=0.1180, val_acc_super=0.9583\n",
            "  Saved new best superclass model\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>super_train_loss</td><td>█▃▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>super_val_acc</td><td>▁▃▃▅▆▆▅▇▆▆▅▇█▆█</td></tr><tr><td>super_val_loss</td><td>█▆▅▄▃▂▃▂▂▂▄▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>super_train_loss</td><td>0.13686</td></tr><tr><td>super_val_acc</td><td>0.95833</td></tr><tr><td>super_val_loss</td><td>0.11802</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_super_resnet_20251212_210647</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/uj6geqsu' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/uj6geqsu</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251212_210647-uj6geqsu/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Freezing backbone; training 2 parameter tensors in heads only.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251212_210819-w19gr98o</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/w19gr98o' target=\"_blank\">two_models_sub_resnet_20251212_210819</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/w19gr98o' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/w19gr98o</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training subclass model:\n",
            "[Sub] Epoch 1: train_loss=1.8153, val_loss=1.1072, val_acc_sub=0.7261\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 2: train_loss=0.9841, val_loss=0.8987, val_acc_sub=0.7713\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 3: train_loss=0.8245, val_loss=0.8263, val_acc_sub=0.7713\n",
            "[Sub] Epoch 4: train_loss=0.7460, val_loss=0.8012, val_acc_sub=0.7908\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 5: train_loss=0.6918, val_loss=0.7429, val_acc_sub=0.7979\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 6: train_loss=0.6503, val_loss=0.7698, val_acc_sub=0.8023\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 7: train_loss=0.6190, val_loss=0.6962, val_acc_sub=0.8032\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 8: train_loss=0.5965, val_loss=0.7528, val_acc_sub=0.7934\n",
            "[Sub] Epoch 9: train_loss=0.5616, val_loss=0.6961, val_acc_sub=0.8023\n",
            "[Sub] Epoch 10: train_loss=0.5542, val_loss=0.7382, val_acc_sub=0.7988\n",
            "[Sub] Epoch 11: train_loss=0.5679, val_loss=0.6944, val_acc_sub=0.8041\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 12: train_loss=0.5282, val_loss=0.7591, val_acc_sub=0.8094\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 13: train_loss=0.5326, val_loss=0.6863, val_acc_sub=0.8121\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 14: train_loss=0.5085, val_loss=0.7143, val_acc_sub=0.8156\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 15: train_loss=0.4988, val_loss=0.7262, val_acc_sub=0.8121\n",
            "pseudo_novel_loader is None. Set USE_PSEUDO_NOVEL = True before building loaders to use this analysis.\n",
            "\n",
            "Seen superclasses (0/1/2) superclass max-prob stats:\n",
            "  count = 628\n",
            "  mean  = 0.940\n",
            "  std   = 0.120\n",
            "  percentiles:\n",
            "    p 1: 0.510\n",
            "    p 5: 0.599\n",
            "    p10: 0.773\n",
            "    p25: 0.955\n",
            "    p50: 0.996\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Novel superclasses (== NOVEL_SUPER_IDX) superclass max-prob stats:\n",
            "  count = 500\n",
            "  mean  = 0.981\n",
            "  std   = 0.071\n",
            "  percentiles:\n",
            "    p 1: 0.615\n",
            "    p 5: 0.900\n",
            "    p10: 0.976\n",
            "    p25: 0.996\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Suggested TAU_SUPER candidates (using seen + novel):\n",
            "  tau_super ≈ 10th percentile of seen:       0.773\n",
            "  tau_super ≈ 5th percentile of seen:        0.599\n",
            "  tau_super ≈ mean(seen) - std(seen):        0.820\n",
            "  tau_super ≈ mean(seen & novel) midpoint:   0.960\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged superclass histograms and tau_super candidates to Weights & Biases.\n",
            "\n",
            "=== Evaluation on val_super_only ===\n",
            "Overall superclass acc: 0.7810\n",
            "Seen superclass acc (true super != novel):   0.6067\n",
            "Seen superclass false-novel rate:            0.3933\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "=== Evaluation on val_sub_only ===\n",
            "Overall subclass acc:   0.6800\n",
            "Seen subclass acc (true sub != novel):       0.4268\n",
            "Seen subclass false-novel rate:              0.5732\n",
            "No pseudo_novel_loader available.\n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall superclass acc: 0.7810\n",
            "Seen superclass acc (true super != novel):   0.6067\n",
            "Seen superclass false-novel rate:            0.3933\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "     Split   Head                             Metric  \\\n",
            "0   config      -                           APPROACH   \n",
            "1   config      -                           BACKBONE   \n",
            "2   config      -                   CIFAR_NOVEL_MODE   \n",
            "3   config      -                       DATA_AUGMENT   \n",
            "4   config      -                     FINE_TUNE_MODE   \n",
            "5   config      -                            TAU_SUB   \n",
            "6   config      -                          TAU_SUPER   \n",
            "7   config      -                   USE_PSEUDO_NOVEL   \n",
            "8      val  super  Novel superclass accuracy (CIFAR)   \n",
            "9      val  super           Seen superclass accuracy   \n",
            "10     val  super   Seen superclass false-novel rate   \n",
            "\n",
            "                                              Meaning       Value  \n",
            "0        Model architecture (two_heads vs two_models)  two_models  \n",
            "1        Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                   Extra novel-super CIFAR data mode       large  \n",
            "3   Whether data augmentation is enabled for training        True  \n",
            "4             Backbone training mode (full vs frozen)      frozen  \n",
            "5                 Novelty threshold for subclass head        0.85  \n",
            "6               Novelty threshold for superclass head        0.99  \n",
            "7     Using held-out subclasses for pseudo-novel eval       False  \n",
            "8   CIFAR novel-super samples correctly predicted ...         1.0  \n",
            "9            Correctly keep seen superclasses as seen    0.606688  \n",
            "10     Seen superclasses incorrectly flipped to novel    0.393312  \n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall subclass acc:   0.6800\n",
            "Seen subclass acc (true sub != novel):       0.4268\n",
            "Seen subclass false-novel rate:              0.5732\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "    Split Head                          Metric  \\\n",
            "0  config    -                        APPROACH   \n",
            "1  config    -                        BACKBONE   \n",
            "2  config    -                CIFAR_NOVEL_MODE   \n",
            "3  config    -                    DATA_AUGMENT   \n",
            "4  config    -                  FINE_TUNE_MODE   \n",
            "5  config    -                         TAU_SUB   \n",
            "6  config    -                       TAU_SUPER   \n",
            "7  config    -                USE_PSEUDO_NOVEL   \n",
            "8     val  sub          Seen subclass accuracy   \n",
            "9     val  sub  Seen subclass false-novel rate   \n",
            "\n",
            "                                             Meaning       Value  \n",
            "0       Model architecture (two_heads vs two_models)  two_models  \n",
            "1       Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                  Extra novel-super CIFAR data mode       large  \n",
            "3  Whether data augmentation is enabled for training        True  \n",
            "4            Backbone training mode (full vs frozen)      frozen  \n",
            "5                Novelty threshold for subclass head        0.85  \n",
            "6              Novelty threshold for superclass head        0.99  \n",
            "7    Using held-out subclasses for pseudo-novel eval       False  \n",
            "8             Correctly keep seen subclasses as seen    0.426752  \n",
            "9       Seen subclasses incorrectly flipped to novel    0.573248  \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>sub_train_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>sub_val_acc</td><td>▁▅▅▆▇▇▇▆▇▇▇████</td></tr><tr><td>sub_val_loss</td><td>█▅▃▃▂▂▁▂▁▂▁▂▁▁▂</td></tr><tr><td>tau_super_candidate_1</td><td>▁</td></tr><tr><td>tau_super_candidate_2</td><td>▁</td></tr><tr><td>tau_super_candidate_3</td><td>▁</td></tr><tr><td>val_novel_super_acc</td><td>▁</td></tr><tr><td>val_overall_sub_acc</td><td>▁</td></tr><tr><td>val_overall_super_acc</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>sub_train_loss</td><td>0.49885</td></tr><tr><td>sub_val_acc</td><td>0.81206</td></tr><tr><td>sub_val_loss</td><td>0.72623</td></tr><tr><td>tau_super_candidate_1</td><td>0.77273</td></tr><tr><td>tau_super_candidate_2</td><td>0.59941</td></tr><tr><td>tau_super_candidate_3</td><td>0.81966</td></tr><tr><td>val_novel_super_acc</td><td>1</td></tr><tr><td>val_overall_sub_acc</td><td>0.67996</td></tr><tr><td>val_overall_super_acc</td><td>0.78103</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_sub_resnet_20251212_210819</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/w19gr98o' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/w19gr98o</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 2 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251212_210819-w19gr98o/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Second idea to compare\n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "if APPROACH == \"two_models\":\n",
        "    # Superclass model\n",
        "    model_super = SingleHeadModel(num_classes=num_super).to(device)\n",
        "    criterion_super = nn.CrossEntropyLoss()\n",
        "    optimizer_super = setup_backbone_training(\n",
        "        model_super,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_super = None\n",
        "    if USE_WANDB:\n",
        "        run_super = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_super_resnet\"),\n",
        "            group=\"two_models\",  # to filter all two_models runs together\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"super\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_super = 0.0\n",
        "\n",
        "    print(\"Training superclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_super,\n",
        "            optimizer_super,\n",
        "            train_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_super,\n",
        "            val_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        print(\n",
        "            f\"[Super] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_super={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"super_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"super_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"super_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_super:\n",
        "            best_val_super = val_acc\n",
        "            torch.save(\n",
        "                model_super.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_super_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best superclass model\")\n",
        "\n",
        "    if run_super is not None:\n",
        "        run_super.finish()\n",
        "\n",
        "    # Subclass model\n",
        "    model_sub = SingleHeadModel(num_classes=num_sub).to(device)\n",
        "    criterion_sub = nn.CrossEntropyLoss()\n",
        "    optimizer_sub = setup_backbone_training(\n",
        "        model_sub,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_sub = None\n",
        "    if USE_WANDB:\n",
        "        run_sub = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_sub_resnet\"),\n",
        "            group=\"two_models\",\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"sub\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_sub = 0.0\n",
        "\n",
        "    print(\"\\nTraining subclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_sub,\n",
        "            optimizer_sub,\n",
        "            train_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_sub,\n",
        "            val_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        print(\n",
        "            f\"[Sub] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"sub_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"sub_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"sub_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_sub:\n",
        "            best_val_sub = val_acc\n",
        "            torch.save(\n",
        "                model_sub.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_sub_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best subclass model\")\n",
        "\n",
        "    best_super_path = os.path.join(DATA_ROOT, \"best_super_model.pth\")\n",
        "    best_sub_path = os.path.join(DATA_ROOT, \"best_sub_model.pth\")\n",
        "    model_super.load_state_dict(torch.load(best_super_path, map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(best_sub_path, map_location=device))\n",
        "\n",
        "    # analyze_tau_sub(model_sub, mode=\"sub_single_head\")\n",
        "    # analyze_tau_super(model_super, mode=\"super_single_head\")\n",
        "    # evaluate_on_val_with_novelty(\n",
        "    #     model_super,\n",
        "    #     mode=\"super_single_head\",\n",
        "    #     tau_super=TAU_SUPER,\n",
        "    #     tau_sub=TAU_SUB,\n",
        "    #     loader=val_loader,\n",
        "    #     name=\"val_super_only\",\n",
        "    # )\n",
        "    # evaluate_on_val_with_novelty(\n",
        "    #     model_sub, mode=\"sub_single_head\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, loader=val_loader, name=\"val_sub_only\"\n",
        "    # )\n",
        "    # evaluate_pseudo_novel_sub_with_novelty(model_sub, mode=\"sub_single_head\", tau_sub=TAU_SUB)\n",
        "    # novelty_dashboard(\n",
        "    #     model_super, mode=\"super_single_head\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, include_pseudo=False\n",
        "    # )  # no pseudo-novel meaning for super head\n",
        "    # novelty_dashboard(model_sub, mode=\"sub_single_head\", tau_super=TAU_SUPER, tau_sub=TAU_SUB, include_pseudo=True)\n",
        "\n",
        "    analyze_tau_sub(model_sub, pseudo_novel_loader, val_loader, mode=\"sub_single_head\")\n",
        "    analyze_tau_super(model_super, val_loader, NOVEL_SUPER_IDX, mode=\"super_single_head\")\n",
        "\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_super,\n",
        "        mode=\"super_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        val_loader=val_loader,\n",
        "        name=\"val_super_only\",\n",
        "    )\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_sub,\n",
        "        mode=\"sub_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        val_loader=val_loader,\n",
        "        name=\"val_sub_only\",\n",
        "    )\n",
        "\n",
        "    evaluate_pseudo_novel_sub_with_novelty(model_sub, mode=\"sub_single_head\", tau_sub=TAU_SUB)\n",
        "\n",
        "    novelty_dashboard(\n",
        "        model_super,\n",
        "        val_loader=val_loader,\n",
        "        pseudo_novel_loader=pseudo_novel_loader,\n",
        "        mode=\"super_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        include_pseudo=False,\n",
        "    )\n",
        "    novelty_dashboard(\n",
        "        model_sub,\n",
        "        val_loader=val_loader,\n",
        "        pseudo_novel_loader=pseudo_novel_loader,\n",
        "        mode=\"sub_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        include_pseudo=True,\n",
        "    )\n",
        "\n",
        "    if run_sub is not None:\n",
        "        run_sub.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-model training in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZTFepgRxey"
      },
      "source": [
        "# SECTION 8: Test-time Inference & CSV Export for leaderboard **(two-head model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_69xbINR2w6",
        "outputId": "a987063f-7a04-41a2-a04b-35426cd6c4dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\n"
          ]
        }
      ],
      "source": [
        "# SECTION: Test-time inference & CSV export for two-heads model\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    # Recreate the model and load best checkpoint\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    test_predictions = predict_test_two_heads(\n",
        "        model_two_heads,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_heads_predictions.csv\")\n",
        "    test_predictions.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-heads predictions (with novelty) to:\", out_csv_path)\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPpeqduiLv5"
      },
      "source": [
        "# SECTION 9: Test-time Inference & CSV Export for leaderboard **(two separate models)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWEswAdKijVa",
        "outputId": "25108b58-eb3f-4448-aa47-5afb258895f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved two-model predictions (with novelty) to: /content/drive/MyDrive/NNDL-Project/Project Data/two_models_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "if APPROACH == \"two_models\":\n",
        "    model_super = SingleHeadModel(num_classes=num_super).to(device)\n",
        "    model_sub = SingleHeadModel(num_classes=num_sub).to(device)\n",
        "\n",
        "    model_super.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_super_model.pth\"), map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_sub_model.pth\"), map_location=device))\n",
        "\n",
        "    test_predictions_two_models = predict_test_two_models(\n",
        "        model_super,\n",
        "        model_sub,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_models_predictions.csv\")\n",
        "    test_predictions_two_models.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-model predictions (with novelty) to:\", out_csv_path)\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-models inference in this cell.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kret_312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
