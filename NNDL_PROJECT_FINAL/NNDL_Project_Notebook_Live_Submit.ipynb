{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "p_5aFAaALeLW",
        "a0NzoPU6L0kE",
        "iuf8bEcxONLs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 1: Setup & Imports"
      ],
      "metadata": {
        "id": "p_5aFAaALeLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85tMtuD924rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd59e65-3592-4eac-f199-210e20204079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Sun Dec 14 18:21:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   32C    P0             52W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makseldkw\u001b[0m (\u001b[33makseldkw07\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi  # just to sanity-check the GPU\n",
        "\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "\n",
        "USE_WANDB = True\n",
        "WANDB_ENTITY = \"nndl-project-F25\"\n",
        "WANDB_PROJECT = \"Multihead-Classification-Competition\"\n",
        "\n",
        "if USE_WANDB:\n",
        "  wandb.login()\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import os, zipfile, random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# wandb run-naming schema\n",
        "def make_run_name(base: str) -> str:\n",
        "    \"\"\"Create a unique run name with timestamp.\"\"\"\n",
        "    return f\"{base}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "# optional: for approximate reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 2: Config & Paths"
      ],
      "metadata": {
        "id": "UxiTY5skLo7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = \"/content/drive/MyDrive/NNDL-Project/Project Data\"\n",
        "\n",
        "# Local scratch space on the VM / Colab\n",
        "LOCAL_DATA_ROOT = \"/content/local_data\"\n",
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "\n",
        "train_zip_path = os.path.join(DATA_ROOT, \"train_images.zip\")\n",
        "test_zip_path  = os.path.join(DATA_ROOT, \"test_images.zip\")\n",
        "\n",
        "# Unzip to LOCAL_DATA_ROOT instead of Drive\n",
        "train_out_dir = os.path.join(LOCAL_DATA_ROOT, \"train_images\")\n",
        "test_out_dir  = os.path.join(LOCAL_DATA_ROOT, \"test_images\")\n",
        "\n",
        "if not os.path.exists(train_out_dir):\n",
        "    os.makedirs(train_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(train_zip_path, 'r') as z:\n",
        "        z.extractall(train_out_dir)\n",
        "\n",
        "if not os.path.exists(test_out_dir):\n",
        "    os.makedirs(test_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(test_zip_path, 'r') as z:\n",
        "        z.extractall(test_out_dir)\n",
        "\n",
        "TRAIN_IMG_DIR = os.path.join(train_out_dir, \"train_images\")\n",
        "TEST_IMG_DIR  = os.path.join(test_out_dir, \"test_images\")\n",
        "\n",
        "TRAIN_CSV = os.path.join(DATA_ROOT, \"train_data.csv\")\n",
        "SUPER_CSV = os.path.join(DATA_ROOT, \"superclass_mapping.csv\")\n",
        "SUB_CSV   = os.path.join(DATA_ROOT, \"subclass_mapping.csv\")\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2  # can set to 0 if we hit dataloader issues\n",
        "\n",
        "VAL_SPLIT = 0.1  # 10% validation\n",
        "IMG_SIZE = 64   # our image dimensions\n",
        "\n",
        "PROJECT_NAME = \"coms4776-transfer-learning\" # TBD update\n",
        "APPROACH = \"two_models\" # \"two_heads\" or \"two_models\"\n",
        "DATA_AUGMENT = True\n",
        "\n",
        "# Indices for \"novel\" classes (per provided data)\n",
        "NOVEL_SUPER_IDX = 3    # superclass index for novel\n",
        "NOVEL_SUB_IDX = 87     # subclass index for novel\n",
        "\n",
        "# Number of times run full-batch\n",
        "EPOCHS = 15\n",
        "\n",
        "# Learning rates\n",
        "LR = 1e-4  # overall learning rate\n",
        "LR_HEAD = 1e-2 # head learning rate, used when freezing backbone\n",
        "WEIGHT_DECAY = 1e-4 # seems standard\n",
        "BACKBONE = \"resnet50\" # \"resnet18\" or \"resnet50\"\n",
        "\n",
        "# Novel-super CIFAR integration (more images)\n",
        "# Options: \"none\", \"small\" (~1000 samples), \"large\" (~5000 samples)\n",
        "CIFAR_NOVEL_MODE = \"large\"   # \"large\" or \"small\" or \"none\"\n",
        "\n",
        "# Path to store metadata about CIFAR novel images\n",
        "CIFAR_NOVEL_CSV_PATH = os.path.join(LOCAL_DATA_ROOT, \"cifar_novel_data.csv\")\n",
        "\n",
        "# Fine-tuning mode for ResNet backbone\n",
        "# \"full\"   = train all layers (what you're currently doing)\n",
        "# \"frozen\" = freeze backbone, train only the heads on top\n",
        "FINE_TUNE_MODE = \"full\"    # or \"frozen\"\n",
        "\n",
        "# Initial novelty thresholds (starting points, will tune further)\n",
        "TAU_SUPER = 0.99        # NOTE: per calibration with validation data. if max superclass prob < TAU_SUPER -> predict novel superclass\n",
        "TAU_SUB = 0.85          # NOTE: per calibration with validation data. if max subclass prob < TAU_SUB  -> predict novel subclass\n",
        "\n",
        "########### MAKE SURE USE_PSEDUO_NOVEL IS FALSE BEFORE LEADERBOARD SUBMISSION ##################################################\n",
        "USE_PSEUDO_NOVEL = True # to validate on held-out subclasses from training. Used to fine-tune TAU_SUB\n",
        "PSEUDO_NOVEL_FRACTION = 0.15\n",
        "PSEUDO_NOVEL_SEED = 123\n"
      ],
      "metadata": {
        "id": "04GRyoqmIVed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CIFAR-100 novel-super dataset (excluding reptiles)\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "# Download CIFAR100 once (raw PIL images)\n",
        "CIFAR_ROOT = os.path.join(LOCAL_DATA_ROOT, \"cifar100_raw\")\n",
        "os.makedirs(CIFAR_ROOT, exist_ok=True)\n",
        "\n",
        "# Only do the heavy image-copying if CSV doesn't exist\n",
        "if CIFAR_NOVEL_MODE != \"none\" and not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "    print(\"Building CIFAR novel-super dataset (this happens once)...\")\n",
        "\n",
        "    cifar_train = CIFAR100(root=CIFAR_ROOT, train=True, download=True, transform=None)\n",
        "\n",
        "    # CIFAR-100 fine label names (with underscores)\n",
        "    cifar_fine_names = cifar_train.classes  # e.g. \"apple\", \"beaver\", \"aquarium_fish\", ...\n",
        "\n",
        "    # Fine classes we want, based on your list, excluding reptiles\n",
        "    # (these names match CIFAR-100 fine label names)\n",
        "    allowed_fine_names = set([\n",
        "        # aquatic mammals\n",
        "        \"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\",\n",
        "        # fish\n",
        "        \"aquarium_fish\", \"flatfish\", \"ray\", \"shark\", \"trout\",\n",
        "        # flowers\n",
        "        \"orchid\", \"poppy\", \"rose\", \"sunflower\", \"tulip\",\n",
        "        # food containers\n",
        "        \"bottle\", \"bowl\", \"can\", \"cup\", \"plate\",\n",
        "        # fruit and vegetables\n",
        "        \"apple\", \"mushroom\", \"orange\", \"pear\", \"sweet_pepper\",\n",
        "        # household electrical devices\n",
        "        \"clock\", \"keyboard\", \"lamp\", \"telephone\", \"television\",\n",
        "        # household furniture\n",
        "        \"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\",\n",
        "        # insects\n",
        "        \"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\",\n",
        "        # large carnivores\n",
        "        \"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\",\n",
        "        # large man-made outdoor things\n",
        "        \"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\",\n",
        "        # large natural outdoor scenes\n",
        "        \"cloud\", \"forest\", \"mountain\", \"plain\", \"sea\",\n",
        "        # large omnivores and herbivores\n",
        "        \"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\",\n",
        "        # medium-sized mammals\n",
        "        \"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\",\n",
        "        # non-insect invertebrates\n",
        "        \"crab\", \"lobster\", \"snail\", \"spider\", \"worm\",\n",
        "        # people\n",
        "        \"baby\", \"boy\", \"girl\", \"man\", \"woman\",\n",
        "        # small mammals\n",
        "        \"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\",\n",
        "        # trees\n",
        "        \"maple\", \"oak\", \"palm\", \"pine\", \"willow\",\n",
        "        # vehicles 1\n",
        "        \"bicycle\", \"bus\", \"motorcycle\", \"pickup_truck\", \"train\",\n",
        "        # vehicles 2\n",
        "        \"lawn_mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\",\n",
        "        # NOTE: reptiles group (\"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\") is *excluded* on purpose\n",
        "    ])\n",
        "\n",
        "    # Map class_name -> list of indices for that fine class\n",
        "    name_to_indices = {name: [] for name in allowed_fine_names}\n",
        "    for idx in range(len(cifar_train)):\n",
        "        _, fine_label = cifar_train[idx]  # fine_label is int index into cifar_fine_names\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "        if fine_name in allowed_fine_names:\n",
        "            name_to_indices[fine_name].append(idx)\n",
        "\n",
        "    # Flatten candidate indices across all allowed classes\n",
        "    candidate_indices = []\n",
        "    for name, idx_list in name_to_indices.items():\n",
        "        candidate_indices.extend(idx_list)\n",
        "\n",
        "    print(\"Total candidate CIFAR images (allowed classes, excl. reptiles):\", len(candidate_indices))\n",
        "\n",
        "    # Target total novel-super samples (max 5000, as you requested)\n",
        "    TARGET_TOTAL = 5000\n",
        "    random.seed(42)\n",
        "    random.shuffle(candidate_indices)\n",
        "    selected_indices = candidate_indices[:TARGET_TOTAL]\n",
        "\n",
        "    print(\"Selected indices:\", len(selected_indices))\n",
        "\n",
        "    # Copy images into TRAIN_IMG_DIR and build CSV rows\n",
        "    cifar_aug_records = []\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        img, fine_label = cifar_train[idx]\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "\n",
        "        # Unique filename to avoid collisions\n",
        "        fname = f\"cifar_novel_{idx}_{fine_name}.png\"\n",
        "        dst_path = os.path.join(TRAIN_IMG_DIR, fname)\n",
        "\n",
        "        # img is PIL.Image when transform=None\n",
        "        img.save(dst_path)\n",
        "\n",
        "        record = {\n",
        "            \"image\": fname,\n",
        "            \"superclass_index\": NOVEL_SUPER_IDX,  # novel superclass\n",
        "            \"subclass_index\": NOVEL_SUB_IDX,     # novel subclass\n",
        "            \"description\": f\"CIFAR100:{fine_name} (novel superclass)\",\n",
        "        }\n",
        "        cifar_aug_records.append(record)\n",
        "\n",
        "    cifar_aug_df = pd.DataFrame(cifar_aug_records)\n",
        "    cifar_aug_df.to_csv(CIFAR_NOVEL_CSV_PATH, index=False)\n",
        "    print(\"Saved CIFAR novel-super metadata to:\", CIFAR_NOVEL_CSV_PATH)\n",
        "    print(\"Images copied into TRAIN_IMG_DIR:\", TRAIN_IMG_DIR)\n",
        "\n",
        "elif CIFAR_NOVEL_MODE != \"none\":\n",
        "    print(\"CIFAR novel-super CSV already exists at:\", CIFAR_NOVEL_CSV_PATH)\n",
        "else:\n",
        "    print(\"CIFAR_NOVEL_MODE='none'; skipping CIFAR novel-super creation.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "stQpD0L1ggNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cfc5b4-6cde-4c82-9068-ccb52cf7837e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR novel-super CSV already exists at: /content/local_data/cifar_novel_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 3: Data Loading & DataLoaders"
      ],
      "metadata": {
        "id": "a0NzoPU6L0kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 3: Data Loading & Dataloaders\n",
        "\n",
        "# Base training data from class\n",
        "base_train_df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "super_map_df = pd.read_csv(SUPER_CSV)   # columns: index, class\n",
        "sub_map_df   = pd.read_csv(SUB_CSV)     # columns: index, class\n",
        "\n",
        "num_super = len(super_map_df)\n",
        "num_sub   = len(sub_map_df)\n",
        "\n",
        "print(\"Num superclasses:\", num_super)\n",
        "print(\"Num subclasses:\", num_sub)\n",
        "\n",
        "# --- Integrate CIFAR novel-super examples, if enabled ---\n",
        "\n",
        "if CIFAR_NOVEL_MODE == \"none\":\n",
        "    train_df = base_train_df.copy()\n",
        "    print(\"CIFAR_NOVEL_MODE='none' → using only original training data.\")\n",
        "else:\n",
        "    if not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"CIFAR_NOVEL_MODE={CIFAR_NOVEL_MODE} but {CIFAR_NOVEL_CSV_PATH} not found. \"\n",
        "            \"Run the CIFAR novel-super build section first.\"\n",
        "        )\n",
        "\n",
        "    cifar_aug_df = pd.read_csv(CIFAR_NOVEL_CSV_PATH)\n",
        "\n",
        "    if CIFAR_NOVEL_MODE == \"small\":\n",
        "        # Use ~1000 CIFAR novel-super images\n",
        "        n_small = min(1000, len(cifar_aug_df))\n",
        "        cifar_aug_df = cifar_aug_df.sample(n=n_small, random_state=42).reset_index(drop=True)\n",
        "        print(f\"CIFAR_NOVEL_MODE='small' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    elif CIFAR_NOVEL_MODE == \"large\":\n",
        "        # Use all available (up to 5000 created earlier)\n",
        "        print(f\"CIFAR_NOVEL_MODE='large' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown CIFAR_NOVEL_MODE: {CIFAR_NOVEL_MODE}\")\n",
        "\n",
        "    # Combine original training data with CIFAR novel-super rows\n",
        "    train_df = pd.concat([base_train_df, cifar_aug_df], ignore_index=True)\n",
        "    print(\"Combined train_df size (original + CIFAR):\", len(train_df))\n",
        "    print(\"  Novel-super count (superclass_index == NOVEL_SUPER_IDX):\",\n",
        "          (train_df[\"superclass_index\"] == NOVEL_SUPER_IDX).sum())\n",
        "\n",
        "# --- Build subclass -> superclass mapping from *combined* train_df ---\n",
        "# This still satisfies “each subclass has a single superclass”:\n",
        "#  - Original subclasses 0..86\n",
        "#  - Novel subclass 87 always maps to NOVEL_SUPER_IDX\n",
        "sub_to_super = (\n",
        "    train_df.groupby(\"subclass_index\")[\"superclass_index\"]\n",
        "            .agg(lambda x: x.value_counts().index[0])\n",
        "            .to_dict()\n",
        ")\n",
        "\n",
        "print(\"Example sub_to_super mapping (first 10):\",\n",
        "      dict(list(sub_to_super.items())[:10]))"
      ],
      "metadata": {
        "id": "c1DTM3ycL7_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb83307-dd78-48ba-89f7-5fbfef1f5c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num superclasses: 4\n",
            "Num subclasses: 88\n",
            "CIFAR_NOVEL_MODE='large' → using 5000 CIFAR novel-super samples.\n",
            "Combined train_df size (original + CIFAR): 11288\n",
            "  Novel-super count (superclass_index == NOVEL_SUPER_IDX): 5000\n",
            "Example sub_to_super mapping (first 10): {0: 1, 1: 2, 2: 1, 3: 2, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset functions\n",
        "class BirdDogReptileDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_name = row[\"image\"]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        super_idx = int(row[\"superclass_index\"])\n",
        "        sub_idx = int(row[\"subclass_index\"])\n",
        "        return image, super_idx, sub_idx"
      ],
      "metadata": {
        "id": "vdqaByetMJR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset (for leaderboard predictions)\n",
        "\n",
        "class BirdDogReptileTestDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        # assumes images are named 0.jpg, 1.jpg, ..., N-1.jpg\n",
        "        self.filenames = sorted(os.listdir(img_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.filenames[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name"
      ],
      "metadata": {
        "id": "ydp5kOpbMWTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms\n",
        "\n",
        "if DATA_AUGMENT:\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "else:\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "LcWn_qDgMcIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/val split + loaders with optional pseudo-novel validation,\n",
        "# ensuring novel-super examples (super == NOVEL_SUPER_IDX) appear in both train and val.\n",
        "\n",
        "from math import ceil\n",
        "\n",
        "pseudo_novel_loader = None      # default; will be set if USE_PSEUDO_NOVEL\n",
        "heldout_subclasses = None       # to inspect later if needed\n",
        "\n",
        "def split_seen_vs_novel_super(df, val_split, novel_super_idx, rng_seed=42):\n",
        "    \"\"\"\n",
        "    Split dataframe into train/val, ensuring that both seen-super (0/1/2)\n",
        "    and novel-super (== novel_super_idx) appear in both splits if present.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "\n",
        "    df_novel_super = df[df[\"superclass_index\"] == novel_super_idx]\n",
        "    df_seen_super  = df[df[\"superclass_index\"] != novel_super_idx]\n",
        "\n",
        "    print(\"  Seen-super samples:\", len(df_seen_super))\n",
        "    print(\"  Novel-super samples:\", len(df_novel_super))\n",
        "\n",
        "    # Split seen-super part\n",
        "    if len(df_seen_super) > 0:\n",
        "        val_seen_size = int(len(df_seen_super) * val_split)\n",
        "        val_seen_indices = rng.choice(len(df_seen_super), size=val_seen_size, replace=False)\n",
        "        val_seen_df = df_seen_super.iloc[val_seen_indices]\n",
        "        train_seen_df = df_seen_super.drop(val_seen_df.index)\n",
        "    else:\n",
        "        val_seen_df = df_seen_super.iloc[0:0]\n",
        "        train_seen_df = df_seen_super.iloc[0:0]\n",
        "\n",
        "    # Split novel-super part (if any)\n",
        "    if len(df_novel_super) > 0:\n",
        "        val_novel_size = max(1, int(len(df_novel_super) * val_split))\n",
        "        val_novel_indices = rng.choice(len(df_novel_super), size=val_novel_size, replace=False)\n",
        "        val_novel_df = df_novel_super.iloc[val_novel_indices]\n",
        "        train_novel_df = df_novel_super.drop(val_novel_df.index)\n",
        "    else:\n",
        "        val_novel_df = df_novel_super.iloc[0:0]\n",
        "        train_novel_df = df_novel_super.iloc[0:0]\n",
        "\n",
        "    # Combine splits and shuffle\n",
        "    train_split_df = pd.concat([train_seen_df, train_novel_df], ignore_index=True)\n",
        "    val_split_df   = pd.concat([val_seen_df,   val_novel_df],   ignore_index=True)\n",
        "\n",
        "    train_split_df = train_split_df.sample(frac=1.0, random_state=rng_seed).reset_index(drop=True)\n",
        "    val_split_df   = val_split_df.sample(frac=1.0,   random_state=rng_seed + 1).reset_index(drop=True)\n",
        "\n",
        "    print(\"  Final split sizes:\")\n",
        "    print(\"    train:\", len(train_split_df))\n",
        "    print(\"    val:  \", len(val_split_df))\n",
        "    print(\"    train novel-super:\",\n",
        "          (train_split_df[\"superclass_index\"] == novel_super_idx).sum())\n",
        "    print(\"    val novel-super:  \",\n",
        "          (val_split_df[\"superclass_index\"] == novel_super_idx).sum())\n",
        "\n",
        "    return train_split_df, val_split_df\n",
        "\n",
        "\n",
        "if not USE_PSEUDO_NOVEL:\n",
        "    # -------------------------\n",
        "    # Simple split, but novel-super-aware\n",
        "    # -------------------------\n",
        "    print(\"[Simple split, novel-super aware]\")\n",
        "\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(\n",
        "        train_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=42,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(f\"[Simple split] Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
        "\n",
        "else:\n",
        "    # -------------------------\n",
        "    # Pseudo-novel setup: hold out some subclasses entirely for pseudo-novel validation\n",
        "    # while still keeping novel-super in both train and val.\n",
        "    # -------------------------\n",
        "\n",
        "    print(\"[Pseudo-novel subclass split + novel-super-aware train/val]\")\n",
        "\n",
        "    # 1) choose subset of subclasses to treat as pseudo-novel\n",
        "    all_subclasses = sorted(train_df[\"subclass_index\"].unique())\n",
        "    # Do NOT hold out the novel subclass itself (87)\n",
        "    all_subclasses_no_novel = [c for c in all_subclasses if c != NOVEL_SUB_IDX]\n",
        "\n",
        "    rng = np.random.default_rng(PSEUDO_NOVEL_SEED)\n",
        "\n",
        "    num_holdout = max(1, int(len(all_subclasses_no_novel) * PSEUDO_NOVEL_FRACTION))\n",
        "    heldout_subclasses = set(\n",
        "        rng.choice(all_subclasses_no_novel, size=num_holdout, replace=False).tolist()\n",
        "    )\n",
        "    seen_subclasses = [c for c in all_subclasses if c not in heldout_subclasses]\n",
        "\n",
        "    print(f\"[Pseudo-novel] Total subclasses (excl. novel): {len(all_subclasses_no_novel)}\")\n",
        "    print(f\"[Pseudo-novel] Held-out subclasses (pseudo-novel): {sorted(heldout_subclasses)}\")\n",
        "    print(f\"[Pseudo-novel] Seen subclasses (incl. novel-sub): {len(seen_subclasses)}\")\n",
        "\n",
        "    # 2) split dataframe into seen vs pseudo-novel (by subclass)\n",
        "    seen_mask = ~train_df[\"subclass_index\"].isin(heldout_subclasses)\n",
        "    seen_df = train_df[seen_mask].reset_index(drop=True)\n",
        "    pseudo_novel_df = train_df[~seen_mask].reset_index(drop=True)\n",
        "\n",
        "    print(f\"[Pseudo-novel] Seen samples: {len(seen_df)}, Pseudo-novel samples: {len(pseudo_novel_df)}\")\n",
        "\n",
        "    # 3) Train/val split on seen data, but ensure novel-super in both\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(\n",
        "        seen_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=PSEUDO_NOVEL_SEED,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_seen_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_seen_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # 4) pseudo-novel validation loader (all held-out subclasses, val-style transform)\n",
        "    pseudo_novel_dataset = BirdDogReptileDataset(\n",
        "        pseudo_novel_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "    pseudo_novel_loader = DataLoader(\n",
        "        pseudo_novel_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(f\"[Pseudo-novel] Train size: {len(train_dataset)}, \"\n",
        "          f\"Seen-val size: {len(val_seen_dataset)}, \"\n",
        "          f\"Pseudo-novel val size: {len(pseudo_novel_dataset)}\")\n",
        "\n",
        "# Test loader is the same regardless\n",
        "test_dataset = BirdDogReptileTestDataset(TEST_IMG_DIR, transform=val_test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64,\n",
        "                         shuffle=False, num_workers=NUM_WORKERS)\n",
        "# change batch size back to 1 if see any errors\n",
        "\n",
        "print(f\"Test size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "l_xpuCQFMf6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0033c536-b044-4adb-fd5e-62fc040d6602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pseudo-novel subclass split + novel-super-aware train/val]\n",
            "[Pseudo-novel] Total subclasses (excl. novel): 87\n",
            "[Pseudo-novel] Held-out subclasses (pseudo-novel): [1, 4, 14, 15, 17, 20, 27, 29, 39, 45, 51, 69, 71]\n",
            "[Pseudo-novel] Seen subclasses (incl. novel-sub): 75\n",
            "[Pseudo-novel] Seen samples: 10340, Pseudo-novel samples: 948\n",
            "  Seen-super samples: 5340\n",
            "  Novel-super samples: 5000\n",
            "  Final split sizes:\n",
            "    train: 9306\n",
            "    val:   1034\n",
            "    train novel-super: 4500\n",
            "    val novel-super:   500\n",
            "[Pseudo-novel] Train size: 9306, Seen-val size: 1034, Pseudo-novel val size: 948\n",
            "Test size: 11180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 4: Backbone & Model Definitions"
      ],
      "metadata": {
        "id": "B6WgPWLVND6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Backbone builder\n",
        "\n",
        "# Using ImageNet pretrained ResNet backbone, and chopping off FC head to Transfer Learn\n",
        "\n",
        "def build_resnet_backbone():\n",
        "    # Using torchvision ResNet-18 with ImageNet weights\n",
        "    if BACKBONE == \"resnet18\":\n",
        "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    elif BACKBONE == \"resnet50\":\n",
        "        base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown BACKBONE: {BACKBONE}\")\n",
        "    # Remove the final classification layer\n",
        "    in_features = base.fc.in_features\n",
        "    base.fc = nn.Identity()\n",
        "    return base, in_features"
      ],
      "metadata": {
        "id": "VQS_4YIINJyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Methods for Shared backbone + two heads + KL divergence\n",
        "\n",
        "class SharedBackboneTwoHeads(nn.Module):\n",
        "    def __init__(self, num_super, num_sub):\n",
        "        super().__init__()\n",
        "        self.backbone, feat_dim = build_resnet_backbone()\n",
        "        self.super_head = nn.Linear(feat_dim, num_super)\n",
        "        self.sub_head = nn.Linear(feat_dim, num_sub)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        super_logits = self.super_head(feats)\n",
        "        sub_logits = self.sub_head(feats)\n",
        "        return super_logits, sub_logits"
      ],
      "metadata": {
        "id": "MyTxkOsZNZaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KL helper that maps subclass probs to superclass probs using sub_to_super mapping\n",
        "\n",
        "def sub_probs_to_super_probs(sub_probs, sub_to_super, num_super):\n",
        "    \"\"\"\n",
        "    sub_probs: (B, num_sub), softmax over subclasses\n",
        "    returns: (B, num_super), summed probs per super-class\n",
        "    \"\"\"\n",
        "    B, num_sub = sub_probs.shape\n",
        "    super_probs = torch.zeros(B, num_super, device=sub_probs.device)\n",
        "\n",
        "    for sub_idx, super_idx in sub_to_super.items():\n",
        "        super_probs[:, super_idx] += sub_probs[:, sub_idx]\n",
        "\n",
        "    # For safety: re-normalize in case of any numeric drift\n",
        "    super_probs = super_probs / (super_probs.sum(dim=1, keepdim=True) + 1e-8)\n",
        "    return super_probs"
      ],
      "metadata": {
        "id": "7NrchhvbNhi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-head model for 2-separate models approach\n",
        "# Each model is just a backbone + one linear head\n",
        "\n",
        "# to instantiate, one has num_classes = num_super, other has num_classes = num_sub\n",
        "\n",
        "class SingleHeadModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone, feat_dim = build_resnet_backbone()\n",
        "        self.head = nn.Linear(feat_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        logits = self.head(feats)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "O4yfIaOINvbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 5: Training & evaluation utilities"
      ],
      "metadata": {
        "id": "iuf8bEcxONLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functions for training\n",
        "\n",
        "# we pass a flag mode to indicate which model using either:\n",
        "# \"two_heads_kl\", \"single_head_super\" or \"single_head\"sub\"\n",
        "\n",
        "\n",
        "def accuracy_from_logits(logits, targets):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    correct = (preds == targets).sum().item()\n",
        "    total = targets.size(0)\n",
        "    return correct, total\n",
        "\n",
        "\n",
        "def train_one_epoch(model, optimizer, loader, criterion, mode, sub_to_super=None,\n",
        "                    num_super=None, alpha_kl=0.1, temperature=1.0):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    super_correct = sub_correct = 0\n",
        "    super_total = sub_total = 0\n",
        "\n",
        "    for images, super_labels, sub_labels in loader:\n",
        "        images = images.to(device)\n",
        "        super_labels = super_labels.to(device)\n",
        "        sub_labels = sub_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if mode == \"two_heads_kl\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "            # CE losses\n",
        "            loss_super = criterion(super_logits, super_labels)\n",
        "            loss_sub = criterion(sub_logits, sub_labels)\n",
        "\n",
        "            # KL term between super head and aggregated subclass head\n",
        "            with torch.no_grad():\n",
        "                # target: super_probs\n",
        "                super_probs = F.softmax(super_logits / temperature, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits / temperature, dim=1)\n",
        "            agg_super_probs = sub_probs_to_super_probs(sub_probs, sub_to_super, num_super)\n",
        "\n",
        "            # KL(super || agg_super) = sum p * (log p - log q)\n",
        "            # using KLDivLoss with log_softmax input and probs target:\n",
        "            kl_loss = F.kl_div(\n",
        "                input=torch.log(agg_super_probs + 1e-8),\n",
        "                target=super_probs,\n",
        "                reduction=\"batchmean\"\n",
        "            )\n",
        "\n",
        "            loss = loss_super + loss_sub + alpha_kl * kl_loss\n",
        "\n",
        "            sc, st = accuracy_from_logits(super_logits, super_labels)\n",
        "            suc, sut = accuracy_from_logits(sub_logits, sub_labels)\n",
        "            super_correct += sc\n",
        "            super_total += st\n",
        "            sub_correct += suc\n",
        "            sub_total += sut\n",
        "\n",
        "        elif mode in (\"single_head_super\", \"single_head_sub\"):\n",
        "            logits = model(images)\n",
        "            if mode == \"single_head_super\":\n",
        "                loss = criterion(logits, super_labels)\n",
        "                sc, st = accuracy_from_logits(logits, super_labels)\n",
        "                super_correct += sc\n",
        "                super_total += st\n",
        "            else:\n",
        "                loss = criterion(logits, sub_labels)\n",
        "                suc, sut = accuracy_from_logits(logits, sub_labels)\n",
        "                sub_correct += suc\n",
        "                sub_total += sut\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode {mode}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    metrics = {\"loss\": avg_loss}\n",
        "    if super_total > 0:\n",
        "        metrics[\"acc_super\"] = super_correct / super_total\n",
        "    if sub_total > 0:\n",
        "        metrics[\"acc_sub\"] = sub_correct / sub_total\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader, criterion, mode, sub_to_super=None,\n",
        "                   num_super=None, alpha_kl=0.1, temperature=1.0):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    super_correct = sub_correct = 0\n",
        "    super_total = sub_total = 0\n",
        "\n",
        "    for images, super_labels, sub_labels in loader:\n",
        "        images = images.to(device)\n",
        "        super_labels = super_labels.to(device)\n",
        "        sub_labels = sub_labels.to(device)\n",
        "\n",
        "        if mode == \"two_heads_kl\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "            loss_super = criterion(super_logits, super_labels)\n",
        "            loss_sub = criterion(sub_logits, sub_labels)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                super_probs = F.softmax(super_logits / temperature, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits / temperature, dim=1)\n",
        "            agg_super_probs = sub_probs_to_super_probs(sub_probs, sub_to_super, num_super)\n",
        "\n",
        "            kl_loss = F.kl_div(\n",
        "                input=torch.log(agg_super_probs + 1e-8),\n",
        "                target=super_probs,\n",
        "                reduction=\"batchmean\"\n",
        "            )\n",
        "\n",
        "            loss = loss_super + loss_sub + alpha_kl * kl_loss\n",
        "\n",
        "            sc, st = accuracy_from_logits(super_logits, super_labels)\n",
        "            suc, sut = accuracy_from_logits(sub_logits, sub_labels)\n",
        "            super_correct += sc\n",
        "            super_total += st\n",
        "            sub_correct += suc\n",
        "            sub_total += sut\n",
        "\n",
        "        elif mode in (\"single_head_super\", \"single_head_sub\"):\n",
        "            logits = model(images)\n",
        "            if mode == \"single_head_super\":\n",
        "                loss = criterion(logits, super_labels)\n",
        "                sc, st = accuracy_from_logits(logits, super_labels)\n",
        "                super_correct += sc\n",
        "                super_total += st\n",
        "            else:\n",
        "                loss = criterion(logits, sub_labels)\n",
        "                suc, sut = accuracy_from_logits(logits, sub_labels)\n",
        "                sub_correct += suc\n",
        "                sub_total += sut\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    metrics = {\"val_loss\": avg_loss}\n",
        "    if super_total > 0:\n",
        "        metrics[\"val_acc_super\"] = super_correct / super_total\n",
        "    if sub_total > 0:\n",
        "        metrics[\"val_acc_sub\"] = sub_correct / sub_total\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "Unso2GHLOnLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis and Visualize: for Novel Subclass fine tuning\n",
        "# Determines optimal threshold value from training data (except held out) vs. held out (pseudo-novel) subclass data\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_max_probs_sub(model, loader, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Collect max softmax probabilities from the subclass head.\n",
        "\n",
        "    mode:\n",
        "      - \"two_heads\": model(images) -> (super_logits, sub_logits)\n",
        "      - \"sub_single_head\": model(images) -> sub_logits\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    probs = []\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            _, sub_logits = model(images)\n",
        "        elif mode == \"sub_single_head\":\n",
        "            sub_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        # Softmax over subclasses, then take max per sample\n",
        "        p = F.softmax(sub_logits, dim=1).max(dim=1).values\n",
        "        probs.extend(p.cpu().numpy().tolist())\n",
        "\n",
        "    return np.array(probs)\n",
        "\n",
        "@torch.no_grad()\n",
        "def analyze_tau_sub(model, mode=\"two_heads\"):\n",
        "  \"\"\"\n",
        "  Compare max subclass probabilities on:\n",
        "    - seen validation (val_loader)\n",
        "    - pseudo-novel validation (pseudo_novel_loader)\n",
        "  and suggest TAU_SUB candidates.\n",
        "  \"\"\"\n",
        "\n",
        "  if pseudo_novel_loader is None:\n",
        "      print(\"pseudo_novel_loader is None. \"\n",
        "            \"Set USE_PSEUDO_NOVEL = True before building loaders to use this analysis.\")\n",
        "      return\n",
        "\n",
        "  # Collect max probs\n",
        "  seen_probs = collect_max_probs_sub(model, val_loader, mode=mode)\n",
        "  pseudo_probs = collect_max_probs_sub(model, pseudo_novel_loader, mode=mode)\n",
        "\n",
        "  # Summary stats\n",
        "  def summarize(name, arr):\n",
        "      print(f\"\\n{name} subclass max-prob stats:\")\n",
        "      print(f\"  count = {len(arr)}\")\n",
        "      print(f\"  mean  = {arr.mean():.3f}\")\n",
        "      print(f\"  std   = {arr.std():.3f}\")\n",
        "      percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
        "      pvals = {p: float(np.percentile(arr, p)) for p in percentiles}\n",
        "      print(\"  percentiles:\")\n",
        "      for p in percentiles:\n",
        "          print(f\"    p{p:>2}: {pvals[p]:.3f}\")\n",
        "      return pvals\n",
        "\n",
        "  seen_p = summarize(\"Seen\", seen_probs)\n",
        "  pseudo_p = summarize(\"Pseudo-novel\", pseudo_probs)\n",
        "\n",
        "  # Simple candidate thresholds\n",
        "  # 1) 10th percentile of seen (reject only the lowest-confidence seen examples)\n",
        "  tau_candidate_1 = seen_p[10]\n",
        "\n",
        "  # 2) Midpoint between mean(seen) and mean(pseudo)\n",
        "  tau_candidate_2 = 0.5 * (seen_probs.mean() + pseudo_probs.mean())\n",
        "\n",
        "  print(\"\\nSuggested TAU_SUB candidates:\")\n",
        "  print(f\"  tau_sub ≈ 10th percentile of seen: {tau_candidate_1:.3f}\")\n",
        "  print(f\"  tau_sub ≈ mean(seen + pseudo)/2:  {tau_candidate_2:.3f}\")\n",
        "  print(\"\\nYou can start with one of these for TAU_SUB and adjust based on leaderboard/behavior.\")\n",
        "\n",
        "  # Histogram visualization\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  plt.hist(seen_probs, bins=30, alpha=0.5, label=\"Seen subclasses\")\n",
        "  plt.hist(pseudo_probs, bins=30, alpha=0.5, label=\"Pseudo-novel subclasses\")\n",
        "  plt.axvline(tau_candidate_1, linestyle=\"--\", label=f\"p10 seen ~ {tau_candidate_1:.2f}\")\n",
        "  plt.axvline(tau_candidate_2, linestyle=\":\", label=f\"mean midpoint ~ {tau_candidate_2:.2f}\")\n",
        "  plt.xlabel(\"Max softmax probability (subclass head)\")\n",
        "  plt.ylabel(\"Count\")\n",
        "  plt.title(\"Subclass max-prob: seen vs pseudo-novel\")\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  # Optional: log histograms and candidates to W&B\n",
        "  if USE_WANDB:\n",
        "      try:\n",
        "          import wandb\n",
        "          wandb.log({\n",
        "              \"sub_seen_maxprob_hist\": wandb.Histogram(seen_probs),\n",
        "              \"sub_pseudo_maxprob_hist\": wandb.Histogram(pseudo_probs),\n",
        "              \"tau_sub_candidate_p10_seen\": tau_candidate_1,\n",
        "              \"tau_sub_candidate_mean_midpoint\": tau_candidate_2,\n",
        "          })\n",
        "          print(\"Logged histograms and tau_sub candidates to Weights & Biases.\")\n",
        "      except Exception as e:\n",
        "          print(\"Could not log to W&B:\", e)"
      ],
      "metadata": {
        "id": "varT5fWNMiJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis and Visualize: for Novel Superclass fine tuning\n",
        "# Determines the optimal threshold from provided training data vs. Novel Super data (more images)\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_max_probs_super(model, loader, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Collect max softmax probabilities from the superclass head.\n",
        "\n",
        "    mode:\n",
        "      - \"two_heads\": model(images) -> (super_logits, sub_logits)\n",
        "      - \"super_single_head\": model(images) -> super_logits\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    probs = []\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            super_logits, _ = model(images)\n",
        "        elif mode == \"super_single_head\":\n",
        "            super_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        p = F.softmax(super_logits, dim=1).max(dim=1).values\n",
        "        probs.extend(p.cpu().numpy().tolist())\n",
        "\n",
        "    return np.array(probs)\n",
        "\n",
        "@torch.no_grad()\n",
        "def analyze_tau_super(model, mode=\"two_heads\"):\n",
        "    \"\"\"\n",
        "    Analyze max superclass probabilities on validation set, split into:\n",
        "      - seen superclasses (super != NOVEL_SUPER_IDX)\n",
        "      - novel superclasses (super == NOVEL_SUPER_IDX)\n",
        "\n",
        "    This assumes:\n",
        "      - val_loader batches look like (images, super_labels, sub_labels, ...)\n",
        "      - NOVEL_SUPER_IDX is defined (e.g. 3)\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    seen_probs = []\n",
        "    novel_probs = []\n",
        "\n",
        "    for batch in val_loader:\n",
        "        images = batch[0].to(device)\n",
        "        super_labels = batch[1].to(device)   # assumes (images, super, sub, ...)\n",
        "\n",
        "        # Forward\n",
        "        if mode == \"two_heads\":\n",
        "            super_logits, _ = model(images)\n",
        "        elif mode == \"super_single_head\":\n",
        "            super_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        probs = F.softmax(super_logits, dim=1)          # (B, num_super)\n",
        "        max_probs, _ = probs.max(dim=1)                 # (B,)\n",
        "\n",
        "        novel_mask = (super_labels == NOVEL_SUPER_IDX)\n",
        "        seen_mask = ~novel_mask\n",
        "\n",
        "        if seen_mask.any():\n",
        "            seen_probs.extend(max_probs[seen_mask].detach().cpu().numpy().tolist())\n",
        "        if novel_mask.any():\n",
        "            novel_probs.extend(max_probs[novel_mask].detach().cpu().numpy().tolist())\n",
        "\n",
        "    seen_probs = np.array(seen_probs)\n",
        "    novel_probs = np.array(novel_probs)\n",
        "\n",
        "    def summarize(name, arr):\n",
        "        print(f\"\\n{name} superclass max-prob stats:\")\n",
        "        print(f\"  count = {len(arr)}\")\n",
        "        print(f\"  mean  = {arr.mean():.3f}\")\n",
        "        print(f\"  std   = {arr.std():.3f}\")\n",
        "        percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
        "        pvals = {p: float(np.percentile(arr, p)) for p in percentiles}\n",
        "        print(\"  percentiles:\")\n",
        "        for p in percentiles:\n",
        "            print(f\"    p{p:>2}: {pvals[p]:.3f}\")\n",
        "        return pvals\n",
        "\n",
        "    if len(seen_probs) == 0:\n",
        "        print(\"No seen-super examples found in val_loader (super != NOVEL_SUPER_IDX).\")\n",
        "        return\n",
        "    seen_p = summarize(\"Seen superclasses (0/1/2)\", seen_probs)\n",
        "\n",
        "    if len(novel_probs) == 0:\n",
        "        print(\"\\nNo novel-super examples (super == NOVEL_SUPER_IDX) in val_loader yet.\")\n",
        "        novel_p = None\n",
        "    else:\n",
        "        novel_p = summarize(\"Novel superclasses (== NOVEL_SUPER_IDX)\", novel_probs)\n",
        "\n",
        "    # ---- Candidate thresholds ----\n",
        "    # Start from seen distribution:\n",
        "    tau_p10_seen = seen_p[10]\n",
        "    tau_p5_seen  = seen_p[5]\n",
        "    tau_mean_minus_std = max(0.0, min(1.0, seen_probs.mean() - seen_probs.std()))\n",
        "\n",
        "    # If we have novel-super stats, try to place tau between seen & novel means/percentiles\n",
        "    if novel_p is not None:\n",
        "        # Midpoint between seen mean and novel mean\n",
        "        tau_mean_mid = 0.5 * (seen_probs.mean() + novel_probs.mean())\n",
        "        print(\"\\nSuggested TAU_SUPER candidates (using seen + novel):\")\n",
        "        print(f\"  tau_super ≈ 10th percentile of seen:       {tau_p10_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ 5th percentile of seen:        {tau_p5_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ mean(seen) - std(seen):        {tau_mean_minus_std:.3f}\")\n",
        "        print(f\"  tau_super ≈ mean(seen & novel) midpoint:   {tau_mean_mid:.3f}\")\n",
        "        tau_candidates = [tau_p10_seen, tau_p5_seen, tau_mean_minus_std, tau_mean_mid]\n",
        "    else:\n",
        "        print(\"\\nSuggested TAU_SUPER candidates (seen only):\")\n",
        "        print(f\"  tau_super ≈ 10th percentile of seen:       {tau_p10_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ 5th percentile of seen:        {tau_p5_seen:.3f}\")\n",
        "        print(f\"  tau_super ≈ mean(seen) - std(seen):        {tau_mean_minus_std:.3f}\")\n",
        "        tau_candidates = [tau_p10_seen, tau_p5_seen, tau_mean_minus_std]\n",
        "\n",
        "    # ---- Histogram plot ----\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(seen_probs, bins=30, alpha=0.6, label=\"Seen superclasses (0/1/2)\")\n",
        "    if len(novel_probs) > 0:\n",
        "        plt.hist(novel_probs, bins=30, alpha=0.6, label=\"Novel superclasses (3)\")\n",
        "\n",
        "    # Draw candidate lines (use a couple of them for visual reference)\n",
        "    for tau in tau_candidates[:3]:\n",
        "        plt.axvline(tau, linestyle=\"--\", alpha=0.7)\n",
        "\n",
        "    plt.xlabel(\"Max softmax probability (superclass head)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Superclass max-prob: seen vs novel-super on validation\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ---- Optional: log to W&B ----\n",
        "    if USE_WANDB:\n",
        "        try:\n",
        "            import wandb\n",
        "            log_dict = {\n",
        "                \"super_seen_maxprob_hist\": wandb.Histogram(seen_probs),\n",
        "            }\n",
        "            if len(novel_probs) > 0:\n",
        "                log_dict[\"super_novel_maxprob_hist\"] = wandb.Histogram(novel_probs)\n",
        "            # Also log first few tau candidates\n",
        "            log_dict[\"tau_super_candidate_1\"] = float(tau_candidates[0])\n",
        "            if len(tau_candidates) > 1:\n",
        "                log_dict[\"tau_super_candidate_2\"] = float(tau_candidates[1])\n",
        "            if len(tau_candidates) > 2:\n",
        "                log_dict[\"tau_super_candidate_3\"] = float(tau_candidates[2])\n",
        "            wandb.log(log_dict)\n",
        "            print(\"Logged superclass histograms and tau_super candidates to Weights & Biases.\")\n",
        "        except Exception as e:\n",
        "            print(\"Could not log to W&B:\", e)\n",
        "\n"
      ],
      "metadata": {
        "id": "8E6cjjSDOODs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional eval helper functions\n",
        "\n",
        "# This calculates the following:\n",
        "# 1. How often we correctly keep seen classes (low false \"novel\" rate)\n",
        "# 2. How often we correctly identify CIFAR \"novel super\" samples (new data)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_on_val_with_novelty(model, mode=\"two_heads\",\n",
        "                                 tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                                 loader=None, name=\"val\"):\n",
        "    \"\"\"\n",
        "    Evaluate a model on a loader with novel thresholds applied.\n",
        "\n",
        "    For subclasses, we ONLY care about:\n",
        "      - overall subclass acc\n",
        "      - seen-subclass acc / false-novel rate\n",
        "\n",
        "    We DO NOT report \"novel-subclass accuracy\" here because there are no\n",
        "    ground-truth novel-sub labels in the original validation data.\n",
        "    \"\"\"\n",
        "    if loader is None:\n",
        "        loader = val_loader\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    super_correct = 0\n",
        "    sub_correct = 0\n",
        "\n",
        "    seen_super_correct = seen_super_total = 0\n",
        "    novel_super_correct = novel_super_total = 0\n",
        "\n",
        "    seen_sub_correct = seen_sub_total = 0\n",
        "    novel_sub_correct = novel_sub_total = 0  # still counted but not reported\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "        super_true = batch[1].to(device)\n",
        "        sub_true   = batch[2].to(device)\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "        elif mode == \"super_single_head\":\n",
        "            super_logits = model(images); sub_logits = None\n",
        "        elif mode == \"sub_single_head\":\n",
        "            super_logits = None; sub_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        # --- Superclass ---\n",
        "        if super_logits is not None:\n",
        "            super_probs = F.softmax(super_logits, dim=1)\n",
        "            max_super_probs, super_idx = super_probs.max(dim=1)\n",
        "\n",
        "            super_pred = super_idx.clone()\n",
        "            novel_mask_super = max_super_probs < tau_super\n",
        "            super_pred[novel_mask_super] = NOVEL_SUPER_IDX\n",
        "\n",
        "            match_super = (super_pred == super_true)\n",
        "            super_correct += match_super.sum().item()\n",
        "\n",
        "            seen_mask_super = (super_true != NOVEL_SUPER_IDX)\n",
        "            novel_mask_super_label = (super_true == NOVEL_SUPER_IDX)\n",
        "\n",
        "            if seen_mask_super.any():\n",
        "                seen_super_correct += match_super[seen_mask_super].sum().item()\n",
        "                seen_super_total   += seen_mask_super.sum().item()\n",
        "            if novel_mask_super_label.any():\n",
        "                novel_super_correct += match_super[novel_mask_super_label].sum().item()\n",
        "                novel_super_total   += novel_mask_super_label.sum().item()\n",
        "\n",
        "        # --- Subclass ---\n",
        "        if sub_logits is not None:\n",
        "            sub_probs = F.softmax(sub_logits, dim=1)\n",
        "            max_sub_probs, sub_idx = sub_probs.max(dim=1)\n",
        "\n",
        "            sub_pred = sub_idx.clone()\n",
        "            novel_mask_sub = max_sub_probs < tau_sub\n",
        "            sub_pred[novel_mask_sub] = NOVEL_SUB_IDX\n",
        "\n",
        "            match_sub = (sub_pred == sub_true)\n",
        "            sub_correct += match_sub.sum().item()\n",
        "\n",
        "            seen_mask_sub = (sub_true != NOVEL_SUB_IDX)\n",
        "            novel_mask_sub_label = (sub_true == NOVEL_SUB_IDX)\n",
        "\n",
        "            if seen_mask_sub.any():\n",
        "                seen_sub_correct += match_sub[seen_mask_sub].sum().item()\n",
        "                seen_sub_total   += seen_mask_sub.sum().item()\n",
        "            if novel_mask_sub_label.any():\n",
        "                # counted but not reported; there shouldn't be any in original val\n",
        "                novel_sub_correct += match_sub[novel_mask_sub_label].sum().item()\n",
        "                novel_sub_total   += novel_mask_sub_label.sum().item()\n",
        "\n",
        "    # ----- Compute metrics dict -----\n",
        "    metrics = {}\n",
        "\n",
        "    if total > 0:\n",
        "        if super_correct > 0 or seen_super_total + novel_super_total > 0:\n",
        "            metrics[\"overall_super_acc\"] = super_correct / total\n",
        "        if sub_correct > 0 or seen_sub_total + novel_sub_total > 0:\n",
        "            metrics[\"overall_sub_acc\"] = sub_correct / total\n",
        "\n",
        "    if seen_super_total > 0:\n",
        "        metrics[\"seen_super_acc\"] = seen_super_correct / seen_super_total\n",
        "        metrics[\"seen_super_false_novel\"] = 1.0 - metrics[\"seen_super_acc\"]\n",
        "    if novel_super_total > 0:\n",
        "        metrics[\"novel_super_acc\"] = novel_super_correct / novel_super_total\n",
        "\n",
        "    if seen_sub_total > 0:\n",
        "        metrics[\"seen_sub_acc\"] = seen_sub_correct / seen_sub_total\n",
        "        metrics[\"seen_sub_false_novel\"] = 1.0 - metrics[\"seen_sub_acc\"]\n",
        "    # NOTE: we deliberately do NOT add novel-sub metrics to `metrics`,\n",
        "    # because they are not meaningful for this dataset.\n",
        "\n",
        "    # ----- Print summary -----\n",
        "    print(f\"\\n=== Evaluation on {name} ===\")\n",
        "    if \"overall_super_acc\" in metrics:\n",
        "        print(f\"Overall superclass acc: {metrics['overall_super_acc']:.4f}\")\n",
        "    if \"overall_sub_acc\" in metrics:\n",
        "        print(f\"Overall subclass acc:   {metrics['overall_sub_acc']:.4f}\")\n",
        "\n",
        "    if \"seen_super_acc\" in metrics:\n",
        "        print(f\"Seen superclass acc (true super != novel):   {metrics['seen_super_acc']:.4f}\")\n",
        "        print(f\"Seen superclass false-novel rate:            {metrics['seen_super_false_novel']:.4f}\")\n",
        "    if \"novel_super_acc\" in metrics:\n",
        "        print(f\"Novel superclass acc (true super == novel):  {metrics['novel_super_acc']:.4f}\")\n",
        "\n",
        "    if \"seen_sub_acc\" in metrics:\n",
        "        print(f\"Seen subclass acc (true sub != novel):       {metrics['seen_sub_acc']:.4f}\")\n",
        "        print(f\"Seen subclass false-novel rate:              {metrics['seen_sub_false_novel']:.4f}\")\n",
        "\n",
        "    # ----- Optional: log to W&B (only real metrics) -----\n",
        "    if USE_WANDB:\n",
        "        log_dict = {}\n",
        "        for k, v in metrics.items():\n",
        "            log_dict[f\"{name}_{k}\"] = v\n",
        "        if log_dict:\n",
        "            wandb.log(log_dict)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# This enables us to evaluate how often we correctly mark held-out subclasses as novel (proxy for leaderboard performance on subclasses)\n",
        "@torch.no_grad()\n",
        "def evaluate_pseudo_novel_sub_with_novelty(model, mode=\"two_heads\",\n",
        "                                           tau_sub=TAU_SUB,\n",
        "                                           loader=None,\n",
        "                                           name=\"pseudo_novel_sub\"):\n",
        "    \"\"\"\n",
        "    Evaluate how well the model flags held-out subclasses as novel.\n",
        "\n",
        "    Assumes:\n",
        "      - loader yields only *held-out* subclasses (true unseen subclasses)\n",
        "      - true labels are NOT NOVEL_SUB_IDX, but we *want* the model to predict NOVEL_SUB_IDX.\n",
        "    \"\"\"\n",
        "    if loader is None:\n",
        "        loader = pseudo_novel_loader\n",
        "\n",
        "    if loader is None:\n",
        "        print(\"No pseudo_novel_loader available.\")\n",
        "        return {}\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total = 0\n",
        "    predicted_novel = 0\n",
        "    predicted_seen = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        images = batch[0].to(device)\n",
        "        # we don't actually need the labels here for correctness, only for counting\n",
        "\n",
        "        if mode == \"two_heads\":\n",
        "            _, sub_logits = model(images)\n",
        "        elif mode == \"sub_single_head\":\n",
        "            sub_logits = model(images)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode for pseudo-novel eval: {mode}\")\n",
        "\n",
        "        sub_probs = F.softmax(sub_logits, dim=1)\n",
        "        max_sub_probs, sub_idx = sub_probs.max(dim=1)\n",
        "\n",
        "        sub_pred = sub_idx.clone()\n",
        "        novel_mask_sub = max_sub_probs < tau_sub\n",
        "        sub_pred[novel_mask_sub] = NOVEL_SUB_IDX\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        predicted_novel += (sub_pred == NOVEL_SUB_IDX).sum().item()\n",
        "        predicted_seen  += (sub_pred != NOVEL_SUB_IDX).sum().item()\n",
        "\n",
        "    metrics = {}\n",
        "    if total > 0:\n",
        "        metrics[\"pseudo_novel_sub_novel_rate\"] = predicted_novel / total\n",
        "        metrics[\"pseudo_novel_sub_false_seen\"] = predicted_seen / total\n",
        "\n",
        "    print(f\"\\n=== Evaluation on {name} (held-out subclasses) ===\")\n",
        "    if total > 0:\n",
        "        print(f\"Fraction flagged as novel (good): {metrics['pseudo_novel_sub_novel_rate']:.4f}\")\n",
        "        print(f\"Fraction mapped to seen subclasses (bad): {metrics['pseudo_novel_sub_false_seen']:.4f}\")\n",
        "\n",
        "    if USE_WANDB and metrics:\n",
        "        log_dict = {f\"{name}_{k}\": v for k, v in metrics.items()}\n",
        "        wandb.log(log_dict)\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "bO9BTeC7rIwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dashboard for our evals so we can determine how model will likely perform on leaderboard evaluation\n",
        "\n",
        "@torch.no_grad()\n",
        "def novelty_dashboard(model, mode=\"two_heads\",\n",
        "                      tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                      include_pseudo=True):\n",
        "    \"\"\"\n",
        "    Run thresholded evals and show a compact table of key metrics.\n",
        "\n",
        "    Subclass side focuses on:\n",
        "      - seen subclasses (false-novel rate)\n",
        "      - held-out pseudo-novel subclasses (how often marked as novel)\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "\n",
        "    # --- Main val_loader stats (seen + CIFAR-novel) ---\n",
        "    val_metrics = evaluate_on_val_with_novelty(\n",
        "        model,\n",
        "        mode=mode,\n",
        "        tau_super=tau_super,\n",
        "        tau_sub=tau_sub,\n",
        "        loader=val_loader,\n",
        "        name=\"val\",\n",
        "    )\n",
        "\n",
        "    # Superclass (val)\n",
        "    if \"seen_super_acc\" in val_metrics:\n",
        "        rows.append({\n",
        "            \"Split\": \"val\",\n",
        "            \"Head\": \"super\",\n",
        "            \"Metric\": \"Seen superclass accuracy\",\n",
        "            \"Meaning\": \"Correctly keep seen superclasses as seen\",\n",
        "            \"Value\": float(val_metrics[\"seen_super_acc\"]),\n",
        "        })\n",
        "        if \"seen_super_false_novel\" in val_metrics:\n",
        "          rows.append({\n",
        "                \"Split\": \"val\",\n",
        "                \"Head\": \"super\",\n",
        "                \"Metric\": \"Seen superclass false-novel rate\",\n",
        "                \"Meaning\": \"Seen superclasses incorrectly flipped to novel\",\n",
        "                \"Value\": float(val_metrics[\"seen_super_false_novel\"]),\n",
        "            })\n",
        "\n",
        "    if \"novel_super_acc\" in val_metrics:\n",
        "        rows.append({\n",
        "            \"Split\": \"val\",\n",
        "            \"Head\": \"super\",\n",
        "            \"Metric\": \"Novel superclass accuracy (CIFAR)\",\n",
        "            \"Meaning\": \"CIFAR novel-super samples correctly predicted as novel\",\n",
        "            \"Value\": float(val_metrics[\"novel_super_acc\"]),\n",
        "        })\n",
        "\n",
        "    # Subclass (val) — ONLY seen-subclass metrics\n",
        "    if \"seen_sub_acc\" in val_metrics:\n",
        "        rows.append({\n",
        "            \"Split\": \"val\",\n",
        "            \"Head\": \"sub\",\n",
        "            \"Metric\": \"Seen subclass accuracy\",\n",
        "            \"Meaning\": \"Correctly keep seen subclasses as seen\",\n",
        "            \"Value\": float(val_metrics[\"seen_sub_acc\"]),\n",
        "        })\n",
        "        if \"seen_sub_false_novel\" in val_metrics:\n",
        "            rows.append({\n",
        "                \"Split\": \"val\",\n",
        "                \"Head\": \"sub\",\n",
        "                \"Metric\": \"Seen subclass false-novel rate\",\n",
        "                \"Meaning\": \"Seen subclasses incorrectly flipped to novel\",\n",
        "                \"Value\": float(val_metrics[\"seen_sub_false_novel\"]),\n",
        "            })\n",
        "    # NOTE: we deliberately do NOT add a \"novel subclass accuracy\" row here.\n",
        "\n",
        "    # --- Pseudo-novel subclass stats (held-out subclasses) ---\n",
        "    pseudo_metrics = {}\n",
        "    if include_pseudo and pseudo_novel_loader is not None and mode in (\"two_heads\", \"sub_single_head\"):\n",
        "        pseudo_metrics = evaluate_pseudo_novel_sub_with_novelty(\n",
        "            model,\n",
        "            mode=mode,\n",
        "            tau_sub=tau_sub,\n",
        "            loader=pseudo_novel_loader,\n",
        "            name=\"pseudo_novel_sub\",\n",
        "        )\n",
        "\n",
        "        if \"pseudo_novel_sub_novel_rate\" in pseudo_metrics:\n",
        "            rows.append({\n",
        "                \"Split\": \"pseudo_novel\",\n",
        "                \"Head\": \"sub\",\n",
        "                \"Metric\": \"Pseudo-novel marked as novel\",\n",
        "                \"Meaning\": \"Held-out subclasses correctly flagged as novel\",\n",
        "                \"Value\": float(pseudo_metrics[\"pseudo_novel_sub_novel_rate\"]),\n",
        "            })\n",
        "        if \"pseudo_novel_sub_false_seen\" in pseudo_metrics:\n",
        "            rows.append({\n",
        "                \"Split\": \"pseudo_novel\",\n",
        "                \"Head\": \"sub\",\n",
        "                \"Metric\": \"Pseudo-novel mapped to seen\",\n",
        "                \"Meaning\": \"Held-out subclasses wrongly mapped to some seen subclass\",\n",
        "                \"Value\": float(pseudo_metrics[\"pseudo_novel_sub_false_seen\"]),\n",
        "            })\n",
        "\n",
        "    # --- Config / settings summary (for *printing* only) ---\n",
        "    config_rows = [\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"BACKBONE\",\n",
        "            \"Meaning\": \"Feature extractor (e.g. resnet18 / resnet50)\",\n",
        "            \"Value\": BACKBONE,\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"TAU_SUPER\",\n",
        "            \"Meaning\": \"Novelty threshold for superclass head\",\n",
        "            \"Value\": str(tau_super),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"TAU_SUB\",\n",
        "            \"Meaning\": \"Novelty threshold for subclass head\",\n",
        "            \"Value\": str(tau_sub),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"CIFAR_NOVEL_MODE\",\n",
        "            \"Meaning\": \"Extra novel-super CIFAR data mode\",\n",
        "            \"Value\": str(CIFAR_NOVEL_MODE),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"FINE_TUNE_MODE\",\n",
        "            \"Meaning\": \"Backbone training mode (full vs frozen)\",\n",
        "            \"Value\": str(FINE_TUNE_MODE),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"APPROACH\",\n",
        "            \"Meaning\": \"Model architecture (two_heads vs two_models)\",\n",
        "            \"Value\": str(APPROACH),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"USE_PSEUDO_NOVEL\",\n",
        "            \"Meaning\": \"Using held-out subclasses for pseudo-novel eval\",\n",
        "            \"Value\": str(bool(USE_PSEUDO_NOVEL)),\n",
        "        },\n",
        "        {\n",
        "            \"Split\": \"config\",\n",
        "            \"Head\": \"-\",\n",
        "            \"Metric\": \"DATA_AUGMENT\",\n",
        "            \"Meaning\": \"Whether data augmentation is enabled for training\",\n",
        "            \"Value\": str(bool(DATA_AUGMENT)),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    rows.extend(config_rows)\n",
        "\n",
        "    if not rows:\n",
        "        print(\"No metrics to display in dashboard.\")\n",
        "        return None\n",
        "\n",
        "    dashboard_df = pd.DataFrame(rows)\n",
        "    dashboard_df = dashboard_df.sort_values(\n",
        "        by=[\"Split\", \"Head\", \"Metric\"]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    print(\"\\n==== Novelty Dashboard ====\")\n",
        "    print(dashboard_df)\n",
        "\n",
        "    # --- Log to W&B: metrics only, numeric Value column ---\n",
        "    if USE_WANDB:\n",
        "        try:\n",
        "            wandb_table_df = dashboard_df.copy()\n",
        "\n",
        "            def _to_str(v):\n",
        "                if isinstance(v, float):\n",
        "                    return f\"{v:.6f}\"\n",
        "                return str(v)\n",
        "\n",
        "            wandb_table_df[\"Split\"] = wandb_table_df[\"Split\"].astype(str)\n",
        "            wandb_table_df[\"Head\"] = wandb_table_df[\"Head\"].astype(str)\n",
        "            wandb_table_df[\"Metric\"] = wandb_table_df[\"Metric\"].astype(str)\n",
        "            wandb_table_df[\"Meaning\"] = wandb_table_df[\"Meaning\"].astype(str)\n",
        "            wandb_table_df[\"Value\"] = wandb_table_df[\"Value\"].apply(_to_str)\n",
        "\n",
        "            wandb.log({\"novelty_dashboard\": wandb.Table(dataframe=wandb_table_df)})\n",
        "        except Exception as e:\n",
        "            print(\"Could not log dashboard table to W&B:\", e)\n",
        "\n",
        "    return dashboard_df\n",
        "\n"
      ],
      "metadata": {
        "id": "U11cdLGHxFa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper to choose backbone (freeze or full) and choose optimizer parameter\n",
        "\n",
        "def setup_backbone_training(model, fine_tune_mode=\"full\", lr_full=1e-4, lr_head=1e-3):\n",
        "    \"\"\"\n",
        "    Given a model with attributes:\n",
        "        - model.backbone  (all feature extractor layers)\n",
        "        - head layers (e.g. super/sub heads) as other modules,\n",
        "    freeze or unfreeze the backbone and return an optimizer.\n",
        "\n",
        "    Returns:\n",
        "        optimizer, effective_lr\n",
        "    \"\"\"\n",
        "    if fine_tune_mode == \"full\":\n",
        "        # Everything trainable\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "        trainable_params = model.parameters()\n",
        "        lr = lr_full\n",
        "    elif fine_tune_mode == \"frozen\":\n",
        "        # Freeze backbone, train only heads\n",
        "        for p in model.backbone.parameters():\n",
        "            p.requires_grad = False\n",
        "        # Only parameters that still require grad will be optimized\n",
        "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "        lr = lr_head\n",
        "        print(f\"Freezing backbone; training {len(trainable_params)} parameter tensors in heads only.\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown FINE_TUNE_MODE: {fine_tune_mode}\")\n",
        "\n",
        "    optimizer = optim.Adam(trainable_params, lr=lr, weight_decay=WEIGHT_DECAY)\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "DVHcWqkOdomF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 6: Approach A: Shared backbone, two heads + KL"
      ],
      "metadata": {
        "id": "wpvDqfhKRKQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original idea\n",
        "\n",
        "LR = 1e-4 # maybe two different learning rates\n",
        "ALPHA_KL = 0.1\n",
        "TEMPERATURE = 1.0\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    model_two_heads = SharedBackboneTwoHeads(\n",
        "        num_super=num_super,\n",
        "        num_sub=num_sub\n",
        "    ).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = setup_backbone_training(\n",
        "        model_two_heads,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_two_heads = None\n",
        "    if USE_WANDB:\n",
        "        run_two_heads = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_heads_kl_resnet\"),\n",
        "            group=\"two_heads\",  # to group/filter all two_heads runs\n",
        "            config={\n",
        "                \"approach\": \"two_heads_kl\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"alpha_kl\": ALPHA_KL,\n",
        "                \"temperature\": TEMPERATURE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_score = 0.0\n",
        "\n",
        "    print(\"Training shared-backbone two-heads model (KL-coupled):\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_two_heads,\n",
        "            optimizer,\n",
        "            train_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_two_heads,\n",
        "            val_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_acc_super = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        val_acc_sub = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        val_loss = val_metrics[\"val_loss\"]\n",
        "\n",
        "        print(\n",
        "            f\"[Two-heads] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_loss:.4f}, \"\n",
        "            f\"val_acc_super={val_acc_super:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc_sub:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            # prefix metrics so they don't collide with two-model ones\n",
        "            log_dict = {\n",
        "                \"epoch\": epoch,\n",
        "                \"two_heads_train_loss\": train_metrics[\"loss\"],\n",
        "                \"two_heads_val_loss\": val_loss,\n",
        "                \"two_heads_val_acc_super\": val_acc_super,\n",
        "                \"two_heads_val_acc_sub\": val_acc_sub,\n",
        "            }\n",
        "            wandb.log(log_dict, step=epoch)\n",
        "\n",
        "        # simple combined score: average of super/sub val accuracy\n",
        "        val_score = 0.5 * val_acc_super + 0.5 * val_acc_sub\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(\n",
        "                model_two_heads.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best two-heads model\")\n",
        "\n",
        "\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "\n",
        "    analyze_tau_sub(model_two_heads, mode=\"two_heads\")\n",
        "    analyze_tau_super(model_two_heads, mode=\"two_heads\")\n",
        "    evaluate_on_val_with_novelty(model_two_heads, mode=\"two_heads\",\n",
        "                             tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                             loader=val_loader, name=\"val_two_heads\")\n",
        "    evaluate_pseudo_novel_sub_with_novelty(\n",
        "        model_two_heads, mode=\"two_heads\", tau_sub=TAU_SUB\n",
        "    )\n",
        "    novelty_dashboard(model_two_heads, mode=\"two_heads\",\n",
        "                  tau_super=TAU_SUPER, tau_sub=TAU_SUB)\n",
        "\n",
        "    if run_two_heads is not None:\n",
        "        run_two_heads.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads training in this cell.\")"
      ],
      "metadata": {
        "id": "vxn7j1w1RRJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36fe8dff-7d09-4a18-b084-030b26c6b822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads training in this cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aksel Modifications\n"
      ],
      "metadata": {
        "id": "vxEUMhWy76FL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newer Resnet"
      ],
      "metadata": {
        "id": "C_u4IkoPCeyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_resnet_backbone(backbone: str=BACKBONE):\n",
        "    # Using torchvision ResNet-18 with ImageNet weights\n",
        "    if backbone == \"resnet18\":\n",
        "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    elif backbone == \"resnet50\":\n",
        "        base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown BACKBONE: {backbone}\")\n",
        "    # Remove the final classification layer\n",
        "    in_features = base.fc.in_features\n",
        "    base.fc = nn.Identity()  # type: ignore[assignment]\n",
        "    return base, in_features"
      ],
      "metadata": {
        "id": "k7KGVOOfChPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New training routine\n"
      ],
      "metadata": {
        "id": "EmDohY_tAARW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    loader: torch.utils.data.DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    mode: str,\n",
        "    sub_to_super: dict|None = None,\n",
        "    num_super: int | None = None,\n",
        "    trained_superclass_model: nn.Module | None = None,\n",
        "    alpha_kl=0.1,\n",
        "    temperature=1.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Optionally, add super class to calculate KL divergence penalty\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    super_correct = sub_correct = 0\n",
        "    super_total = sub_total = 0\n",
        "    loss: torch.Tensor\n",
        "\n",
        "    for images, super_labels, sub_labels in loader:\n",
        "        images: torch.Tensor\n",
        "        super_labels: torch.Tensor\n",
        "        sub_labels: torch.Tensor\n",
        "        images = images.to(device)\n",
        "        super_labels = super_labels.to(device)\n",
        "        sub_labels = sub_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if mode == \"two_heads_kl\":\n",
        "            super_logits, sub_logits = model(images)\n",
        "            # CE losses\n",
        "            loss_super = criterion(super_logits, super_labels)\n",
        "            loss_sub = criterion(sub_logits, sub_labels)\n",
        "\n",
        "            # KL term between super head and aggregated subclass head\n",
        "            with torch.no_grad():\n",
        "                # target: super_probs\n",
        "                super_probs = F.softmax(super_logits / temperature, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits / temperature, dim=1)\n",
        "            agg_super_probs = sub_probs_to_super_probs(sub_probs, sub_to_super, num_super)\n",
        "\n",
        "            # KL(super || agg_super) = sum p * (log p - log q)\n",
        "            # using KLDivLoss with log_softmax input and probs target:\n",
        "            kl_loss = F.kl_div(\n",
        "                F.log_softmax(super_logits / temperature, dim=1),\n",
        "                (agg_super_probs + 1e-8).log(),\n",
        "                reduction=\"batchmean\",\n",
        "                log_target=True,\n",
        "            )\n",
        "\n",
        "            loss = loss_super + loss_sub + alpha_kl * kl_loss\n",
        "\n",
        "            sc, st = accuracy_from_logits(super_logits, super_labels)\n",
        "            suc, sut = accuracy_from_logits(sub_logits, sub_labels)\n",
        "            super_correct += sc\n",
        "            super_total += st\n",
        "            sub_correct += suc\n",
        "            sub_total += sut\n",
        "\n",
        "        elif mode in (\"single_head_super\", \"single_head_sub\"):\n",
        "            logits: torch.Tensor = model(images)\n",
        "            if mode == \"single_head_super\":\n",
        "                loss = criterion(logits, super_labels)\n",
        "                sc, st = accuracy_from_logits(logits, super_labels)\n",
        "                super_correct += sc\n",
        "                super_total += st\n",
        "            else:\n",
        "                # Base subclass CE loss\n",
        "                loss_sub = criterion(logits, sub_labels)\n",
        "\n",
        "                # Optional: superclass-consistency penalty using a pretrained superclass \"teacher\"\n",
        "                # Idea: teacher gives p(super|x). We aggregate the subclass head's probabilities into\n",
        "                # q(super|x) by summing subclass probs within each super. Penalize mismatch.\n",
        "                loss_consistency = torch.zeros((), device=device)\n",
        "\n",
        "                if trained_superclass_model is not None:\n",
        "                    assert sub_to_super is not None, \"sub_to_super mapping required for superclass-consistency\"\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        super_teacher_logits = trained_superclass_model(images)\n",
        "                        super_teacher_probs = F.softmax(super_teacher_logits, dim=1)\n",
        "\n",
        "                    # Aggregate subclass probs to super probs\n",
        "                    sub_probs = F.softmax(logits, dim=1)\n",
        "                    agg_super_probs = sub_probs_to_super_probs(sub_probs, sub_to_super, num_super)\n",
        "\n",
        "                    # Consistency loss option A (soft): KL( teacher || agg_super )\n",
        "                    # Avoid 0 * log 0 by clamping.\n",
        "                    eps = 1e-8\n",
        "                    loss_consistency = F.kl_div(\n",
        "                        (agg_super_probs.clamp_min(eps)).log(),\n",
        "                        super_teacher_probs,\n",
        "                        reduction=\"batchmean\",\n",
        "                    )\n",
        "\n",
        "                    # Consistency loss option B (hard): encourage probability mass to fall inside the teacher's top super\n",
        "                    # Uncomment to add this as well.\n",
        "                    # in_super_prob = agg_super_probs.gather(1, super_pred_indices.unsqueeze(1)).squeeze(1)\n",
        "                    # loss_consistency = loss_consistency + (-torch.log(in_super_prob.clamp_min(eps))).mean()\n",
        "\n",
        "                # Weight the consistency term (tune as needed)\n",
        "                loss = loss_sub + ALPHA_SUPER_CONSISTENCY * loss_consistency\n",
        "\n",
        "                suc, sut = accuracy_from_logits(logits, sub_labels)\n",
        "                sub_correct += suc\n",
        "                sub_total += sut\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown mode {mode}\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    metrics = {\"loss\": avg_loss}\n",
        "    if super_total > 0:\n",
        "        metrics[\"acc_super\"] = super_correct / super_total\n",
        "    if sub_total > 0:\n",
        "        metrics[\"acc_sub\"] = sub_correct / sub_total\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "AbNjD1zi8nxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Single Head"
      ],
      "metadata": {
        "id": "puYVpKyv_5G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-head model for 2-separate models approach\n",
        "# Each model is just a backbone + one linear head\n",
        "\n",
        "# to instantiate, one has num_classes = num_super, other has num_classes = num_sub\n",
        "\n",
        "class CosineClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Cosine-similarity classifier (normalized linear head).\n",
        "    logits = scale * cos(theta), where cos(theta)=<normalize(x), normalize(W)>.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features: int, out_features: int, scale: float = 30.0, learn_scale: bool = True):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "        if learn_scale:\n",
        "            self.scale = nn.Parameter(torch.tensor(float(scale)))\n",
        "        else:\n",
        "            self.register_buffer(\"scale\", torch.tensor(float(scale)))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.normalize(x, p=2, dim=1)  # [B, D]\n",
        "        w = F.normalize(self.weight, p=2, dim=1)  # [C, D]\n",
        "        logits = x @ w.t()  # [B, C]\n",
        "        return logits * self.scale\n",
        "\n",
        "\n",
        "class SingleHeadModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int,\n",
        "        head: str,  # \"linear\" or \"cosine\"\n",
        "        cosine_scale: float = 30.0,\n",
        "        learn_scale: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.backbone, feat_dim = build_resnet_backbone()\n",
        "\n",
        "        if head == \"cosine\":\n",
        "            self.head = nn.Sequential(\n",
        "                CosineClassifier(\n",
        "                    in_features=feat_dim,\n",
        "                    out_features=(out := num_classes),\n",
        "                    scale=cosine_scale,\n",
        "                    learn_scale=learn_scale,\n",
        "                ),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(out, num_classes),\n",
        "            )\n",
        "        elif head == \"linear\":\n",
        "            self.head = nn.Linear(feat_dim, num_classes)\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        feats = self.backbone(x)\n",
        "        logits = self.head(feats)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "K-Vk_1CG-wn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print Vars"
      ],
      "metadata": {
        "id": "LeTzRQ6u-qKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUPER_HEAD_TYPE = \"linear\"  # \"linear\" or \"cosine\"\n",
        "SUB_HEAD_TYPE = \"cosine\"  # \"linear\" or \"cosine\"\n",
        "ALPHA_SUPER_CONSISTENCY = 0.2 # unused\n",
        "USE_PSUDEO_NOVEL = False"
      ],
      "metadata": {
        "id": "3c_qp4Fx8Ywb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(BACKBONE, FINE_TUNE_MODE, SUPER_HEAD_TYPE, SUB_HEAD_TYPE, USE_PSEUDO_NOVEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys-ZBQoo702R",
        "outputId": "18dc426f-7400-4cc6-bb04-8e8f844a162a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet50 full linear cosine True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 7: Approach B - Two separate models"
      ],
      "metadata": {
        "id": "fNtlQWujRg4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Super"
      ],
      "metadata": {
        "id": "qAj1ryz0_cIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Second idea to compare\n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "if APPROACH == \"two_models\":\n",
        "    # Superclass model\n",
        "    model_super = SingleHeadModel(num_classes=num_super, head=SUPER_HEAD_TYPE).to(device)\n",
        "    criterion_super = nn.CrossEntropyLoss()\n",
        "    optimizer_super = setup_backbone_training(\n",
        "        model_super,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_super = None\n",
        "    if USE_WANDB:\n",
        "        run_super = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_super_resnet\"),\n",
        "            group=\"two_models\",   # to filter all two_models runs together\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"super\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "                'super_head_type': SUPER_HEAD_TYPE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_super = 0.0\n",
        "\n",
        "    print(\"Training superclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_super,\n",
        "            optimizer_super,\n",
        "            train_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_super,\n",
        "            val_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        print(\n",
        "            f\"[Super] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_super={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"super_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"super_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"super_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_super:\n",
        "            best_val_super = val_acc\n",
        "            torch.save(\n",
        "                model_super.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_super_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best superclass model\")\n",
        "        if val_acc ==1.0:\n",
        "          print('ACHIEVED PERFECT SCORE.')\n",
        "\n",
        "    if run_super is not None:\n",
        "        run_super.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "RPa25bz6RlhN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "ef7a06b6-2a2c-4796-94cf-47e67db550a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_182146-mg0dg7cw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/mg0dg7cw' target=\"_blank\">two_models_super_resnet_20251214_182145</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/mg0dg7cw' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/mg0dg7cw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training superclass model:\n",
            "[Super] Epoch 1: train_loss=0.2098, val_loss=0.0126, val_acc_super=0.9932\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 2: train_loss=0.0141, val_loss=0.0059, val_acc_super=0.9981\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 3: train_loss=0.0077, val_loss=0.0042, val_acc_super=0.9990\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 4: train_loss=0.0044, val_loss=0.0016, val_acc_super=1.0000\n",
            "  Saved new best superclass model\n",
            "ACHIEVED PERFECT SCORE.\n",
            "[Super] Epoch 5: train_loss=0.0033, val_loss=0.0036, val_acc_super=0.9990\n",
            "[Super] Epoch 6: train_loss=0.0037, val_loss=0.0045, val_acc_super=0.9990\n",
            "[Super] Epoch 7: train_loss=0.0021, val_loss=0.0077, val_acc_super=0.9981\n",
            "[Super] Epoch 8: train_loss=0.0016, val_loss=0.0018, val_acc_super=0.9990\n",
            "[Super] Epoch 9: train_loss=0.0018, val_loss=0.0082, val_acc_super=0.9971\n",
            "[Super] Epoch 10: train_loss=0.0007, val_loss=0.0012, val_acc_super=1.0000\n",
            "ACHIEVED PERFECT SCORE.\n",
            "[Super] Epoch 11: train_loss=0.0029, val_loss=0.0012, val_acc_super=1.0000\n",
            "ACHIEVED PERFECT SCORE.\n",
            "[Super] Epoch 12: train_loss=0.0026, val_loss=0.0008, val_acc_super=1.0000\n",
            "ACHIEVED PERFECT SCORE.\n",
            "[Super] Epoch 13: train_loss=0.0006, val_loss=0.0017, val_acc_super=0.9990\n",
            "[Super] Epoch 14: train_loss=0.0059, val_loss=0.0008, val_acc_super=1.0000\n",
            "ACHIEVED PERFECT SCORE.\n",
            "[Super] Epoch 15: train_loss=0.0033, val_loss=0.0004, val_acc_super=1.0000\n",
            "ACHIEVED PERFECT SCORE.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>super_train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>super_val_acc</td><td>▁▆▇█▇▇▆▇▅███▇██</td></tr><tr><td>super_val_loss</td><td>█▄▃▂▃▃▅▂▅▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>super_train_loss</td><td>0.00332</td></tr><tr><td>super_val_acc</td><td>1</td></tr><tr><td>super_val_loss</td><td>0.00041</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_super_resnet_20251214_182145</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/mg0dg7cw' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/mg0dg7cw</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_182146-mg0dg7cw/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sub Class Training"
      ],
      "metadata": {
        "id": "sXnGsr9P_qlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if APPROACH == \"two_models\":\n",
        "  # Subclass model\n",
        "    model_sub = SingleHeadModel(num_classes=num_sub, head=SUB_HEAD_TYPE).to(device)\n",
        "    criterion_sub = nn.CrossEntropyLoss()\n",
        "    optimizer_sub = setup_backbone_training(\n",
        "        model_sub,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_sub = None\n",
        "    if USE_WANDB:\n",
        "        run_sub = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_sub_resnet\"),\n",
        "            group=\"two_models\",\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"sub\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "                'sub_head_type': SUB_HEAD_TYPE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_sub = 0.0\n",
        "\n",
        "    print(\"\\nTraining subclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_sub,\n",
        "            optimizer_sub,\n",
        "            train_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_sub,\n",
        "            val_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        print(\n",
        "            f\"[Sub] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"sub_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"sub_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"sub_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_sub:\n",
        "            best_val_sub = val_acc\n",
        "            torch.save(\n",
        "                model_sub.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_sub_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best subclass model\")\n",
        "\n",
        "    if run_sub is not None:\n",
        "        run_sub.finish()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "Xe0F0miB_JYW",
        "outputId": "1d06337e-5767-4e61-a11e-21d3bfa6559c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_182306-oz6zoxv7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/oz6zoxv7' target=\"_blank\">two_models_sub_resnet_20251214_182305</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/oz6zoxv7' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/oz6zoxv7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training subclass model:\n",
            "[Sub] Epoch 1: train_loss=2.4963, val_loss=1.4422, val_acc_sub=0.7602\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 2: train_loss=0.8537, val_loss=0.3808, val_acc_sub=0.9352\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 3: train_loss=0.2495, val_loss=0.1471, val_acc_sub=0.9642\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 4: train_loss=0.1251, val_loss=0.1204, val_acc_sub=0.9623\n",
            "[Sub] Epoch 5: train_loss=0.0797, val_loss=0.1175, val_acc_sub=0.9613\n",
            "[Sub] Epoch 6: train_loss=0.0569, val_loss=0.1131, val_acc_sub=0.9652\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 7: train_loss=0.0529, val_loss=0.1042, val_acc_sub=0.9681\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 8: train_loss=0.0372, val_loss=0.0824, val_acc_sub=0.9749\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 9: train_loss=0.0328, val_loss=0.0974, val_acc_sub=0.9671\n",
            "[Sub] Epoch 10: train_loss=0.0302, val_loss=0.1236, val_acc_sub=0.9652\n",
            "[Sub] Epoch 11: train_loss=0.0179, val_loss=0.0716, val_acc_sub=0.9787\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 12: train_loss=0.0262, val_loss=0.1177, val_acc_sub=0.9671\n",
            "[Sub] Epoch 13: train_loss=0.0258, val_loss=0.0949, val_acc_sub=0.9691\n",
            "[Sub] Epoch 14: train_loss=0.0225, val_loss=0.0767, val_acc_sub=0.9807\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 15: train_loss=0.0185, val_loss=0.0988, val_acc_sub=0.9739\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>sub_train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sub_val_acc</td><td>▁▇▇▇▇██████████</td></tr><tr><td>sub_val_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>sub_train_loss</td><td>0.01852</td></tr><tr><td>sub_val_acc</td><td>0.97389</td></tr><tr><td>sub_val_loss</td><td>0.09878</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_sub_resnet_20251214_182305</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/oz6zoxv7' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/oz6zoxv7</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_182306-oz6zoxv7/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ],
      "metadata": {
        "id": "ZOBKZcoB_wx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TAU_SUB = 0.85"
      ],
      "metadata": {
        "id": "LFu_J0kbDvAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if APPROACH == \"two_models\":\n",
        "    best_super_path = os.path.join(DATA_ROOT, \"best_super_model.pth\")\n",
        "    best_sub_path   = os.path.join(DATA_ROOT, \"best_sub_model.pth\")\n",
        "    model_super.load_state_dict(torch.load(best_super_path, map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(best_sub_path,   map_location=device))\n",
        "\n",
        "    run_eval = None\n",
        "    if USE_WANDB:\n",
        "        run_eval = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_eval_resnet\"),\n",
        "            group=\"two_models\",\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"sub\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "                'sub_head_type': SUB_HEAD_TYPE,\n",
        "                'super_head_type': SUPER_HEAD_TYPE,\n",
        "                'tau_sub': TAU_SUB,\n",
        "                'tau_super': TAU_SUPER,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    analyze_tau_sub(model_sub, mode=\"sub_single_head\")\n",
        "    analyze_tau_super(model_super, mode=\"super_single_head\")\n",
        "    evaluate_on_val_with_novelty(model_super, mode=\"super_single_head\",\n",
        "                             tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                             loader=val_loader, name=\"val_super_only\")\n",
        "    evaluate_on_val_with_novelty(model_sub, mode=\"sub_single_head\",\n",
        "                             tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                             loader=val_loader, name=\"val_sub_only\")\n",
        "    evaluate_pseudo_novel_sub_with_novelty(\n",
        "        model_sub, mode=\"sub_single_head\", tau_sub=TAU_SUB\n",
        "    )\n",
        "    novelty_dashboard(model_super, mode=\"super_single_head\",\n",
        "                  tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                  include_pseudo=False)  # no pseudo-novel meaning for super head\n",
        "    novelty_dashboard(model_sub, mode=\"sub_single_head\",\n",
        "                  tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "                  include_pseudo=True)\n",
        "\n",
        "    if run_eval is not None:\n",
        "        run_eval.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-model training in this cell.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1X62zVCV_O9a",
        "outputId": "6a39a6ce-fa09-4bcb-a881-466d473da43d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_182426-eaqmpnun</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/eaqmpnun' target=\"_blank\">two_models_eval_resnet_20251214_182426</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/eaqmpnun' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/eaqmpnun</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Seen subclass max-prob stats:\n",
            "  count = 1034\n",
            "  mean  = 0.983\n",
            "  std   = 0.069\n",
            "  percentiles:\n",
            "    p 1: 0.612\n",
            "    p 5: 0.936\n",
            "    p10: 0.982\n",
            "    p25: 0.996\n",
            "    p50: 0.999\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Pseudo-novel subclass max-prob stats:\n",
            "  count = 948\n",
            "  mean  = 0.724\n",
            "  std   = 0.264\n",
            "  percentiles:\n",
            "    p 1: 0.116\n",
            "    p 5: 0.226\n",
            "    p10: 0.307\n",
            "    p25: 0.522\n",
            "    p50: 0.810\n",
            "    p75: 0.964\n",
            "    p90: 0.993\n",
            "    p95: 0.996\n",
            "    p99: 0.997\n",
            "\n",
            "Suggested TAU_SUB candidates:\n",
            "  tau_sub ≈ 10th percentile of seen: 0.982\n",
            "  tau_sub ≈ mean(seen + pseudo)/2:  0.854\n",
            "\n",
            "You can start with one of these for TAU_SUB and adjust based on leaderboard/behavior.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged histograms and tau_sub candidates to Weights & Biases.\n",
            "\n",
            "Seen superclasses (0/1/2) superclass max-prob stats:\n",
            "  count = 534\n",
            "  mean  = 0.998\n",
            "  std   = 0.028\n",
            "  percentiles:\n",
            "    p 1: 0.982\n",
            "    p 5: 0.997\n",
            "    p10: 0.999\n",
            "    p25: 1.000\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Novel superclasses (== NOVEL_SUPER_IDX) superclass max-prob stats:\n",
            "  count = 500\n",
            "  mean  = 1.000\n",
            "  std   = 0.000\n",
            "  percentiles:\n",
            "    p 1: 0.999\n",
            "    p 5: 1.000\n",
            "    p10: 1.000\n",
            "    p25: 1.000\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Suggested TAU_SUPER candidates (using seen + novel):\n",
            "  tau_super ≈ 10th percentile of seen:       0.999\n",
            "  tau_super ≈ 5th percentile of seen:        0.997\n",
            "  tau_super ≈ mean(seen) - std(seen):        0.970\n",
            "  tau_super ≈ mean(seen & novel) midpoint:   0.999\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged superclass histograms and tau_super candidates to Weights & Biases.\n",
            "\n",
            "=== Evaluation on val_super_only ===\n",
            "Overall superclass acc: 0.9913\n",
            "Seen superclass acc (true super != novel):   0.9831\n",
            "Seen superclass false-novel rate:            0.0169\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "=== Evaluation on val_sub_only ===\n",
            "Overall subclass acc:   0.9584\n",
            "Seen subclass acc (true sub != novel):       0.9195\n",
            "Seen subclass false-novel rate:              0.0805\n",
            "\n",
            "=== Evaluation on pseudo_novel_sub (held-out subclasses) ===\n",
            "Fraction flagged as novel (good): 0.5464\n",
            "Fraction mapped to seen subclasses (bad): 0.4536\n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall superclass acc: 0.9913\n",
            "Seen superclass acc (true super != novel):   0.9831\n",
            "Seen superclass false-novel rate:            0.0169\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "     Split   Head                             Metric  \\\n",
            "0   config      -                           APPROACH   \n",
            "1   config      -                           BACKBONE   \n",
            "2   config      -                   CIFAR_NOVEL_MODE   \n",
            "3   config      -                       DATA_AUGMENT   \n",
            "4   config      -                     FINE_TUNE_MODE   \n",
            "5   config      -                            TAU_SUB   \n",
            "6   config      -                          TAU_SUPER   \n",
            "7   config      -                   USE_PSEUDO_NOVEL   \n",
            "8      val  super  Novel superclass accuracy (CIFAR)   \n",
            "9      val  super           Seen superclass accuracy   \n",
            "10     val  super   Seen superclass false-novel rate   \n",
            "\n",
            "                                              Meaning       Value  \n",
            "0        Model architecture (two_heads vs two_models)  two_models  \n",
            "1        Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                   Extra novel-super CIFAR data mode       large  \n",
            "3   Whether data augmentation is enabled for training        True  \n",
            "4             Backbone training mode (full vs frozen)        full  \n",
            "5                 Novelty threshold for subclass head        0.85  \n",
            "6               Novelty threshold for superclass head        0.99  \n",
            "7     Using held-out subclasses for pseudo-novel eval        True  \n",
            "8   CIFAR novel-super samples correctly predicted ...         1.0  \n",
            "9            Correctly keep seen superclasses as seen    0.983146  \n",
            "10     Seen superclasses incorrectly flipped to novel    0.016854  \n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall subclass acc:   0.9584\n",
            "Seen subclass acc (true sub != novel):       0.9195\n",
            "Seen subclass false-novel rate:              0.0805\n",
            "\n",
            "=== Evaluation on pseudo_novel_sub (held-out subclasses) ===\n",
            "Fraction flagged as novel (good): 0.5464\n",
            "Fraction mapped to seen subclasses (bad): 0.4536\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "           Split Head                          Metric  \\\n",
            "0         config    -                        APPROACH   \n",
            "1         config    -                        BACKBONE   \n",
            "2         config    -                CIFAR_NOVEL_MODE   \n",
            "3         config    -                    DATA_AUGMENT   \n",
            "4         config    -                  FINE_TUNE_MODE   \n",
            "5         config    -                         TAU_SUB   \n",
            "6         config    -                       TAU_SUPER   \n",
            "7         config    -                USE_PSEUDO_NOVEL   \n",
            "8   pseudo_novel  sub     Pseudo-novel mapped to seen   \n",
            "9   pseudo_novel  sub    Pseudo-novel marked as novel   \n",
            "10           val  sub          Seen subclass accuracy   \n",
            "11           val  sub  Seen subclass false-novel rate   \n",
            "\n",
            "                                              Meaning       Value  \n",
            "0        Model architecture (two_heads vs two_models)  two_models  \n",
            "1        Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                   Extra novel-super CIFAR data mode       large  \n",
            "3   Whether data augmentation is enabled for training        True  \n",
            "4             Backbone training mode (full vs frozen)        full  \n",
            "5                 Novelty threshold for subclass head        0.85  \n",
            "6               Novelty threshold for superclass head        0.99  \n",
            "7     Using held-out subclasses for pseudo-novel eval        True  \n",
            "8   Held-out subclasses wrongly mapped to some see...    0.453586  \n",
            "9      Held-out subclasses correctly flagged as novel    0.546414  \n",
            "10             Correctly keep seen subclasses as seen    0.919476  \n",
            "11       Seen subclasses incorrectly flipped to novel    0.080524  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pseudo_novel_sub_pseudo_novel_sub_false_seen</td><td>▁▁</td></tr><tr><td>pseudo_novel_sub_pseudo_novel_sub_novel_rate</td><td>▁▁</td></tr><tr><td>tau_sub_candidate_mean_midpoint</td><td>▁</td></tr><tr><td>tau_sub_candidate_p10_seen</td><td>▁</td></tr><tr><td>tau_super_candidate_1</td><td>▁</td></tr><tr><td>tau_super_candidate_2</td><td>▁</td></tr><tr><td>tau_super_candidate_3</td><td>▁</td></tr><tr><td>val_novel_super_acc</td><td>▁</td></tr><tr><td>val_overall_sub_acc</td><td>▁</td></tr><tr><td>val_overall_super_acc</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pseudo_novel_sub_pseudo_novel_sub_false_seen</td><td>0.45359</td></tr><tr><td>pseudo_novel_sub_pseudo_novel_sub_novel_rate</td><td>0.54641</td></tr><tr><td>tau_sub_candidate_mean_midpoint</td><td>0.85361</td></tr><tr><td>tau_sub_candidate_p10_seen</td><td>0.98222</td></tr><tr><td>tau_super_candidate_1</td><td>0.99895</td></tr><tr><td>tau_super_candidate_2</td><td>0.99705</td></tr><tr><td>tau_super_candidate_3</td><td>0.97</td></tr><tr><td>val_novel_super_acc</td><td>1</td></tr><tr><td>val_overall_sub_acc</td><td>0.95841</td></tr><tr><td>val_overall_super_acc</td><td>0.9913</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_eval_resnet_20251214_182426</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/eaqmpnun' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/eaqmpnun</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_182426-eaqmpnun/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 8: Test-time Inference & CSV Export for leaderboard **(two-head model)**"
      ],
      "metadata": {
        "id": "mfZTFepgRxey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference in order to predict \"novel\" superclass / subclasses\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_test_two_heads(model, test_loader, tau_super=TAU_SUPER, tau_sub=TAU_SUB):\n",
        "    \"\"\"\n",
        "    Inference for the two-heads model with novelty thresholds.\n",
        "\n",
        "    model:       SharedBackboneTwoHeads(...)\n",
        "    test_loader: DataLoader yielding (images, img_names)\n",
        "    tau_super:   threshold for superclass novelty\n",
        "    tau_sub:     threshold for subclass novelty\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    images_list = []\n",
        "    super_preds = []\n",
        "    sub_preds = []\n",
        "\n",
        "    for images, img_names in test_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "\n",
        "        # Forward pass once\n",
        "        super_logits, sub_logits = model(images)    # (B, num_super), (B, num_sub)\n",
        "\n",
        "        # --- Superclass predictions with novelty ---\n",
        "        super_probs = F.softmax(super_logits, dim=1)           # (B, num_super)\n",
        "        max_super_probs, super_idx = super_probs.max(dim=1)    # (B,)\n",
        "        super_novel_mask = max_super_probs < tau_super\n",
        "        super_idx = super_idx.clone()\n",
        "        super_idx[super_novel_mask] = NOVEL_SUPER_IDX\n",
        "\n",
        "        # --- Subclass predictions with novelty ---\n",
        "        sub_probs = F.softmax(sub_logits, dim=1)               # (B, num_sub)\n",
        "        max_sub_probs, sub_idx = sub_probs.max(dim=1)          # (B,)\n",
        "        sub_novel_mask = max_sub_probs < tau_sub\n",
        "        sub_idx = sub_idx.clone()\n",
        "        sub_idx[sub_novel_mask] = NOVEL_SUB_IDX\n",
        "\n",
        "        # Move to CPU as plain Python ints\n",
        "        super_idx = super_idx.cpu().tolist()\n",
        "        sub_idx   = sub_idx.cpu().tolist()\n",
        "\n",
        "        # img_names is a list of filenames (len = B)\n",
        "        images_list.extend(img_names)\n",
        "        super_preds.extend(super_idx)\n",
        "        sub_preds.extend(sub_idx)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"image\": images_list,\n",
        "        \"superclass_index\": super_preds,\n",
        "        \"subclass_index\": sub_preds\n",
        "    })\n",
        "    return df\n",
        "\n",
        "# SECTION: Test-time inference & CSV export for two-heads model\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    # Recreate the model and load best checkpoint\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    test_predictions = predict_test_two_heads(\n",
        "        model_two_heads,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_heads_predictions.csv\")\n",
        "    test_predictions.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-heads predictions (with novelty) to:\", out_csv_path)\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\")\n"
      ],
      "metadata": {
        "id": "V_69xbINR2w6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93777ab-0bcc-4886-bcd0-2c9a7905244a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 9: Test-time Inference & CSV Export for leaderboard **(two separate models)**"
      ],
      "metadata": {
        "id": "wwPpeqduiLv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TAU_SUB"
      ],
      "metadata": {
        "id": "Pifzw-bIIP-x",
        "outputId": "586fec7b-5cf1-484e-cb94-72445ec1b707",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict_test_two_models(model_super, model_sub, test_loader,\n",
        "                            tau_super=TAU_SUPER, tau_sub=TAU_SUB):\n",
        "    \"\"\"\n",
        "    Inference for the two-model setup (separate super + sub models) with novelty thresholds.\n",
        "\n",
        "    model_super: SingleHeadModel for superclass (num_classes = num_super)\n",
        "    model_sub:   SingleHeadModel for subclass  (num_classes = num_sub)\n",
        "    test_loader: DataLoader yielding (images, img_names)\n",
        "    tau_super:   threshold for superclass novelty\n",
        "    tau_sub:     threshold for subclass novelty\n",
        "    \"\"\"\n",
        "\n",
        "    model_super.eval()\n",
        "    model_sub.eval()\n",
        "\n",
        "    images_list = []\n",
        "    super_preds = []\n",
        "    sub_preds = []\n",
        "\n",
        "    for images, img_names in test_loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "\n",
        "        # Forward passes\n",
        "        super_logits = model_super(images)   # (B, num_super)\n",
        "        sub_logits   = model_sub(images)     # (B, num_sub)\n",
        "\n",
        "        # --- Superclass predictions with novelty ---\n",
        "        super_probs = F.softmax(super_logits, dim=1)           # (B, num_super)\n",
        "        max_super_probs, super_idx = super_probs.max(dim=1)    # (B,)\n",
        "        super_novel_mask = max_super_probs < tau_super\n",
        "        super_idx = super_idx.clone()\n",
        "        super_idx[super_novel_mask] = NOVEL_SUPER_IDX\n",
        "\n",
        "        # --- Subclass predictions with novelty ---\n",
        "        sub_probs = F.softmax(sub_logits, dim=1)               # (B, num_sub)\n",
        "        max_sub_probs, sub_idx = sub_probs.max(dim=1)          # (B,)\n",
        "        sub_novel_mask = max_sub_probs < tau_sub\n",
        "        sub_idx = sub_idx.clone()\n",
        "        sub_idx[sub_novel_mask] = NOVEL_SUB_IDX\n",
        "\n",
        "        # Move indices to CPU as plain Python ints\n",
        "        super_idx = super_idx.cpu().tolist()\n",
        "        sub_idx   = sub_idx.cpu().tolist()\n",
        "\n",
        "        # img_names is a list of filenames (len = B)\n",
        "        images_list.extend(img_names)\n",
        "        super_preds.extend(super_idx)\n",
        "        sub_preds.extend(sub_idx)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"image\": images_list,\n",
        "        \"superclass_index\": super_preds,\n",
        "        \"subclass_index\": sub_preds,\n",
        "    })\n",
        "    return df\n",
        "\n",
        "\n",
        "if APPROACH == \"two_models\":\n",
        "    model_super = SingleHeadModel(num_classes=num_super, head=SUPER_HEAD_TYPE).to(device)\n",
        "    model_sub   = SingleHeadModel(num_classes=num_sub, head=SUB_HEAD_TYPE).to(device)\n",
        "\n",
        "    model_super.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_super_model.pth\"),\n",
        "                                           map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_sub_model.pth\"),\n",
        "                                         map_location=device))\n",
        "\n",
        "    test_predictions_two_models = predict_test_two_models(\n",
        "        model_super, model_sub, test_loader,\n",
        "        tau_super=TAU_SUPER, tau_sub=TAU_SUB,\n",
        "    )\n",
        "\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_models_predictions.csv\")\n",
        "    test_predictions_two_models.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-model predictions (with novelty) to:\", out_csv_path)\n",
        "\n",
        "else:\n",
        "  print(\"APPROACH is not 'two_models'; skipping two-models inference in this cell.\")"
      ],
      "metadata": {
        "id": "XWEswAdKijVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44999039-45d8-490c-966f-707298107ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved two-model predictions (with novelty) to: /content/drive/MyDrive/NNDL-Project/Project Data/two_models_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Info\n",
        "Team Name: Caged Manifolds\n",
        "\n",
        "Model Name: ResNet50v2 with Data Augmentation - Cosine Similarity heads\n",
        "\n",
        "Description: 2 model architecture (separate super and subclass predictor), various regularization and data augmentation added, cosine classifier subhead"
      ],
      "metadata": {
        "id": "PVW3p2mcHXcF"
      }
    }
  ]
}