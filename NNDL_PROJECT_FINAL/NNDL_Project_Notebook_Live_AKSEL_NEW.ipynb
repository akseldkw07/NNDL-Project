{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_5aFAaALeLW"
      },
      "source": [
        "# SECTION 1: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85tMtuD924rr",
        "outputId": "beaa1d90-37c8-437a-e841-93832e68561f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Sun Dec 14 05:46:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   37C    P0             56W /  400W |       0MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makseldkw\u001b[0m (\u001b[33makseldkw07\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi  # just to sanity-check the GPU\n",
        "\n",
        "!pip install wandb -q\n",
        "import wandb\n",
        "\n",
        "USE_WANDB = True\n",
        "WANDB_ENTITY = \"nndl-project-F25\"\n",
        "WANDB_PROJECT = \"Multihead-Classification-Competition\"\n",
        "\n",
        "if USE_WANDB:\n",
        "  wandb.login()\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import os, zipfile, random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# wandb run-naming schema\n",
        "def make_run_name(base: str) -> str:\n",
        "    \"\"\"Create a unique run name with timestamp.\"\"\"\n",
        "    return f\"{base}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "# optional: for approximate reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aLBSBye0kk1x"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "UML_AKSEL_DIR = \"/content/drive/MyDrive/NNDL-Project/Notebooks\"\n",
        "if UML_AKSEL_DIR not in sys.path:\n",
        "    sys.path.append(UML_AKSEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z-JgjOwRkJg6"
      },
      "outputs": [],
      "source": [
        "from constants import *\n",
        "from evaluation_utils import *\n",
        "from inference import *\n",
        "from models import *\n",
        "from resnet_pretrain import *\n",
        "from training_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eh6m2cwH6Bui",
        "outputId": "418d9aad-67e3-41c6-f70e-3f3c046d7cf6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cosine'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SUB_HEAD_TYPE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxiTY5skLo7b"
      },
      "source": [
        "# SECTION 2: Config & Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "04GRyoqmIVed"
      },
      "outputs": [],
      "source": [
        "os.makedirs(LOCAL_DATA_ROOT, exist_ok=True)\n",
        "\n",
        "train_zip_path = os.path.join(DATA_ROOT, \"train_images.zip\")\n",
        "test_zip_path = os.path.join(DATA_ROOT, \"test_images.zip\")\n",
        "\n",
        "# Unzip to LOCAL_DATA_ROOT instead of Drive\n",
        "train_out_dir = os.path.join(LOCAL_DATA_ROOT, \"train_images\")\n",
        "test_out_dir = os.path.join(LOCAL_DATA_ROOT, \"test_images\")\n",
        "if not os.path.exists(train_out_dir):\n",
        "    os.makedirs(train_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(train_zip_path, \"r\") as z:\n",
        "        z.extractall(train_out_dir)\n",
        "\n",
        "if not os.path.exists(test_out_dir):\n",
        "    os.makedirs(test_out_dir, exist_ok=True)\n",
        "    with zipfile.ZipFile(test_zip_path, \"r\") as z:\n",
        "        z.extractall(test_out_dir)\n",
        "\n",
        "\n",
        "TRAIN_IMG_DIR = os.path.join(train_out_dir, \"train_images\")\n",
        "TEST_IMG_DIR = os.path.join(test_out_dir, \"test_images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stQpD0L1ggNX",
        "outputId": "a66bfb08-20a1-40fb-c631-3fceb525b64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFAR novel-super CSV already exists at: /content/local_data/cifar_novel_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Build CIFAR-100 novel-super dataset (excluding reptiles)\n",
        "from torchvision.datasets import CIFAR100\n",
        "\n",
        "# Download CIFAR100 once (raw PIL images)\n",
        "CIFAR_ROOT = os.path.join(LOCAL_DATA_ROOT, \"cifar100_raw\")\n",
        "os.makedirs(CIFAR_ROOT, exist_ok=True)\n",
        "\n",
        "# Only do the heavy image-copying if CSV doesn't exist\n",
        "if CIFAR_NOVEL_MODE != \"none\" and not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "    print(\"Building CIFAR novel-super dataset (this happens once)...\")\n",
        "\n",
        "    cifar_train = CIFAR100(root=CIFAR_ROOT, train=True, download=True, transform=None)\n",
        "\n",
        "    # CIFAR-100 fine label names (with underscores)\n",
        "    cifar_fine_names = cifar_train.classes  # e.g. \"apple\", \"beaver\", \"aquarium_fish\", ...\n",
        "\n",
        "    # Fine classes we want, based on your list, excluding reptiles\n",
        "    # (these names match CIFAR-100 fine label names)\n",
        "\n",
        "    # Map class_name -> list of indices for that fine class\n",
        "    name_to_indices = {name: [] for name in ALLOWED_FINE_NAMES}\n",
        "    for idx in range(len(cifar_train)):\n",
        "        _, fine_label = cifar_train[idx]  # fine_label is int index into cifar_fine_names\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "        if fine_name in ALLOWED_FINE_NAMES:\n",
        "            name_to_indices[fine_name].append(idx)\n",
        "\n",
        "    # Flatten candidate indices across all allowed classes\n",
        "    candidate_indices = []\n",
        "    for name, idx_list in name_to_indices.items():\n",
        "        candidate_indices.extend(idx_list)\n",
        "\n",
        "    print(\"Total candidate CIFAR images (allowed classes, excl. reptiles):\", len(candidate_indices))\n",
        "\n",
        "    # Target total novel-super samples (max 5000, as you requested)\n",
        "    TARGET_TOTAL = 5000\n",
        "    random.seed(42)\n",
        "    random.shuffle(candidate_indices)\n",
        "    selected_indices = candidate_indices[:TARGET_TOTAL]\n",
        "\n",
        "    print(\"Selected indices:\", len(selected_indices))\n",
        "\n",
        "    # Copy images into TRAIN_IMG_DIR and build CSV rows\n",
        "    cifar_aug_records = []\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        img, fine_label = cifar_train[idx]\n",
        "        fine_name = cifar_fine_names[fine_label]\n",
        "\n",
        "        # Unique filename to avoid collisions\n",
        "        fname = f\"cifar_novel_{idx}_{fine_name}.png\"\n",
        "        dst_path = os.path.join(TRAIN_IMG_DIR, fname)\n",
        "\n",
        "        # img is PIL.Image when transform=None\n",
        "        img.save(dst_path)\n",
        "\n",
        "        record = {\n",
        "            \"image\": fname,\n",
        "            \"superclass_index\": NOVEL_SUPER_IDX,  # novel superclass\n",
        "            \"subclass_index\": NOVEL_SUB_IDX,  # novel subclass\n",
        "            \"description\": f\"CIFAR100:{fine_name} (novel superclass)\",\n",
        "        }\n",
        "        cifar_aug_records.append(record)\n",
        "\n",
        "    cifar_aug_df = pd.DataFrame(cifar_aug_records)\n",
        "    cifar_aug_df.to_csv(CIFAR_NOVEL_CSV_PATH, index=False)\n",
        "    print(\"Saved CIFAR novel-super metadata to:\", CIFAR_NOVEL_CSV_PATH)\n",
        "    print(\"Images copied into TRAIN_IMG_DIR:\", TRAIN_IMG_DIR)\n",
        "\n",
        "elif CIFAR_NOVEL_MODE != \"none\":\n",
        "    print(\"CIFAR novel-super CSV already exists at:\", CIFAR_NOVEL_CSV_PATH)\n",
        "else:\n",
        "    print(\"CIFAR_NOVEL_MODE='none'; skipping CIFAR novel-super creation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0NzoPU6L0kE"
      },
      "source": [
        "# SECTION 3: Data Loading & DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1DTM3ycL7_-",
        "outputId": "f4d2ee35-2adb-4c71-9f07-d154f3054e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num superclasses: 4\n",
            "Num subclasses: 88\n",
            "CIFAR_NOVEL_MODE='large' → using 5000 CIFAR novel-super samples.\n",
            "Combined train_df size (original + CIFAR): 11288\n",
            "  Novel-super count (superclass_index == NOVEL_SUPER_IDX): 5000\n",
            "Example sub_to_super mapping (first 10): {0: 1, 1: 2, 2: 1, 3: 2, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 1}\n"
          ]
        }
      ],
      "source": [
        "# SECTION 3: Data Loading & Dataloaders\n",
        "\n",
        "# Base training data from class\n",
        "base_train_df = pd.read_csv(TRAIN_CSV)\n",
        "\n",
        "super_map_df = pd.read_csv(SUPER_CSV)  # columns: index, class\n",
        "sub_map_df = pd.read_csv(SUB_CSV)  # columns: index, class\n",
        "\n",
        "num_super = len(super_map_df)\n",
        "num_sub = len(sub_map_df)\n",
        "\n",
        "print(\"Num superclasses:\", num_super)\n",
        "print(\"Num subclasses:\", num_sub)\n",
        "\n",
        "# --- Integrate CIFAR novel-super examples, if enabled ---\n",
        "\n",
        "if CIFAR_NOVEL_MODE == \"none\":\n",
        "    train_df = base_train_df.copy()\n",
        "    print(\"CIFAR_NOVEL_MODE='none' → using only original training data.\")\n",
        "else:\n",
        "    if not os.path.exists(CIFAR_NOVEL_CSV_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"CIFAR_NOVEL_MODE={CIFAR_NOVEL_MODE} but {CIFAR_NOVEL_CSV_PATH} not found. \"\n",
        "            \"Run the CIFAR novel-super build section first.\"\n",
        "        )\n",
        "\n",
        "    cifar_aug_df = pd.read_csv(CIFAR_NOVEL_CSV_PATH)\n",
        "\n",
        "    if CIFAR_NOVEL_MODE == \"small\":\n",
        "        # Use ~1000 CIFAR novel-super images\n",
        "        n_small = min(1000, len(cifar_aug_df))\n",
        "        cifar_aug_df = cifar_aug_df.sample(n=n_small, random_state=42).reset_index(drop=True)\n",
        "        print(f\"CIFAR_NOVEL_MODE='small' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    elif CIFAR_NOVEL_MODE == \"large\":\n",
        "        # Use all available (up to 5000 created earlier)\n",
        "        print(f\"CIFAR_NOVEL_MODE='large' → using {len(cifar_aug_df)} CIFAR novel-super samples.\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown CIFAR_NOVEL_MODE: {CIFAR_NOVEL_MODE}\")\n",
        "\n",
        "    # Combine original training data with CIFAR novel-super rows\n",
        "    train_df = pd.concat([base_train_df, cifar_aug_df], ignore_index=True)\n",
        "    print(\"Combined train_df size (original + CIFAR):\", len(train_df))\n",
        "    print(\n",
        "        \"  Novel-super count (superclass_index == NOVEL_SUPER_IDX):\",\n",
        "        (train_df[\"superclass_index\"] == NOVEL_SUPER_IDX).sum(),\n",
        "    )\n",
        "\n",
        "# --- Build subclass -> superclass mapping from *combined* train_df ---\n",
        "# This still satisfies “each subclass has a single superclass”:\n",
        "#  - Original subclasses 0..86\n",
        "#  - Novel subclass 87 always maps to NOVEL_SUPER_IDX\n",
        "sub_to_super = train_df.groupby(\"subclass_index\")[\"superclass_index\"].agg(lambda x: x.value_counts().index[0]).to_dict()\n",
        "\n",
        "print(\"Example sub_to_super mapping (first 10):\", dict(list(sub_to_super.items())[:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LcWn_qDgMcIa"
      },
      "outputs": [],
      "source": [
        "# Transforms\n",
        "\n",
        "if DATA_AUGMENT:\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=MEAN_IMG, std=STD_IMG),\n",
        "        ]\n",
        "    )\n",
        "else:\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=MEAN_IMG, std=STD_IMG),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "val_test_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=MEAN_IMG, std=STD_IMG),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_xpuCQFMf6X",
        "outputId": "724571ca-b215-40a8-ecdc-1aea60c3a52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Simple split, novel-super aware]\n",
            "  Seen-super samples: 6288\n",
            "  Novel-super samples: 5000\n",
            "  Final split sizes:\n",
            "    train: 10160\n",
            "    val:   1128\n",
            "    train novel-super: 4500\n",
            "    val novel-super:   500\n",
            "[Simple split] Train size: 10160, Val size: 1128\n",
            "Test size: 11180\n"
          ]
        }
      ],
      "source": [
        "# Train/val split + loaders with optional pseudo-novel validation,\n",
        "# ensuring novel-super examples (super == NOVEL_SUPER_IDX) appear in both train and val.\n",
        "\n",
        "\n",
        "pseudo_novel_loader = None  # default; will be set if USE_PSEUDO_NOVEL\n",
        "heldout_subclasses = None  # to inspect later if needed\n",
        "\n",
        "\n",
        "if not USE_PSEUDO_NOVEL:\n",
        "    # -------------------------\n",
        "    # Simple split, but novel-super-aware\n",
        "    # -------------------------\n",
        "    print(\"[Simple split, novel-super aware]\")\n",
        "\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(  # type: ignore\n",
        "        train_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=42,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(f\"[Simple split] Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n",
        "\n",
        "else:\n",
        "    # -------------------------\n",
        "    # Pseudo-novel setup: hold out some subclasses entirely for pseudo-novel validation\n",
        "    # while still keeping novel-super in both train and val.\n",
        "    # -------------------------\n",
        "\n",
        "    print(\"[Pseudo-novel subclass split + novel-super-aware train/val]\")\n",
        "\n",
        "    # 1) choose subset of subclasses to treat as pseudo-novel\n",
        "    all_subclasses = sorted(train_df[\"subclass_index\"].unique())\n",
        "    # Do NOT hold out the novel subclass itself (87)\n",
        "    all_subclasses_no_novel = [c for c in all_subclasses if c != NOVEL_SUB_IDX]\n",
        "\n",
        "    rng = np.random.default_rng(PSEUDO_NOVEL_SEED)\n",
        "\n",
        "    num_holdout = max(1, int(len(all_subclasses_no_novel) * PSEUDO_NOVEL_FRACTION))\n",
        "    heldout_subclasses = set(rng.choice(all_subclasses_no_novel, size=num_holdout, replace=False).tolist())\n",
        "    seen_subclasses = [c for c in all_subclasses if c not in heldout_subclasses]\n",
        "\n",
        "    print(f\"[Pseudo-novel] Total subclasses (excl. novel): {len(all_subclasses_no_novel)}\")\n",
        "    print(f\"[Pseudo-novel] Held-out subclasses (pseudo-novel): {sorted(heldout_subclasses)}\")\n",
        "    print(f\"[Pseudo-novel] Seen subclasses (incl. novel-sub): {len(seen_subclasses)}\")\n",
        "\n",
        "    # 2) split dataframe into seen vs pseudo-novel (by subclass)\n",
        "    seen_mask = ~train_df[\"subclass_index\"].isin(heldout_subclasses)\n",
        "    seen_df = train_df[seen_mask].reset_index(drop=True)\n",
        "    pseudo_novel_df = train_df[~seen_mask].reset_index(drop=True)\n",
        "\n",
        "    print(f\"[Pseudo-novel] Seen samples: {len(seen_df)}, Pseudo-novel samples: {len(pseudo_novel_df)}\")\n",
        "\n",
        "    # 3) Train/val split on seen data, but ensure novel-super in both\n",
        "    train_split_df, val_split_df = split_seen_vs_novel_super(  # type: ignore\n",
        "        seen_df,\n",
        "        VAL_SPLIT,\n",
        "        NOVEL_SUPER_IDX,\n",
        "        rng_seed=PSEUDO_NOVEL_SEED,\n",
        "    )\n",
        "\n",
        "    train_dataset = BirdDogReptileDataset(\n",
        "        train_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "    val_seen_dataset = BirdDogReptileDataset(\n",
        "        val_split_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_seen_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    # 4) pseudo-novel validation loader (all held-out subclasses, val-style transform)\n",
        "    pseudo_novel_dataset = BirdDogReptileDataset(\n",
        "        pseudo_novel_df,\n",
        "        TRAIN_IMG_DIR,\n",
        "        transform=val_test_transform,\n",
        "    )\n",
        "    pseudo_novel_loader = DataLoader(\n",
        "        pseudo_novel_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"[Pseudo-novel] Train size: {len(train_dataset)}, \"\n",
        "        f\"Seen-val size: {len(val_seen_dataset)}, \"\n",
        "        f\"Pseudo-novel val size: {len(pseudo_novel_dataset)}\"\n",
        "    )\n",
        "\n",
        "# Test loader is the same regardless\n",
        "test_dataset = BirdDogReptileTestDataset(TEST_IMG_DIR, transform=val_test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=NUM_WORKERS)\n",
        "# change batch size back to 1 if see any errors\n",
        "\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpvDqfhKRKQ7"
      },
      "source": [
        "# SECTION 6: Approach A: Shared backbone, two heads + KL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxn7j1w1RRJk",
        "outputId": "d9d6756a-af88-40ea-db47-e5558692e5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads training in this cell.\n"
          ]
        }
      ],
      "source": [
        "# Original idea\n",
        "\n",
        "LR = 1e-4  # maybe two different learning rates\n",
        "ALPHA_KL = 0.1\n",
        "TEMPERATURE = 1.0\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = setup_backbone_training(\n",
        "        model_two_heads,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_two_heads = None\n",
        "    if USE_WANDB:\n",
        "        run_two_heads = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_heads_kl_resnet\"),\n",
        "            group=\"two_heads\",  # to group/filter all two_heads runs\n",
        "            config={\n",
        "                \"approach\": \"two_heads_kl\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"alpha_kl\": ALPHA_KL,\n",
        "                \"temperature\": TEMPERATURE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_score = 0.0\n",
        "\n",
        "    print(\"Training shared-backbone two-heads model (KL-coupled):\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_two_heads,\n",
        "            optimizer,\n",
        "            train_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_two_heads,\n",
        "            val_loader,\n",
        "            criterion,\n",
        "            mode=\"two_heads_kl\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            alpha_kl=ALPHA_KL,\n",
        "            temperature=TEMPERATURE,\n",
        "        )\n",
        "\n",
        "        val_acc_super = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        val_acc_sub = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        val_loss = val_metrics[\"val_loss\"]\n",
        "\n",
        "        print(\n",
        "            f\"[Two-heads] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_loss:.4f}, \"\n",
        "            f\"val_acc_super={val_acc_super:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc_sub:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            # prefix metrics so they don't collide with two-model ones\n",
        "            log_dict = {\n",
        "                \"epoch\": epoch,\n",
        "                \"two_heads_train_loss\": train_metrics[\"loss\"],\n",
        "                \"two_heads_val_loss\": val_loss,\n",
        "                \"two_heads_val_acc_super\": val_acc_super,\n",
        "                \"two_heads_val_acc_sub\": val_acc_sub,\n",
        "            }\n",
        "            wandb.log(log_dict, step=epoch)\n",
        "\n",
        "        # simple combined score: average of super/sub val accuracy\n",
        "        val_score = 0.5 * val_acc_super + 0.5 * val_acc_sub\n",
        "        if val_score > best_val_score:\n",
        "            best_val_score = val_score\n",
        "            torch.save(\n",
        "                model_two_heads.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best two-heads model\")\n",
        "\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    analyze_tau_sub(model_two_heads, pseudo_novel_loader, val_loader, mode=\"two_heads\")\n",
        "    analyze_tau_super(model_two_heads, val_loader, NOVEL_SUPER_IDX, mode=\"two_heads\")\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_two_heads,\n",
        "        mode=\"two_heads\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        val_loader=val_loader,\n",
        "        name=\"val_two_heads\",\n",
        "    )\n",
        "    evaluate_pseudo_novel_sub_with_novelty(model_two_heads, mode=\"two_heads\", tau_sub=TAU_SUB)\n",
        "    novelty_dashboard(\n",
        "        model_two_heads,\n",
        "        val_loader=val_loader,\n",
        "        pseudo_novel_loader=pseudo_novel_loader,\n",
        "        mode=\"two_heads\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "\n",
        "    if run_two_heads is not None:\n",
        "        run_two_heads.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads training in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNtlQWujRg4X"
      },
      "source": [
        "# SECTION 7: Approach B - Two separate models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RPa25bz6RlhN",
        "outputId": "6f120317-fc75-495d-8117-5c6898c847ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_054652-04p8u48b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/04p8u48b' target=\"_blank\">two_models_super_resnet_20251214_054651</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/04p8u48b' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/04p8u48b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training superclass model:\n",
            "[Super] Epoch 1: train_loss=0.1252, val_loss=0.0221, val_acc_super=0.9956\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 2: train_loss=0.0148, val_loss=0.0279, val_acc_super=0.9947\n",
            "[Super] Epoch 3: train_loss=0.0090, val_loss=0.0057, val_acc_super=0.9982\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 4: train_loss=0.0083, val_loss=0.0104, val_acc_super=0.9982\n",
            "[Super] Epoch 5: train_loss=0.0068, val_loss=0.0112, val_acc_super=0.9973\n",
            "[Super] Epoch 6: train_loss=0.0036, val_loss=0.0152, val_acc_super=0.9982\n",
            "[Super] Epoch 7: train_loss=0.0066, val_loss=0.0112, val_acc_super=0.9991\n",
            "  Saved new best superclass model\n",
            "[Super] Epoch 8: train_loss=0.0031, val_loss=0.0104, val_acc_super=0.9982\n",
            "[Super] Epoch 9: train_loss=0.0026, val_loss=0.0088, val_acc_super=0.9991\n",
            "[Super] Epoch 10: train_loss=0.0068, val_loss=0.0128, val_acc_super=0.9982\n",
            "[Super] Epoch 11: train_loss=0.0030, val_loss=0.0059, val_acc_super=0.9982\n",
            "[Super] Epoch 12: train_loss=0.0033, val_loss=0.0122, val_acc_super=0.9973\n",
            "[Super] Epoch 13: train_loss=0.0034, val_loss=0.0103, val_acc_super=0.9973\n",
            "[Super] Epoch 14: train_loss=0.0025, val_loss=0.0050, val_acc_super=0.9982\n",
            "[Super] Epoch 15: train_loss=0.0012, val_loss=0.0052, val_acc_super=0.9982\n",
            "[Super] Epoch 16: train_loss=0.0023, val_loss=0.0658, val_acc_super=0.9885\n",
            "[Super] Epoch 17: train_loss=0.0090, val_loss=0.0040, val_acc_super=0.9991\n",
            "[Super] Epoch 18: train_loss=0.0032, val_loss=0.0192, val_acc_super=0.9973\n",
            "[Super] Epoch 19: train_loss=0.0030, val_loss=0.0213, val_acc_super=0.9956\n",
            "[Super] Epoch 20: train_loss=0.0015, val_loss=0.0167, val_acc_super=0.9965\n",
            "[Super] Epoch 21: train_loss=0.0017, val_loss=0.0111, val_acc_super=0.9982\n",
            "[Super] Epoch 22: train_loss=0.0033, val_loss=0.0091, val_acc_super=0.9965\n",
            "[Super] Epoch 23: train_loss=0.0027, val_loss=0.0186, val_acc_super=0.9956\n",
            "[Super] Epoch 24: train_loss=0.0050, val_loss=0.0167, val_acc_super=0.9973\n",
            "[Super] Epoch 25: train_loss=0.0060, val_loss=0.0247, val_acc_super=0.9973\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>super_train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>super_val_acc</td><td>▆▅▇▇▇▇█▇█▇▇▇▇▇▇▁█▇▆▆▇▆▆▇▇</td></tr><tr><td>super_val_loss</td><td>▃▄▁▂▂▂▂▂▂▂▁▂▂▁▁█▁▃▃▂▂▂▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>super_train_loss</td><td>0.00602</td></tr><tr><td>super_val_acc</td><td>0.99734</td></tr><tr><td>super_val_loss</td><td>0.02471</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_super_resnet_20251214_054651</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/04p8u48b' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/04p8u48b</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_054652-04p8u48b/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Second idea to compare\n",
        "\n",
        "LR = 1e-4\n",
        "\n",
        "if APPROACH == \"two_models\":\n",
        "    # Superclass model\n",
        "    model_super = SingleHeadModel(num_classes=num_super, backbone=BACKBONE, head=SUPER_HEAD_TYPE).to(device)\n",
        "    criterion_super = nn.CrossEntropyLoss()\n",
        "    optimizer_super = setup_backbone_training(\n",
        "        model_super,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_super = None\n",
        "    if USE_WANDB:\n",
        "        run_super = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_super_resnet\"),\n",
        "            group=\"two_models\",  # to filter all two_models runs together\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"super\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_super = 0.0\n",
        "\n",
        "    print(\"Training superclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_super,\n",
        "            optimizer_super,\n",
        "            train_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_super,\n",
        "            val_loader,\n",
        "            criterion_super,\n",
        "            mode=\"single_head_super\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_super\", 0.0)\n",
        "        print(\n",
        "            f\"[Super] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_super={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"super_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"super_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"super_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_super:\n",
        "            best_val_super = val_acc\n",
        "            torch.save(\n",
        "                model_super.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_super_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best superclass model\")\n",
        "        if val_acc == 1.0:\n",
        "            print(\"Perfect accuracy achieved\")\n",
        "            break\n",
        "\n",
        "    if run_super is not None:\n",
        "        run_super.finish()\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-model training in this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "Ul2V50xOOJXg",
        "outputId": "5aeed32c-8796-40e1-d9cf-cb0489eb47bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251214_054910-i9om768p</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/i9om768p' target=\"_blank\">two_models_sub_resnet_20251214_054909</a></strong> to <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/i9om768p' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/i9om768p</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training subclass model:\n",
            "[Sub] Epoch 1: train_loss=1.5178, val_loss=0.4650, val_acc_sub=0.8599\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 2: train_loss=0.3445, val_loss=0.2648, val_acc_sub=0.9255\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 3: train_loss=0.1828, val_loss=0.2120, val_acc_sub=0.9326\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 4: train_loss=0.1184, val_loss=0.1791, val_acc_sub=0.9441\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 5: train_loss=0.0775, val_loss=0.1616, val_acc_sub=0.9450\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 6: train_loss=0.0665, val_loss=0.1625, val_acc_sub=0.9477\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 7: train_loss=0.0525, val_loss=0.2009, val_acc_sub=0.9344\n",
            "[Sub] Epoch 8: train_loss=0.0548, val_loss=0.1665, val_acc_sub=0.9468\n",
            "[Sub] Epoch 9: train_loss=0.0415, val_loss=0.1771, val_acc_sub=0.9495\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 10: train_loss=0.0321, val_loss=0.1590, val_acc_sub=0.9530\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 11: train_loss=0.0319, val_loss=0.2037, val_acc_sub=0.9415\n",
            "[Sub] Epoch 12: train_loss=0.0208, val_loss=0.1743, val_acc_sub=0.9477\n",
            "[Sub] Epoch 13: train_loss=0.0188, val_loss=0.1776, val_acc_sub=0.9477\n",
            "[Sub] Epoch 14: train_loss=0.0310, val_loss=0.1985, val_acc_sub=0.9415\n",
            "[Sub] Epoch 15: train_loss=0.0184, val_loss=0.1956, val_acc_sub=0.9424\n",
            "[Sub] Epoch 16: train_loss=0.0265, val_loss=0.1626, val_acc_sub=0.9566\n",
            "  Saved new best subclass model\n",
            "[Sub] Epoch 17: train_loss=0.0306, val_loss=0.1799, val_acc_sub=0.9477\n",
            "[Sub] Epoch 18: train_loss=0.0297, val_loss=0.2473, val_acc_sub=0.9424\n",
            "[Sub] Epoch 19: train_loss=0.0250, val_loss=0.2191, val_acc_sub=0.9450\n",
            "[Sub] Epoch 20: train_loss=0.0258, val_loss=0.1879, val_acc_sub=0.9548\n",
            "[Sub] Epoch 21: train_loss=0.0182, val_loss=0.1845, val_acc_sub=0.9495\n",
            "[Sub] Epoch 22: train_loss=0.0237, val_loss=0.1685, val_acc_sub=0.9530\n",
            "[Sub] Epoch 23: train_loss=0.0229, val_loss=0.2143, val_acc_sub=0.9406\n",
            "[Sub] Epoch 24: train_loss=0.0180, val_loss=0.2038, val_acc_sub=0.9450\n",
            "[Sub] Epoch 25: train_loss=0.0193, val_loss=0.1778, val_acc_sub=0.9495\n"
          ]
        }
      ],
      "source": [
        "if APPROACH == \"two_models\":\n",
        "    best_super_path = os.path.join(DATA_ROOT, \"best_super_model.pth\")\n",
        "    model_super.load_state_dict(torch.load(best_super_path, map_location=device))\n",
        "    # Subclass model\n",
        "    model_sub = SingleHeadModel(num_classes=num_sub, backbone=BACKBONE, head=SUB_HEAD_TYPE).to(device)\n",
        "    criterion_sub = nn.CrossEntropyLoss()\n",
        "    optimizer_sub = setup_backbone_training(\n",
        "        model_sub,\n",
        "        fine_tune_mode=FINE_TUNE_MODE,\n",
        "        lr_full=LR,\n",
        "        lr_head=LR_HEAD,\n",
        "    )\n",
        "\n",
        "    run_sub = None\n",
        "    if USE_WANDB:\n",
        "        run_sub = wandb.init(\n",
        "            entity=WANDB_ENTITY,\n",
        "            project=WANDB_PROJECT,\n",
        "            name=make_run_name(\"two_models_sub_resnet\"),\n",
        "            group=\"two_models\",\n",
        "            config={\n",
        "                \"approach\": \"two_models\",\n",
        "                \"head\": \"sub\",\n",
        "                \"backbone\": BACKBONE,\n",
        "                \"epochs\": EPOCHS,\n",
        "                \"lr_full\": LR,\n",
        "                \"lr_head\": LR_HEAD,\n",
        "                \"fine_tune_mode\": FINE_TUNE_MODE,\n",
        "                \"img_size\": IMG_SIZE,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    best_val_sub = 0.0\n",
        "\n",
        "    print(\"\\nTraining subclass model:\")\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_metrics = train_one_epoch(\n",
        "            model_sub,\n",
        "            optimizer_sub,\n",
        "            train_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "            trained_superclass_model=model_super,\n",
        "        )\n",
        "        val_metrics = eval_one_epoch(\n",
        "            model_sub,\n",
        "            val_loader,\n",
        "            criterion_sub,\n",
        "            mode=\"single_head_sub\",\n",
        "            sub_to_super=sub_to_super,\n",
        "            num_super=num_super,\n",
        "        )\n",
        "\n",
        "        val_acc = val_metrics.get(\"val_acc_sub\", 0.0)\n",
        "        print(\n",
        "            f\"[Sub] Epoch {epoch}: \"\n",
        "            f\"train_loss={train_metrics['loss']:.4f}, \"\n",
        "            f\"val_loss={val_metrics['val_loss']:.4f}, \"\n",
        "            f\"val_acc_sub={val_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if USE_WANDB:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"sub_train_loss\": train_metrics[\"loss\"],\n",
        "                    \"sub_val_loss\": val_metrics[\"val_loss\"],\n",
        "                    \"sub_val_acc\": val_acc,\n",
        "                },\n",
        "                step=epoch,\n",
        "            )\n",
        "\n",
        "        if val_acc > best_val_sub:\n",
        "            best_val_sub = val_acc\n",
        "            torch.save(\n",
        "                model_sub.state_dict(),\n",
        "                os.path.join(DATA_ROOT, \"best_sub_model.pth\"),\n",
        "            )\n",
        "            print(\"  Saved new best subclass model\")\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping subclass model training in this cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ITJMYu40OJXg",
        "outputId": "af217291-07b5-4a5f-b053-af9fcdd0a995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pseudo_novel_loader is None. Set USE_PSEUDO_NOVEL = True before building loaders to use this analysis.\n",
            "\n",
            "Seen superclasses (0/1/2) superclass max-prob stats:\n",
            "  count = 628\n",
            "  mean  = 0.997\n",
            "  std   = 0.027\n",
            "  percentiles:\n",
            "    p 1: 0.913\n",
            "    p 5: 0.996\n",
            "    p10: 0.999\n",
            "    p25: 1.000\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Novel superclasses (== NOVEL_SUPER_IDX) superclass max-prob stats:\n",
            "  count = 500\n",
            "  mean  = 1.000\n",
            "  std   = 0.001\n",
            "  percentiles:\n",
            "    p 1: 0.996\n",
            "    p 5: 0.999\n",
            "    p10: 1.000\n",
            "    p25: 1.000\n",
            "    p50: 1.000\n",
            "    p75: 1.000\n",
            "    p90: 1.000\n",
            "    p95: 1.000\n",
            "    p99: 1.000\n",
            "\n",
            "Suggested TAU_SUPER candidates (using seen + novel):\n",
            "  tau_super ≈ 10th percentile of seen:       0.999\n",
            "  tau_super ≈ 5th percentile of seen:        0.996\n",
            "  tau_super ≈ mean(seen) - std(seen):        0.970\n",
            "  tau_super ≈ mean(seen & novel) midpoint:   0.998\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged superclass histograms and tau_super candidates to Weights & Biases.\n",
            "\n",
            "=== Evaluation on val_super_only ===\n",
            "Overall superclass acc: 0.9787\n",
            "Seen superclass acc (true super != novel):   0.9618\n",
            "Seen superclass false-novel rate:            0.0382\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "=== Evaluation on val_sub_only ===\n",
            "Overall subclass acc:   0.9309\n",
            "Seen subclass acc (true sub != novel):       0.8758\n",
            "Seen subclass false-novel rate:              0.1242\n",
            "No pseudo_novel_loader available.\n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall superclass acc: 0.9787\n",
            "Seen superclass acc (true super != novel):   0.9618\n",
            "Seen superclass false-novel rate:            0.0382\n",
            "Novel superclass acc (true super == novel):  1.0000\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "     Split   Head                             Metric  \\\n",
            "0   config      -                           APPROACH   \n",
            "1   config      -                           BACKBONE   \n",
            "2   config      -                   CIFAR_NOVEL_MODE   \n",
            "3   config      -                       DATA_AUGMENT   \n",
            "4   config      -                     FINE_TUNE_MODE   \n",
            "5   config      -                      SUB_HEAD_TYPE   \n",
            "6   config      -                            TAU_SUB   \n",
            "7   config      -                          TAU_SUPER   \n",
            "8   config      -                   USE_PSEUDO_NOVEL   \n",
            "9      val  super  Novel superclass accuracy (CIFAR)   \n",
            "10     val  super           Seen superclass accuracy   \n",
            "11     val  super   Seen superclass false-novel rate   \n",
            "\n",
            "                                              Meaning       Value  \n",
            "0        Model architecture (two_heads vs two_models)  two_models  \n",
            "1        Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                   Extra novel-super CIFAR data mode       large  \n",
            "3   Whether data augmentation is enabled for training        True  \n",
            "4             Backbone training mode (full vs frozen)        full  \n",
            "5            Type of subclass head (linear or cosine)      cosine  \n",
            "6                 Novelty threshold for subclass head        0.73  \n",
            "7               Novelty threshold for superclass head        0.99  \n",
            "8     Using held-out subclasses for pseudo-novel eval       False  \n",
            "9   CIFAR novel-super samples correctly predicted ...         1.0  \n",
            "10           Correctly keep seen superclasses as seen    0.961783  \n",
            "11     Seen superclasses incorrectly flipped to novel    0.038217  \n",
            "\n",
            "=== Evaluation on val ===\n",
            "Overall subclass acc:   0.9309\n",
            "Seen subclass acc (true sub != novel):       0.8758\n",
            "Seen subclass false-novel rate:              0.1242\n",
            "\n",
            "==== Novelty Dashboard ====\n",
            "     Split Head                          Metric  \\\n",
            "0   config    -                        APPROACH   \n",
            "1   config    -                        BACKBONE   \n",
            "2   config    -                CIFAR_NOVEL_MODE   \n",
            "3   config    -                    DATA_AUGMENT   \n",
            "4   config    -                  FINE_TUNE_MODE   \n",
            "5   config    -                   SUB_HEAD_TYPE   \n",
            "6   config    -                         TAU_SUB   \n",
            "7   config    -                       TAU_SUPER   \n",
            "8   config    -                USE_PSEUDO_NOVEL   \n",
            "9      val  sub          Seen subclass accuracy   \n",
            "10     val  sub  Seen subclass false-novel rate   \n",
            "\n",
            "                                              Meaning       Value  \n",
            "0        Model architecture (two_heads vs two_models)  two_models  \n",
            "1        Feature extractor (e.g. resnet18 / resnet50)    resnet50  \n",
            "2                   Extra novel-super CIFAR data mode       large  \n",
            "3   Whether data augmentation is enabled for training        True  \n",
            "4             Backbone training mode (full vs frozen)        full  \n",
            "5            Type of subclass head (linear or cosine)      cosine  \n",
            "6                 Novelty threshold for subclass head        0.73  \n",
            "7               Novelty threshold for superclass head        0.99  \n",
            "8     Using held-out subclasses for pseudo-novel eval       False  \n",
            "9              Correctly keep seen subclasses as seen    0.875796  \n",
            "10       Seen subclasses incorrectly flipped to novel    0.124204  \n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>sub_train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sub_val_acc</td><td>▁▆▆▇▇▇▆▇▇█▇▇▇▇▇█▇▇▇█▇█▇▇▇</td></tr><tr><td>sub_val_loss</td><td>█▃▂▁▁▁▂▁▁▁▂▁▁▂▂▁▁▃▂▂▂▁▂▂▁</td></tr><tr><td>tau_super_candidate_1</td><td>▁</td></tr><tr><td>tau_super_candidate_2</td><td>▁</td></tr><tr><td>tau_super_candidate_3</td><td>▁</td></tr><tr><td>val_novel_super_acc</td><td>▁</td></tr><tr><td>val_overall_sub_acc</td><td>▁</td></tr><tr><td>val_overall_super_acc</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>sub_train_loss</td><td>0.0193</td></tr><tr><td>sub_val_acc</td><td>0.94947</td></tr><tr><td>sub_val_loss</td><td>0.17777</td></tr><tr><td>tau_super_candidate_1</td><td>0.9992</td></tr><tr><td>tau_super_candidate_2</td><td>0.99555</td></tr><tr><td>tau_super_candidate_3</td><td>0.96998</td></tr><tr><td>val_novel_super_acc</td><td>1</td></tr><tr><td>val_overall_sub_acc</td><td>0.93085</td></tr><tr><td>val_overall_super_acc</td><td>0.97872</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">two_models_sub_resnet_20251214_054909</strong> at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/i9om768p' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition/runs/i9om768p</a><br> View project at: <a href='https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition' target=\"_blank\">https://wandb.ai/nndl-project-F25/Multihead-Classification-Competition</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20251214_054910-i9om768p/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if APPROACH == \"two_models\":\n",
        "    best_super_path = os.path.join(DATA_ROOT, \"best_super_model.pth\")\n",
        "    model_super.load_state_dict(torch.load(best_super_path, map_location=device))\n",
        "    best_sub_path = os.path.join(DATA_ROOT, \"best_sub_model.pth\")\n",
        "    model_sub.load_state_dict(torch.load(best_sub_path, map_location=device))\n",
        "\n",
        "    analyze_tau_sub(model_sub, pseudo_novel_loader, val_loader, mode=\"sub_single_head\")\n",
        "    analyze_tau_super(model_super, val_loader, NOVEL_SUPER_IDX, mode=\"super_single_head\")\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_super,\n",
        "        mode=\"super_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        val_loader=val_loader,\n",
        "        name=\"val_super_only\",\n",
        "    )\n",
        "    evaluate_on_val_with_novelty(\n",
        "        model_sub,\n",
        "        mode=\"sub_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        val_loader=val_loader,\n",
        "        name=\"val_sub_only\",\n",
        "    )\n",
        "\n",
        "    evaluate_pseudo_novel_sub_with_novelty(model_sub, mode=\"sub_single_head\", tau_sub=TAU_SUB)\n",
        "\n",
        "    novelty_dashboard(\n",
        "        model_super,\n",
        "        val_loader=val_loader,\n",
        "        pseudo_novel_loader=pseudo_novel_loader,\n",
        "        mode=\"super_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        include_pseudo=False,\n",
        "    )\n",
        "    novelty_dashboard(\n",
        "        model_sub,\n",
        "        val_loader=val_loader,\n",
        "        pseudo_novel_loader=pseudo_novel_loader,\n",
        "        mode=\"sub_single_head\",\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "        include_pseudo=True,\n",
        "    )\n",
        "\n",
        "    if run_sub is not None:\n",
        "        run_sub.finish()\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping subclass model training in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfZTFepgRxey"
      },
      "source": [
        "# SECTION 8: Test-time Inference & CSV Export for leaderboard **(two-head model)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_69xbINR2w6",
        "outputId": "1aaa42ad-6e1c-4952-b719-cc6441cce238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\n"
          ]
        }
      ],
      "source": [
        "# SECTION: Test-time inference & CSV export for two-heads model\n",
        "\n",
        "if APPROACH == \"two_heads\":\n",
        "    # Recreate the model and load best checkpoint\n",
        "    model_two_heads = SharedBackboneTwoHeads(num_super=num_super, num_sub=num_sub).to(device)\n",
        "    best_ckpt_path = os.path.join(DATA_ROOT, \"best_two_heads_kl.pth\")\n",
        "    model_two_heads.load_state_dict(torch.load(best_ckpt_path, map_location=device))\n",
        "\n",
        "    test_predictions = predict_test_two_heads(\n",
        "        model_two_heads,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_heads_predictions.csv\")\n",
        "    test_predictions.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-heads predictions (with novelty) to:\", out_csv_path)\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_heads'; skipping two-heads inference in this cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPpeqduiLv5"
      },
      "source": [
        "# SECTION 9: Test-time Inference & CSV Export for leaderboard **(two separate models)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWEswAdKijVa",
        "outputId": "2bc16674-6d38-4278-bafc-d631cbbab5bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved two-model predictions (with novelty) to: /content/drive/MyDrive/NNDL-Project/Project Data/two_models_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "if APPROACH == \"two_models\":\n",
        "    model_super.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_super_model.pth\"), map_location=device))\n",
        "    model_sub.load_state_dict(torch.load(os.path.join(DATA_ROOT, \"best_sub_model.pth\"), map_location=device))\n",
        "\n",
        "    test_predictions_two_models = predict_test_two_models(\n",
        "        model_super,\n",
        "        model_sub,\n",
        "        test_loader,\n",
        "        tau_super=TAU_SUPER,\n",
        "        tau_sub=TAU_SUB,\n",
        "    )\n",
        "\n",
        "    out_csv_path = os.path.join(DATA_ROOT, \"two_models_predictions.csv\")\n",
        "    test_predictions_two_models.to_csv(out_csv_path, index=False)\n",
        "    print(\"Saved two-model predictions (with novelty) to:\", out_csv_path)\n",
        "\n",
        "else:\n",
        "    print(\"APPROACH is not 'two_models'; skipping two-models inference in this cell.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kret_312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
