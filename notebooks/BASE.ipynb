{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from /Users/Akseldkw/coding/Columbia/NNDL-Project/.env.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:JAX version 0.7.2 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Akseldkw/coding/kretsinger/data/nb_log.log\n"
     ]
    }
   ],
   "source": [
    "from kret_studies import *\n",
    "from kret_studies.notebook import *\n",
    "from kret_studies.complex import *\n",
    "\n",
    "logger = get_notebook_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Users/Akseldkw/micromamba/envs/kret_312/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from nndl_model.constants import DATA_DIR, MODEL_WEIGHT_DIR, ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/Akseldkw/coding/Columbia/NNDL-Project/img_data')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = uks_torch.exp_decay(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE_TORCH_STR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nndl_model.impl.cnn_3_128_v000_test_aksel import CNN_3_128_V000_Test_Aksel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- sanity_sprint.py (or a single notebook cell) ----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "\n",
    "# Disable wandb logging for this quick check\n",
    "wandb.init(project=\"nndl-sanity\", mode=\"disabled\")\n",
    "\n",
    "from nndl_model.DATA_LOADERS import make_dataloaders\n",
    "from nndl_model.BASE import BaseModel\n",
    "\n",
    "# 1) Load data (uses DATA_DIR from your constants)\n",
    "train_loader, val_loader, test_loader, M, S, K = make_dataloaders(\n",
    "    batch_size=32,  # small, so it runs fast\n",
    "    val_fraction=0.1,  # any small split\n",
    "    image_size=224,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyCNN(BaseModel):\n",
    "    def __init__(self, lr=1e-3, feature_dim=64, S=3, K=10, M=None):\n",
    "        super().__init__(lr=lr)  # 1) init base (no optimizer yet)\n",
    "        self.model = nn.Sequential(  # 2) define backbone params\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),  # -> [B, 64]\n",
    "        )\n",
    "        # 3) add heads + optimizer now exists\n",
    "        self.configure_hierarchy(feature_dim=feature_dim, num_super=S, num_sub=K, M=M)\n",
    "        self.reset_optimizer()  # 4) create optimizer now that params exist\n",
    "        # If you were NOT using hierarchy, call this instead:\n",
    "        # self.reset_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"attribute 'M' already exists\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3) Instantiate model and sprint a couple epochs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mTinyCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mTinyCNN.__init__\u001b[39m\u001b[34m(self, lr, feature_dim, S, K, M)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mself\u001b[39m.model = nn.Sequential(  \u001b[38;5;66;03m# 2) define backbone params\u001b[39;00m\n\u001b[32m      5\u001b[39m     nn.Conv2d(\u001b[32m3\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m3\u001b[39m, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m),\n\u001b[32m      6\u001b[39m     nn.ReLU(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     nn.Flatten(),  \u001b[38;5;66;03m# -> [B, 64]\u001b[39;00m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# 3) add heads + optimizer now exists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfigure_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_super\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sub\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mself\u001b[39m.reset_optimizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/Columbia/NNDL-Project/nndl_model/BASE.py:85\u001b[39m, in \u001b[36mBaseModel.configure_hierarchy\u001b[39m\u001b[34m(self, feature_dim, num_super, num_sub, M, alpha, beta, gamma)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m M.dim() != \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m M.size(\u001b[32m0\u001b[39m) != num_super \u001b[38;5;129;01mor\u001b[39;00m M.size(\u001b[32m1\u001b[39m) != num_sub:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mM must have shape [num_super, num_sub]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregister_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mM\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# saves/loads with state_dict, not optimized\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28mself\u001b[39m.alpha, \u001b[38;5;28mself\u001b[39m.beta, \u001b[38;5;28mself\u001b[39m.gamma = \u001b[38;5;28mfloat\u001b[39m(alpha), \u001b[38;5;28mfloat\u001b[39m(beta), \u001b[38;5;28mfloat\u001b[39m(gamma)\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Recreate optimizer so new head params are included\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/nn/modules/module.py:557\u001b[39m, in \u001b[36mModule.register_buffer\u001b[39m\u001b[34m(self, name, tensor, persistent)\u001b[39m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mbuffer name can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33mt be empty string \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    556\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffers:\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mattribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m already exists\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch.Tensor):\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    560\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot assign \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.typename(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object to buffer \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    561\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(torch Tensor or None required)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    562\u001b[39m     )\n",
      "\u001b[31mKeyError\u001b[39m: \"attribute 'M' already exists\""
     ]
    }
   ],
   "source": [
    "# 3) Instantiate model and sprint a couple epochs\n",
    "model = TinyCNN(lr=1e-3, feature_dim=64, S=S, K=K, M=M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m         \u001b[38;5;28mself\u001b[39m.configure_hierarchy(feature_dim=feature_dim, num_super=S, num_sub=K, M=M)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 3) Instantiate model and sprint a couple epochs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m model = \u001b[43mTinyCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m model.train_model(train_loader, val_loader, epochs=\u001b[32m2\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 4) Quick inference smoke test on the test loader (no labels there)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mTinyCNN.__init__\u001b[39m\u001b[34m(self, lr, feature_dim, S, K, M)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr=\u001b[32m1e-3\u001b[39m, feature_dim=\u001b[32m64\u001b[39m, S=\u001b[32m3\u001b[39m, K=\u001b[32m10\u001b[39m, M=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = nn.Sequential(\n\u001b[32m     24\u001b[39m         nn.Conv2d(\u001b[32m3\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m3\u001b[39m, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m), nn.ReLU(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     25\u001b[39m         nn.Conv2d(\u001b[32m32\u001b[39m, \u001b[32m64\u001b[39m, \u001b[32m3\u001b[39m, stride=\u001b[32m2\u001b[39m, padding=\u001b[32m1\u001b[39m), nn.ReLU(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     26\u001b[39m         nn.AdaptiveAvgPool2d(\u001b[32m1\u001b[39m),\n\u001b[32m     27\u001b[39m         nn.Flatten(),  \u001b[38;5;66;03m# -> [B, 64]\u001b[39;00m\n\u001b[32m     28\u001b[39m     )\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# Turn on hierarchical heads\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/coding/Columbia/NNDL-Project/nndl_model/BASE.py:47\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, lr)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.alpha, \u001b[38;5;28mself\u001b[39m.beta, \u001b[38;5;28mself\u001b[39m.gamma = \u001b[32m1.0\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m0.1\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28mself\u001b[39m.criterion = nn.CrossEntropyLoss()\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.scheduler = torch.optim.lr_scheduler.StepLR(\u001b[38;5;28mself\u001b[39m.optimizer, step_size=\u001b[32m7\u001b[39m, gamma=\u001b[32m0.1\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.device = DEVICE_TORCH_STR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/optim/adam.py:100\u001b[39m, in \u001b[36mAdam.__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused, decoupled_weight_decay)\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m     99\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/kret_312/lib/python3.12/site-packages/torch/optim/optimizer.py:364\u001b[39m, in \u001b[36mOptimizer.__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    362\u001b[39m param_groups = \u001b[38;5;28mlist\u001b[39m(params)\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(param_groups) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33moptimizer got an empty parameter list\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(param_groups[\u001b[32m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    366\u001b[39m     param_groups = [{\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m: param_groups}]\n",
      "\u001b[31mValueError\u001b[39m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "model.train_model(train_loader, val_loader, epochs=2)\n",
    "\n",
    "# 4) Quick inference smoke test on the test loader (no labels there)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for imgs, img_ids in test_loader:\n",
    "        logits_sup, logits_sub = model(imgs.to(model.device))\n",
    "        preds_super = logits_sup.argmax(1).cpu().tolist()\n",
    "        preds_sub = logits_sub.argmax(1).cpu().tolist()\n",
    "        print(f\"Sample predictions: super={preds_super[:5]}, sub={preds_sub[:5]}\")\n",
    "        break  # just peek at one batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kret_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
